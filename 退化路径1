import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from matplotlib.gridspec import GridSpec
from scipy.stats import gaussian_kde
import matplotlib.dates as mdates
from matplotlib.colors import LinearSegmentedColormap
import os
import re

# 定义保存路径
output_path = "/mnt/c/Users/think/Desktop/scond"
os.makedirs(output_path, exist_ok=True)

# 设置随机种子
np.random.seed(42)

# ======================
# 1. 高级退化模型配置 (更新为真实时间范围)
# ======================
class DegradationModelConfig:
    def __init__(self):
        # 时间参数 (基于轮机日志)
        self.start_date = datetime(2015, 3, 14, 1, 0, 0)
        self.end_date = datetime(2019, 1, 14, 23, 59, 0)
        self.total_duration = self.end_date - self.start_date
        self.total_hours = int(self.total_duration.total_seconds() / 3600)
        self.total_days = self.total_hours // 24
        
        # 操作条件
        self.condition_types = ['Normal', 'High Load', 'High Temp', 'Rough Sea']
        self.condition_probs = [0.65, 0.20, 0.10, 0.05]
        
        # 退化影响因素
        self.condition_impact = {
            'Normal': 1.0,
            'High Load': 1.8,
            'High Temp': 2.4,
            'Rough Sea': 3.2
        }
        
        # 清洗参数 (将使用真实清洗事件)
        self.cleaning_effectiveness = {
            'recoverable': 0.95,
            'semi_permanent': 0.60,
            'permanent': 0.05
        }
        self.cleaning_decay = 0.0008
        
        # 退化模型参数
        # 可恢复退化
        self.recoverable_rate = {
            'base': 0.00025,
            'noise': 0.00003,
            'shock_prob': 0.00035,
            'shock_severity': [0.008, 0.025],
            'recovery_speed': 0.85
        }
        
        # 半永久退化
        self.semi_permanent_rate = {
            'base': 0.00008,
            'noise': 0.000012,
            'shock_prob': 0.00025,
            'shock_severity': [0.004, 0.015],
            'recovery_speed': 0.55
        }
        
        # 永久退化
        self.permanent_rate = {
            'base': 0.000045,
            'noise': 0.000007,
            'shock_prob': 0.00018,
            'shock_severity': [0.002, 0.008],
            'recovery_speed': 0.15
        }
        
        # 初始健康状态
        self.initial_health = 1.00
        
        # 性能恢复参数
        self.recovery_duration = 24
        self.recovery_factor = 1.8

# ======================
# 2. 操作条件模拟器
# ======================
class ConditionSimulator:
    def __init__(self, config):
        self.config = config
        
    def generate_conditions(self):
        """生成随时间变化的操作条件"""
        condition_sequence = np.random.choice(
            self.config.condition_types,
            size=self.config.total_hours,
            p=self.config.condition_probs
        )
        
        # 确保操作条件连续性
        current_condition = condition_sequence[0]
        condition_duration = 0
        min_duration = 24
        
        for i in range(1, self.config.total_hours):
            condition_duration += 1
            
            if condition_duration >= min_duration:
                if current_condition == 'Rough Sea' and np.random.rand() < 0.3:
                    new_condition = np.random.choice(['Normal', 'High Load'], p=[0.7, 0.3])
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                elif np.random.rand() < 0.08:
                    new_condition = np.random.choice(
                        self.config.condition_types,
                        p=self.config.condition_probs
                    )
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                else:
                    condition_sequence[i] = current_condition
            else:
                condition_sequence[i] = current_condition
        
        return condition_sequence
    
    def get_impact_factor(self, condition):
        """获取条件的退化影响因子"""
        return self.config.condition_impact[condition]

# ======================
# 3. 清洗事件模拟器 (使用真实轮机日志)
# ======================
class CleaningSimulator:
    def __init__(self, config):
        self.config = config
        self.total_days = config.total_days
        self.cleaning_events = self.parse_engine_log()
        
    def parse_engine_log(self):
        """解析轮机日志中的清洗事件"""
        # 轮机日志文本
        engine_log = """
        2015年3月涡轮清洗时间：2015年3月14号8点，2015年3月24号12点，2015年3月27号12点，2015年3月30号12点
        2015年4月涡轮清洗时间：2015年4月2号13点，2015年4月5号13点，2015年4月8号13点，2015年4月11号13点，2015年4月14号13点，2015年4月17号13点，2015年4月20号13点
        2015年5月涡轮清洗时间：2015年5月19号20点，2015年5月22号18点，2015年5月25号18点，2015年5月31号16点
        2015年6月涡轮清洗时间：2015年6月7号13点，2015年6月10号13点，2015年6月13号13点，2015年6月16号12点，2015年6月19号11点，2015年6月22号12点，2015年6月28号9点
        2015年7月涡轮清洗时间：2015年7月1号9点，2015年7月22号9点，2015年7月25号9点，2015年7月30号10点
        2015年8月涡轮清洗时间：2015年8月23号20点
        2015年9月涡轮清洗时间：2015年9月1号19点，2015年9月4号19点，2015年9月7号19点，2015年9月10号19点，2015年9月13号19点，2015年9月17号5点，2015年9月21号2点，2015年9月25号19点
        2015年10月涡轮清洗时间：2015年10月1号9点，2015年10月4号9点，2015年10月7号9点，2015年10月13号12点，2015年10月25号10点，2015年10月28号10点，2015年10月31号11点
        2015年11月涡轮清洗时间：2015年11月3号13点，2015年11月6号13点，2015年11月9号15点，2015年11月12号14点，2015年11月15号15点，2015年11月18号17点，2015年11月27号18点，2015年11月30号15点
        2015年12月涡轮清洗时间：2015年12月3号16点，2015年12月8号15点，2015年12月11号12点，2015年12月15号15点，2015年12月19号2点，2015年12月21号10点，2015年12月24号10点，2015年12月27号10点，2015年12月30号9点
        
        2016年1月涡轮清洗时间：2016年1月2号9点，2016年1月25号9点，2016年1月28号9点
        2016年2月涡轮清洗时间：2016年2月2号10点，2016年2月5号11点，2016年2月8号10点，2016年2月12号13点，2016年2月15号14点，2016年2月18号15点，2016年2月21号15点，2016年2月24号15点
        2016年3月涡轮清洗时间：2016年3月7号17点，2016年3月10号17点，2016年3月13号18点，2016年3月16号18点，2016年3月19号17点，2016年3月23号15点，2016年3月26号17点，2016年3月29号12点
        2016年4月涡轮清洗时间：2016年4月1号12点，2016年4月4号11点，2016年4月7号11点，2016年4月11号11点，2016年4月14号10点，2016年4月17号9点，2016年4月20号10点
        2016年5月涡轮清洗时间：2016年5月5号9点，2016年5月8号9点，2016年5月11号9点
        2016年6月涡轮清洗时间：2016年6月17号9点，2016年6月20号11点，2016年6月23号12点，2016年6月26号12点，2016年6月29号14点
        2016年7月涡轮清洗时间：2016年7月3号15点，2016年7月6号16点，2016年7月9号17点，2016年7月12号18点，2016年7月16号20点，2016年7月24号19点，2016年7月27号19点，2016年7月30号17点
        2016年8月涡轮清洗时间：2016年8月2号17点，2016年8月5号16点，2016年8月8号14点，2016年8月11号14点，2016年8月14号13点，2016年8月17号12点，2016年8月20号11点，2016年8月23号10点，2016年8月26号10点，2016年8月29号10点
        2016年9月涡轮清洗时间：2016年9月1号9点，2016年9月4号9点，2016年9月13号9点，2016年9月17号9点，2016年9月22号12点，2016年9月25号11点，2016年9月28号11点
        2016年10月涡轮清洗时间：2016年10月1号13点，2016年10月6号15点，2016年10月9号15点，2016年10月12号17点，2016年10月15号16点，2016年10月18号18点，2016年10月21号19点，2016年10月31号19点
        2016年11月涡轮清洗时间：2016年11月3号19点，2016年11月6号19点，2016年11月9号18点，2016年11月12号18点，2016年11月15号17点，2016年11月18号15点，2016年11月21号14点，2016年11月24号13点，2016年11月27号13点，2016年11月30号13点
        2016年12月涡轮清洗时间：2016年12月3号12点，2016年12月6号10点，2016年12月9号10点，2016年12月12号9点，2016年12月15号9点，2016年12月18号9点，2016年12月30号12点
        
        2017年1月涡轮清洗时间：2017年1月4号10点，2017年1月7号10点，2017年1月16号10点，2017年1月19号12点，2017年1月22号12点，2017年1月25号12点，2017年1月28号14点，2017年1月31号15点
        2017年2月涡轮清洗时间：2017年2月3号16点，2017年2月6号16点，2017年2月9号19点，2017年2月12号19点，2017年2月18号20点，2017年2月21号19点，2017年2月24号1点，2017年2月27号16点
        2017年3月涡轮清洗时间：2017年3月2号14点，2017年3月5号14点，2017年3月8号13点，2017年3月11号13点，2017年3月14号12点，2017年3月17号11点，2017年3月20号10点，2017年3月26号10点，2017年3月29号9点
        2017年4月涡轮清洗时间：2017年4月9号14点，2017年4月12号9点，2017年4月9号9点，2017年4月16号11点，2017年4月19号12点，2017年4月22号12点，2017年4月25号13点，2017年4月28号13点
        2017年5月涡轮清洗时间：2017年5月1号14点，2017年5月4号15点，2017年5月9号16点，2017年5月12号16点，2017年5月16号19点，2017年5月19号20点，2017年5月26号20点，2017年5月29号19点
        2017年6月涡轮清洗时间：2017年6月1号18点，2017年6月4号16点，2017年6月7号19点，2017年6月10号16点，2017年6月13号14点，2017年6月16号14点，2017年6月19号12点，2017年6月27号10点
        2017年7月涡轮清洗时间：2017年7月3号10点
        2017年8月涡轮清洗时间：2017年8月20号11点，2017年8月23号12点，2017年8月26号13点，2017年8月29号14点
        2017年9月涡轮清洗时间：2017年9月1号15点，2017年9月4号16点，2017年9月7号17点，2017年9月10号16点，2017年9月3号16点，2017年9月16号20点，2017年9月28号19点
        2017年10月涡轮清洗时间：2017年10月1号19点，2017年10月7号17点，2017年10月10号15点，2017年10月16号14点，2017年10月19号14点，2017年10月22号13点，2017年10月25号11点，2017年10月31号9点
        2017年11月涡轮清洗时间：2017年11月1号9点，2017年11月9号9点
        2017年12月涡轮清洗时间：2017年12月8号9点，2017年12月11号9点，2017年12月17号11点，2017年12月20号11点，2017年12月23号13点，2017年12月26号15点，2017年12月29号15点
        
        2018年1月涡轮清洗时间：2018年1月1号15点，2018年1月4号17点，2018年1月7号18点，2018年1月10号19点，2018年1月19号17点，2018年1月21号19点，2018年1月24号19点，2018年1月27号19点，2018年1月30号17点
        2018年2月涡轮清洗时间：2018年2月2号17点，2018年2月5号15点，2018年2月8号15点，2018年2月11号13点，2018年2月14号12点，2018年2月17号11点，2018年2月20号11点
        2018年3月涡轮清洗时间：2018年3月12号11点，2018年3月15号10点，2018年3月22号11点，2018年3月25号11点，2018年3月27号11点，2018年3月30号14点
        2018年4月涡轮清洗时间：2018年4月2号14点，2018年4月5号15点，2018年4月8号16点，2018年4月11号17点，2018年4月14号18点，2018年4月17号19点
        2018年5月涡轮清洗时间：2018年5月14号19点，2018年5月17号19点，2018年5月20号19点，2018年5月23号17点，2018年5月26号16点，2018年5月29号15点
        2018年6月涡轮清洗时间：2018年6月1号15点，2018年6月4号14点，2018年6月7号13点，2018年6月10号12点，2018年6月13号12点，2018年6月16号10点，2018年6月19号9点，2018年6月22号9点，2018年6月25号9点
        2018年7月涡轮清洗时间：2018年7月13号14点，2018年7月22号18点，2018年7月25号11点，2018年7月28号12点
        2018年8月涡轮清洗时间：2018年8月3号14点，2018年8月6号15点，2018年8月9号16点，2018年8月12号17点，2018年8月15号18点，2018年8月18号19点，2018年8月21号21点
        2018年9月涡轮清洗时间：2018年9月2号19点，2018年9月5号19点，2018年9月8号17点，2018年9月12号16点，2018年9月14号16点，2018年9月17号14点，2018年9月20号13点，2018年9月23号13点，2018年9月26号13点
        2018年10月涡轮清洗时间：2018年10月5号10点，2018年10月8号10点，2018年10月20号9点，2018年10月26号10点，2018年10月29号11点
        2018年11月涡轮清洗时间：2018年11月1号12点，2018年11月4号13点，2018年11月7号14点，2018年11月10号20点，2018年11月13号16点，2018年11月16号17点，2018年11月19号18点，2018年11月22号19点
        2018年12月涡轮清洗时间：2018年12月4号19点，2018年12月7号19点，2018年12月10号19点，2018年12月13号18点，2018年12月16号17点，2018年12月26号14点，2018年12月30号12点
        """
        
        # 解析日志中的清洗事件
        cleaning_events = []
        pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        
        for match in re.finditer(pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                # 创建datetime对象
                event_time = datetime(year, month, day, hour)
                # 确保事件在时间范围内
                if self.config.start_date <= event_time <= self.config.end_date:
                    cleaning_events.append(event_time)
            except ValueError:
                # 跳过无效日期
                continue
        
        # 去重并排序
        cleaning_events = sorted(set(cleaning_events))
        return cleaning_events
    
    def generate_cleaning_schedule(self):
        """生成基于轮机日志的清洗计划"""
        cleaning_hours = []
        
        for event_time in self.cleaning_events:
            # 计算相对于起始时间的小时数
            hours_from_start = int((event_time - self.config.start_date).total_seconds() / 3600)
            cleaning_hours.append(hours_from_start)
        
        return cleaning_hours
    
    def get_cleaning_effectiveness(self, cleaning_count, deg_type):
        """计算清洗效果"""
        base_effectiveness = self.config.cleaning_effectiveness[deg_type]
        effectiveness = base_effectiveness * (1 - self.config.cleaning_decay * cleaning_count)
        
        min_effect = {
            'recoverable': 0.85,
            'semi_permanent': 0.45,
            'permanent': 0.02
        }
        return max(effectiveness, min_effect[deg_type])

# ======================
# 4. 退化路径模拟器（性能恢复）
# ======================
class AdvancedDegradationSimulator:
    def __init__(self, config):
        self.config = config
        self.condition_simulator = ConditionSimulator(config)
        self.cleaning_simulator = CleaningSimulator(config)
        
    def simulate(self):
        """模拟退化路径（小时分辨率）"""
        # 生成时间戳
        timestamps = [self.config.start_date + timedelta(hours=i) 
                      for i in range(self.config.total_hours)]
        
        # 生成操作条件
        conditions = self.condition_simulator.generate_conditions()
        
        # 生成清洗计划（基于轮机日志）
        cleaning_hours = self.cleaning_simulator.generate_cleaning_schedule()
        cleaning_count = 0
        
        # 初始化退化路径
        health = np.full(self.config.total_hours, self.config.initial_health)
        recoverable = np.zeros(self.config.total_hours)
        semi_permanent = np.zeros(self.config.total_hours)
        permanent = np.zeros(self.config.total_hours)
        
        # 性能恢复状态
        recovery_state = np.zeros(self.config.total_hours)
        
        # 清洗效果记录
        cleaning_effects = np.zeros((self.config.total_hours, 3))
        
        # 主模拟循环（小时分辨率）
        for t in range(1, self.config.total_hours):
            # 更新恢复状态
            if recovery_state[t-1] > 0:
                recovery_state[t] = max(recovery_state[t-1] - 1/self.config.recovery_duration, 0)
            
            # 获取条件影响
            condition = conditions[t]
            impact_factor = self.condition_simulator.get_impact_factor(condition)
            
            # 计算退化增量
            # 1. 可恢复退化
            base_rate = self.config.recoverable_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.recoverable_rate['noise'])
            shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                if np.random.rand() < self.config.recoverable_rate['shock_prob'] else 0
            recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
            
            # 2. 半永久退化
            base_rate = self.config.semi_permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.semi_permanent_rate['noise'])
            shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.semi_permanent_rate['shock_prob'] else 0
            semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # 3. 永久退化
            base_rate = self.config.permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.permanent_rate['noise'])
            shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.permanent_rate['shock_prob'] else 0
            permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # 计算总健康度
            total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
            health[t] = max(self.config.initial_health - total_degradation, 0.01)
            
            # 应用性能恢复
            if recovery_state[t] > 0:
                recovery_factor = 1 + (self.config.recovery_factor - 1) * recovery_state[t]
                health[t] = min(health[t] * recovery_factor, self.config.initial_health)
            
            # 应用清洗效果
            if t in cleaning_hours:
                cleaning_count += 1
                recovery_state[t] = 1.0
                
                # 计算退化减少量
                recov_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'recoverable')
                semi_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'semi_permanent')
                perm_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'permanent')
                
                # 应用清洗
                recoverable_reduction = recoverable[t] * recov_effect
                semi_reduction = semi_permanent[t] * semi_effect
                permanent_reduction = permanent[t] * perm_effect
                
                recoverable[t] = max(recoverable[t] - recoverable_reduction, 0)
                semi_permanent[t] = max(semi_permanent[t] - semi_reduction, 0)
                permanent[t] = max(permanent[t] - permanent_reduction, 0)
                
                # 记录清洗效果
                cleaning_effects[t] = [recoverable_reduction, semi_reduction, permanent_reduction]
                
                # 重新计算健康度
                total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
                health[t] = max(self.config.initial_health - total_degradation, 0.01)
                
                # 应用即时性能提升
                health[t] = min(health[t] * self.config.recovery_factor, self.config.initial_health)
        
        # 创建结果DataFrame
        results = pd.DataFrame({
            'timestamp': timestamps,
            'health': health,
            'recoverable': recoverable,
            'semi_permanent': semi_permanent,
            'permanent': permanent,
            'condition': conditions,
            'recovery_state': recovery_state,
            'cleaning_effect_recov': cleaning_effects[:, 0],
            'cleaning_effect_semi': cleaning_effects[:, 1],
            'cleaning_effect_perm': cleaning_effects[:, 2],
        })
        
        # 添加日期信息
        results['date'] = results['timestamp'].dt.date
        results['day'] = (results['timestamp'] - results['timestamp'].iloc[0]).dt.days
        results['hour'] = results['timestamp'].dt.hour
        
        return results, cleaning_hours

# ======================
# 5. 完整可视化（修改横轴为时间）
# ======================
class CompleteVisualization:
    def __init__(self, degradation_data, cleaning_hours, config):
        self.data = degradation_data
        self.cleaning_hours = cleaning_hours
        self.config = config
        self.cleaning_events = [self.data['timestamp'].iloc[h] for h in cleaning_hours]
        
        # 创建每日数据
        self.daily_data = self.data.groupby('date').last().reset_index()
        
        # 标记清洗日期
        cleaning_dates = self.data.loc[self.data.index.isin(cleaning_hours), 'date'].unique()
        self.daily_data['cleaning_event'] = self.daily_data['date'].isin(cleaning_dates)
        
        # 添加年份信息
        self.daily_data['year'] = self.daily_data['date'].apply(lambda x: x.year)
        
        # 计算退化率
        self._calculate_degradation_rates()
    
    def _calculate_degradation_rates(self):
        """计算可视化用的退化率"""
        # 计算每日退化
        self.daily_data['daily_degradation'] = -self.daily_data['health'].diff().fillna(0)
        self.daily_data['degradation_rate'] = self.daily_data['daily_degradation'] * 100  # 百分比
        
        # 计算累计退化
        self.daily_data['cumulative_degradation'] = 1 - self.daily_data['health']
        
        # 计算退化组分百分比
        total_degradation = self.daily_data[['recoverable', 'semi_permanent', 'permanent']].sum(axis=1)
        self.daily_data['recoverable_pct'] = self.daily_data['recoverable'] / total_degradation * 100
        self.daily_data['semi_permanent_pct'] = self.daily_data['semi_permanent'] / total_degradation * 100
        self.daily_data['permanent_pct'] = self.daily_data['permanent'] / total_degradation * 100
    
    def plot_complete_analysis(self):
        """创建包含多个图表的综合分析"""
        plt.figure(figsize=(20, 18))
        
        # 创建网格布局
        gs = GridSpec(4, 2, height_ratios=[1.2, 1, 1, 1])
        
        # 图1：主健康趋势（顶部，全宽）
        ax1 = plt.subplot(gs[0, :])
        self._plot_main_health_trend(ax1, title='健康状态趋势与性能恢复峰值')
        
        # 图2：退化组件（中左）
        ax2 = plt.subplot(gs[1, 0])
        self._plot_degradation_components(ax2, title='随时间变化的退化组件')
        
        # 图3：退化率分析（中右）
        ax3 = plt.subplot(gs[1, 1])
        self._plot_degradation_rate_analysis(ax3, title='每日退化率分析')
        
        # 图4：性能恢复详情（左下）
        ax4 = plt.subplot(gs[2, 0])
        self._plot_recovery_detail(ax4, title='清洗后的性能恢复（72小时）')
        
        # 图5：退化组成随时间变化（右下）
        ax5 = plt.subplot(gs[2, 1])
        self._plot_degradation_composition(ax5, title='随时间变化的退化组成')
        
        # 图6：年度健康比较（底部，全宽）
        ax6 = plt.subplot(gs[3, :])
        self._plot_annual_comparison(ax6, title='年度健康状态比较')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, hspace=0.35)
        plt.suptitle('涡轮增压器退化与恢复综合分析（轮机日志整合）', 
                     fontsize=24, fontweight='bold')
        
        # 保存图片
        plt.savefig(os.path.join(output_path, 'complete_turbine_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
        
        # 保存单独的子图
        self.save_individual_plots()
        
        # 生成额外详细图表
        self.plot_detailed_degradation_path()
        self.plot_condition_impact_analysis()
        self.plot_cleaning_effectiveness_analysis()
    
    def save_individual_plots(self):
        """保存所有子图为单独的图片"""
        # 创建子图目录
        subplot_path = os.path.join(output_path, 'subplots')
        os.makedirs(subplot_path, exist_ok=True)
        
        # 1. 主健康趋势图
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_main_health_trend(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'main_health_trend.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. 退化组件图
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_components(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_components.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. 退化率分析图
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_rate_analysis(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_rate_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. 恢复详情图
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_recovery_detail(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'recovery_detail.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. 退化组成图
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_composition(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_composition.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. 年度比较图
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_annual_comparison(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'annual_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_main_health_trend(self, ax, title=None, show_title=True):
        """绘制主健康趋势与性能恢复标记"""
        # 应用平滑处理
        self.daily_data['health_smooth'] = self.daily_data['health'].rolling(window=7, min_periods=1).mean()
        
        # 绘制平滑健康趋势
        ax.plot(self.daily_data['date'], self.daily_data['health_smooth'], 
                color='#1f77b4', linewidth=2.5, label='健康状态')
        
        # 高亮清洗事件和性能峰值
        cleaning_data = self.data.loc[self.data.index.isin(self.cleaning_hours)]
        peak_values = []
        
        for _, row in cleaning_data.iterrows():
            # 标记清洗事件（垂直线）
            ax.axvline(x=row['timestamp'], color='#ff7f0e', alpha=0.3, linestyle='-', zorder=1)
            
            # 查找并标记性能峰值
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_idx = post_clean['health'].idxmax()
                peak_row = self.data.loc[peak_idx]
                peak_values.append(peak_row['health'])
                ax.plot(peak_row['timestamp'], peak_row['health'], 
                       'D', markersize=6, color='#d62728', alpha=0.8,
                       markeredgecolor='black', zorder=3, label='性能峰值')
        
        # 添加阈值线
        ax.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.852, '维护阈值', fontsize=12, color='#ff7f0e')
        
        ax.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.752, '故障阈值', fontsize=12, color='#d62728')
        
        # 添加年份标记
        years = pd.date_range(start=self.config.start_date, end=self.config.end_date, freq='YS')
        for year in years:
            ax.axvline(x=year, color='#2ca02c', linestyle='--', alpha=0.5, zorder=1)
            ax.text(year + timedelta(days=10), 0.72, f'{year.year}年', fontsize=11, color='#2ca02c')
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('日期', fontsize=12)
        ax.set_ylabel('健康状态', fontsize=12)
        ax.set_ylim(0.70, 1.02)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        
        # 格式化日期轴
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # 添加性能恢复统计
        if peak_values:
            avg_recovery = np.mean([pv - cd for pv, cd in zip(peak_values, cleaning_data['health'])])
            max_recovery = max(peak_values) - min(cleaning_data['health'])
            
            stats_text = f'平均恢复: {avg_recovery:.3f}\n最大恢复: {max_recovery:.3f}'
            ax.text(0.98, 0.05, stats_text,
                   transform=ax.transAxes, ha='right', fontsize=11,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
        
        # 创建自定义图例
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='#1f77b4', lw=2, label='健康状态'),
            Line2D([0], [0], marker='D', color='w', markerfacecolor='#d62728', 
                  markersize=8, markeredgecolor='black', label='性能峰值'),
            Line2D([0], [0], color='#ff7f0e', linestyle='-', alpha=0.3, label='清洗事件'),
        ]
        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)
    
    def _plot_degradation_components(self, ax, title=None, show_title=True):
        """绘制退化组件（使用清晰配色）"""
        # 绘制堆叠面积图
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable'], 
            self.daily_data['semi_permanent'], 
            self.daily_data['permanent'],
            labels=['可恢复', '半永久', '永久'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('日期', fontsize=11)
        ax.set_ylabel('累计退化', fontsize=11)
        ax.set_ylim(0, 0.35)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # 格式化日期轴
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # 添加退化组成信息
        total_deg = self.daily_data.iloc[-1][['recoverable', 'semi_permanent', 'permanent']].sum()
        if total_deg > 0:
            recov_pct = self.daily_data.iloc[-1]['recoverable'] / total_deg * 100
            semi_pct = self.daily_data.iloc[-1]['semi_permanent'] / total_deg * 100
            perm_pct = self.daily_data.iloc[-1]['permanent'] / total_deg * 100
            
            comp_text = (f'最终组成:\n'
                         f'可恢复: {recov_pct:.1f}%\n'
                         f'半永久: {semi_pct:.1f}%\n'
                         f'永久: {perm_pct:.1f}%')
            
            ax.text(0.95, 0.95, comp_text,
                   transform=ax.transAxes, ha='right', va='top', fontsize=10,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_degradation_rate_analysis(self, ax, title=None, show_title=True):
        """绘制退化率分析（含操作条件）"""
        # 应用平滑处理
        self.daily_data['degradation_rate_smooth'] = self.daily_data['degradation_rate'].rolling(window=7, min_periods=1).mean()
        
        # 绘制退化率
        ax.plot(self.daily_data['date'], self.daily_data['degradation_rate_smooth'], 
                color='#6a3d9a', linewidth=1.8, label='退化率')
        
        # 高亮高退化期
        high_degradation = self.daily_data[self.daily_data['degradation_rate_smooth'] > 
                                          self.daily_data['degradation_rate_smooth'].quantile(0.9)]
        ax.scatter(high_degradation['date'], high_degradation['degradation_rate_smooth'], 
                  color='#e31a1c', s=15, alpha=0.7, label='高退化期')
        
        # 添加条件影响标记
        condition_colors = {
            'Normal': '#1f77b4',
            'High Load': '#ff7f0e',
            'High Temp': '#d62728',
            'Rough Sea': '#2ca02c'
        }
        
        # 获取每日条件（通过聚合处理重复日期）
        daily_conditions = self.data.groupby('date')['condition'].agg(lambda x: x.value_counts().idxmax()).reset_index()
        daily_conditions.columns = ['date', 'condition_daily']
        
        # 与每日数据合并（确保唯一日期）
        self.daily_data = pd.merge(self.daily_data, daily_conditions, on='date', how='left')
        
        # 处理'condition_daily'中可能存在的缺失值
        if 'condition_daily' not in self.daily_data.columns:
            self.daily_data['condition_daily'] = 'Normal'
        else:
            self.daily_data['condition_daily'] = self.daily_data['condition_daily'].fillna('Normal')
        
        # 为非正常条件添加标记
        non_normal = self.daily_data[self.daily_data['condition_daily'] != 'Normal']
        for condition, color in condition_colors.items():
            if condition == 'Normal':
                continue
            condition_data = non_normal[non_normal['condition_daily'] == condition]
            ax.scatter(condition_data['date'], condition_data['degradation_rate_smooth'], 
                      color=color, s=25, marker='s', alpha=0.7, label=f'{condition}条件')
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('日期', fontsize=11)
        ax.set_ylabel('退化率 (%/天)', fontsize=11)
        ax.set_ylim(0, self.daily_data['degradation_rate_smooth'].max() * 1.2)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=8)
        
        # 格式化日期轴
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # 添加退化率统计
        avg_rate = self.daily_data['degradation_rate_smooth'].mean()
        max_rate = self.daily_data['degradation_rate_smooth'].max()
        
        stats_text = f'平均速率: {avg_rate:.4f}%/天\n最大速率: {max_rate:.4f}%/天'
        ax.text(0.95, 0.95, stats_text,
               transform=ax.transAxes, ha='right', fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_recovery_detail(self, ax, title=None, show_title=True):
        """绘制清洗后的详细性能恢复"""
        if not self.cleaning_events:
            ax.text(0.5, 0.5, '无清洗事件', ha='center', va='center', fontsize=14)
            return
        
        # 选择一个中期清洗事件
        mid_point = self.config.total_hours // 2
        cleaning_time = min(self.cleaning_events, key=lambda x: abs((x - self.config.start_date).total_seconds()/3600 - mid_point))
        
        # 获取清洗事件前后72小时的数据
        start_time = cleaning_time - timedelta(hours=24)
        end_time = cleaning_time + timedelta(hours=48)
        recovery_data = self.data[
            (self.data['timestamp'] >= start_time) & 
            (self.data['timestamp'] <= end_time)
        ].copy()
        
        if recovery_data.empty:
            return
        
        # 计算相对于清洗事件的小时数
        recovery_data['hours_from_clean'] = (recovery_data['timestamp'] - cleaning_time).dt.total_seconds() / 3600
        
        # 绘制健康变化
        ax.plot(recovery_data['hours_from_clean'], recovery_data['health'], 
                color='#1f77b4', linewidth=2, label='健康状态')
        
        # 绘制退化组件
        ax.plot(recovery_data['hours_from_clean'], recovery_data['recoverable'], 
                color='#a6d96a', linewidth=1.5, linestyle='--', alpha=0.8, label='可恢复')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['semi_permanent'], 
                color='#fdae61', linewidth=1.5, linestyle='--', alpha=0.8, label='半永久')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['permanent'], 
                color='#d7191c', linewidth=1.5, linestyle='--', alpha=0.8, label='永久')
        
        # 标记清洗时间
        ax.axvline(x=0, color='#ff7f0e', linestyle='-', alpha=0.8, label='清洗事件')
        
        # 高亮性能峰值
        post_clean = recovery_data[recovery_data['hours_from_clean'] >= 0]
        if not post_clean.empty:
            peak_idx = post_clean['health'].idxmax()
            peak_row = recovery_data.loc[peak_idx]
            ax.plot(peak_row['hours_from_clean'], peak_row['health'], 
                   'D', markersize=8, color='#d62728', alpha=0.8,
                   markeredgecolor='black', label='性能峰值')
            
            # 添加恢复幅度
            recovery_mag = peak_row['health'] - recovery_data[recovery_data['hours_from_clean'] == 0]['health'].values[0]
            ax.annotate(f'+{recovery_mag:.3f}', 
                       xy=(peak_row['hours_from_clean'], peak_row['health']),
                       xytext=(peak_row['hours_from_clean'], peak_row['health'] + 0.02),
                       ha='center', fontsize=10,
                       arrowprops=dict(arrowstyle='->', color='black'))
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('清洗后小时数', fontsize=11)
        ax.set_ylabel('健康状态', fontsize=11)
        ax.set_ylim(recovery_data[['health', 'recoverable', 'semi_permanent', 'permanent']].min().min() - 0.02, 
                   recovery_data['health'].max() + 0.04)
        ax.grid(alpha=0.1)
        ax.legend(loc='lower right', fontsize=8)
        
        # 添加恢复周期
        ax.axvspan(0, 24, color='#ffffbf', alpha=0.2, label='恢复期')
    
    def _plot_degradation_composition(self, ax, title=None, show_title=True):
        """绘制随时间变化的退化组成"""
        # 绘制百分比堆叠面积图
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable_pct'], 
            self.daily_data['semi_permanent_pct'], 
            self.daily_data['permanent_pct'],
            labels=['可恢复', '半永久', '永久'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('日期', fontsize=11)
        ax.set_ylabel('组成百分比', fontsize=11)
        ax.set_ylim(0, 100)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # 格式化日期轴
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # 添加趋势线
        ax.plot(self.daily_data['date'], self.daily_data['recoverable_pct'].rolling(30).mean(), 
               color='#006837', linewidth=2, alpha=0.7)
        ax.plot(self.daily_data['date'], self.daily_data['permanent_pct'].rolling(30).mean(), 
               color='#a50026', linewidth=2, alpha=0.7)
        
        # 添加组成变化注释
        initial_recov = self.daily_data['recoverable_pct'].iloc[100]
        final_recov = self.daily_data['recoverable_pct'].iloc[-1]
        initial_perm = self.daily_data['permanent_pct'].iloc[100]
        final_perm = self.daily_data['permanent_pct'].iloc[-1]
        
        ax.text(0.05, 0.15, 
               f"可恢复: {initial_recov:.1f}% → {final_recov:.1f}%\n永久: {initial_perm:.1f}% → {final_perm:.1f}%", 
               transform=ax.transAxes, fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_annual_comparison(self, ax, title=None, show_title=True):
        """绘制年度健康状态比较"""
        # 计算年度健康统计
        annual_stats = self.daily_data.groupby('year').agg({
            'health': ['min', 'max', 'mean', 'median'],
            'degradation_rate': ['mean', 'max']
        }).reset_index()
        
        # 设置位置
        bar_width = 0.2
        years = annual_stats['year'].unique()
        index = np.arange(len(years))
        
        # 绘制柱状图
        ax.bar(index, annual_stats[('health', 'max')], bar_width, 
              color='#2ca02c', label='年度峰值')
        ax.bar(index + bar_width, annual_stats[('health', 'mean')], bar_width, 
              color='#1f77b4', label='年度均值')
        ax.bar(index + bar_width*2, annual_stats[('health', 'median')], bar_width, 
              color='#ff7f0e', label='年度中位数')
        ax.bar(index + bar_width*3, annual_stats[('health', 'min')], bar_width, 
              color='#d62728', label='年度谷值')
        
        # 连接峰值和谷值
        for i, year in enumerate(years):
            ax.plot([i + bar_width/2, i + bar_width*3.5], 
                   [annual_stats.loc[i, ('health', 'max')], 
                   annual_stats.loc[i, ('health', 'min')]], 
                   color='#7f7f7f', linestyle='-', alpha=0.3)
        
        # 设置属性
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('年份', fontsize=12)
        ax.set_ylabel('健康状态', fontsize=12)
        ax.set_xticks(index + bar_width*1.5)
        ax.set_xticklabels([f'{year}年' for year in years])
        ax.set_ylim(0.70, 1.02)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=10)
        
        # 添加数值标签
        for i, year in enumerate(years):
            ax.text(i + bar_width*0.5, annual_stats.loc[i, ('health', 'max')] + 0.005, 
                   f'{annual_stats.loc[i, ("health", "max")]:.3f}', 
                   ha='center', fontsize=9)
            ax.text(i + bar_width*3.5, annual_stats.loc[i, ('health', 'min')] - 0.01, 
                   f'{annual_stats.loc[i, ("health", "min")]:.3f}', 
                   ha='center', fontsize=9, va='top')
        
        # 添加退化趋势
        degradation_trend = [1 - annual_stats.loc[i, ('health', 'mean')] for i in range(len(years))]
        ax2 = ax.twinx()
        ax2.plot(index + bar_width*1.5, degradation_trend, 
                'o-', color='#9467bd', linewidth=2, markersize=8, 
                label='平均退化水平')
        ax2.set_ylabel('退化水平', fontsize=12)
        ax2.set_ylim(0, 0.35)
        ax2.legend(loc='upper left', fontsize=10)
        
        # 添加退化率趋势
        ax3 = ax.twinx()
        ax3.spines['right'].set_position(('outward', 60))
        ax3.plot(index + bar_width*1.5, annual_stats[('degradation_rate', 'mean')], 
                's--', color='#e377c2', linewidth=2, markersize=8, 
                label='平均退化率')
        ax3.set_ylabel('退化率 (%/天)', fontsize=12)
        ax3.set_ylim(0, annual_stats[('degradation_rate', 'mean')].max() * 1.5)
        ax3.legend(loc='upper right', fontsize=10)
    
    def plot_detailed_degradation_path(self):
        """绘制详细退化路径（小时分辨率）"""
        plt.figure(figsize=(15, 10))
        
        # 创建网格布局
        gs = GridSpec(2, 1, height_ratios=[2, 1])
        
        # 图1：带清洗事件的健康状态
        ax1 = plt.subplot(gs[0])
        ax1.plot(self.data['timestamp'], self.data['health'], 
                color='#1f77b4', alpha=0.6, linewidth=0.8, label='小时健康度')
        
        # 添加日均值
        daily_health = self.data.groupby('date')['health'].mean()
        ax1.plot(daily_health.index, daily_health, 
                color='#2c7bb6', linewidth=2, label='日均健康度')
        
        # 高亮清洗事件
        for event in self.cleaning_events:
            ax1.axvline(x=event, color='#ff7f0e', alpha=0.4, linestyle='-')
        
        # 添加阈值
        ax1.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8)
        
        # 设置属性
        ax1.set_title('详细退化路径（小时分辨率）', fontsize=16)
        ax1.set_xlabel('日期', fontsize=12)
        ax1.set_ylabel('健康状态', fontsize=12)
        ax1.set_ylim(0.70, 1.02)
        ax1.set_xlim(self.config.start_date, self.config.end_date)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='lower left', fontsize=10)
        
        # 格式化日期轴
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # 图2：退化组件
        ax2 = plt.subplot(gs[1])
        ax2.plot(self.data['timestamp'], self.data['recoverable'], 
                color='#a6d96a', linewidth=1, alpha=0.7, label='可恢复')
        ax2.plot(self.data['timestamp'], self.data['semi_permanent'], 
                color='#fdae61', linewidth=1, alpha=0.7, label='半永久')
        ax2.plot(self.data['timestamp'], self.data['permanent'], 
                color='#d7191c', linewidth=1, alpha=0.7, label='永久')
        
        # 设置属性
        ax2.set_title('退化组件（小时数据）', fontsize=14)
        ax2.set_xlabel('日期', fontsize=12)
        ax2.set_ylabel('退化水平', fontsize=12)
        ax2.set_ylim(0, self.data[['recoverable', 'semi_permanent', 'permanent']].max().max() * 1.1)
        ax2.set_xlim(self.config.start_date, self.config.end_date)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper left', fontsize=9)
        
        # 格式化日期轴
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.25)
        
        # 保存图片
        plt.savefig(os.path.join(output_path, 'detailed_degradation_path.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_condition_impact_analysis(self):
        """绘制条件对退化的影响分析"""
        # 按条件计算退化率
        condition_degradation = self.data.groupby('condition').agg({
            'health': 'mean',
            'recoverable': 'mean',
            'semi_permanent': 'mean',
            'permanent': 'mean'
        })
        
        condition_degradation['total_degradation'] = 1 - condition_degradation['health']
        
        # 按条件计算退化率
        condition_rates = self.data.copy()
        condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
        condition_rates = condition_rates.groupby('condition')['degradation'].agg(['mean', 'std'])
        
        plt.figure(figsize=(14, 6))
        
        # 图1：按条件的退化水平
        ax1 = plt.subplot(121)
        condition_degradation[['recoverable', 'semi_permanent', 'permanent']].plot.bar(
            stacked=True, ax=ax1, color=['#a6d96a', '#fdae61', '#d7191c'], alpha=0.85)
        
        ax1.set_title('按操作条件的退化水平', fontsize=14)
        ax1.set_xlabel('操作条件', fontsize=12)
        ax1.set_ylabel('平均退化', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(title='退化类型', fontsize=9)
        
        # 图2：按条件的退化率
        ax2 = plt.subplot(122)
        condition_rates['mean'].plot.bar(yerr=condition_rates['std'], 
                                        ax=ax2, color='#6a3d9a', alpha=0.7)
        
        ax2.set_title('按操作条件的退化率', fontsize=14)
        ax2.set_xlabel('操作条件', fontsize=12)
        ax2.set_ylabel('平均退化率', fontsize=12)
        ax2.grid(alpha=0.1)
        
        # 添加条件影响因子
        for i, condition in enumerate(condition_rates.index):
            impact = self.config.condition_impact[condition]
            ax2.text(i, condition_rates['mean'].iloc[i] + 0.0001, 
                    f'影响: {impact}x', ha='center', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.88)
        plt.suptitle('操作条件影响分析', fontsize=16)
        
        # 保存图片
        plt.savefig(os.path.join(output_path, 'condition_impact_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_cleaning_effectiveness_analysis(self):
        """绘制清洗效果随时间变化分析"""
        if not self.cleaning_events:
            print("无清洗事件可分析")
            return
        
        # 提取清洗事件数据
        cleaning_events_data = self.data[self.data['timestamp'].isin(self.cleaning_events)].copy()
        cleaning_events_data = cleaning_events_data.sort_values('timestamp')
        cleaning_events_data['cleaning_count'] = range(1, len(cleaning_events_data)+1)
        
        # 计算效果指标
        cleaning_events_data['recoverable_reduction'] = cleaning_events_data['cleaning_effect_recov'] / cleaning_events_data['recoverable']
        cleaning_events_data['semi_reduction'] = cleaning_events_data['cleaning_effect_semi'] / cleaning_events_data['semi_permanent']
        cleaning_events_data['perm_reduction'] = cleaning_events_data['cleaning_effect_perm'] / cleaning_events_data['permanent']
        
        # 计算性能恢复
        performance_recovery = []
        for _, row in cleaning_events_data.iterrows():
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_health = post_clean['health'].max()
                recovery = peak_health - row['health']
                performance_recovery.append(recovery)
            else:
                performance_recovery.append(0)
        cleaning_events_data['performance_recovery'] = performance_recovery
        
        plt.figure(figsize=(14, 8))
        
        # 绘制清洗效果
        ax1 = plt.subplot(211)
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['recoverable_reduction']*100, 
                'o-', color='#a6d96a', label='可恢复')
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['semi_reduction']*100, 
                's-', color='#fdae61', label='半永久')
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['perm_reduction']*100, 
                'd-', color='#d7191c', label='永久')
        
        ax1.set_title('清洗效果随时间变化', fontsize=14)
        ax1.set_xlabel('日期', fontsize=12)
        ax1.set_ylabel('退化减少 (%)', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='upper right', fontsize=10)
        
        # 格式化日期轴
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # 绘制性能恢复
        ax2 = plt.subplot(212)
        ax2.plot(cleaning_events_data['timestamp'], cleaning_events_data['performance_recovery']*100, 
                'o-', color='#1f77b4')
        
        # 添加线性回归
        from scipy.stats import linregress
        x_num = mdates.date2num(cleaning_events_data['timestamp'])
        slope, intercept, r_value, p_value, std_err = linregress(
            x_num, cleaning_events_data['performance_recovery']*100)
        ax2.plot(cleaning_events_data['timestamp'], 
                intercept + slope * x_num, 
                '--', color='#d62728', 
                label=f'趋势: y = {slope:.3f}x + {intercept:.3f}\nR² = {r_value**2:.3f}')
        
        ax2.set_title('清洗后性能恢复', fontsize=14)
        ax2.set_xlabel('日期', fontsize=12)
        ax2.set_ylabel('性能恢复 (%)', fontsize=12)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper right', fontsize=10)
        
        # 格式化日期轴
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3)
        plt.suptitle('清洗效果分析', fontsize=16)
        
        # 保存图片
        plt.savefig(os.path.join(output_path, 'cleaning_effectiveness_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()

# ======================
# 6. 执行模拟和可视化
# ======================
if __name__ == "__main__":
    # 初始化配置
    print("初始化涡轮增压器退化模型...")
    config = DegradationModelConfig()
    
    # 运行模拟
    print("开始模拟...")
    simulator = AdvancedDegradationSimulator(config)
    degradation_data, cleaning_hours = simulator.simulate()
    print(f"模拟完成! 生成 {len(degradation_data)} 小时数据点")
    print(f"清洗事件: {len(cleaning_hours)}")
    
    # 分析结果
    analyzer = CompleteVisualization(degradation_data, cleaning_hours, config)
    
    # 可视化结果
    print("生成综合分析...")
    analyzer.plot_complete_analysis()
    
    # 保存结果
    degradation_data.to_csv(os.path.join(output_path, 'turbine_degradation_data.csv'), index=False)
    print("结果已保存到 'turbine_degradation_data.csv'")
    
    # 打印最终状态
    final_health = degradation_data['health'].iloc[-1]
    print(f"\n4年后健康状态: {final_health:.4f}")
    print(f"总退化量: {1 - final_health:.4f}")

版本2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from matplotlib.gridspec import GridSpec
from scipy.stats import gaussian_kde
import matplotlib.dates as mdates
from matplotlib.colors import LinearSegmentedColormap
import os
import re

# Define save path
output_path = "/mnt/c/Users/think/Desktop/scond"
os.makedirs(output_path, exist_ok=True)

# Set random seed
np.random.seed(42)

# ======================
# 1. Advanced Degradation Model Configuration
# ======================
class DegradationModelConfig:
    def __init__(self):
        # Time parameters (based on engine logs)
        self.start_date = datetime(2015, 3, 14, 1, 0, 0)
        self.end_date = datetime(2019, 1, 14, 23, 59, 0)
        self.total_duration = self.end_date - self.start_date
        self.total_hours = int(self.total_duration.total_seconds() / 3600)
        self.total_days = self.total_hours // 24
        
        # Operating conditions
        self.condition_types = ['Normal', 'High Load', 'High Temp', 'Rough Sea']
        self.condition_probs = [0.65, 0.20, 0.10, 0.05]
        
        # Degradation impact factors
        self.condition_impact = {
            'Normal': 1.0,
            'High Load': 1.8,
            'High Temp': 2.4,
            'Rough Sea': 3.2
        }
        
        # Cleaning parameters
        self.cleaning_effectiveness = {
            'recoverable': 0.95,
            'semi_permanent': 0.60,
            'permanent': 0.05
        }
        self.cleaning_decay = 0.0008
        
        # Degradation model parameters
        # Recoverable degradation
        self.recoverable_rate = {
            'base': 0.00025,
            'noise': 0.00003,
            'shock_prob': 0.00035,
            'shock_severity': [0.008, 0.025],
            'recovery_speed': 0.85
        }
        
        # Semi-permanent degradation
        self.semi_permanent_rate = {
            'base': 0.00008,
            'noise': 0.000012,
            'shock_prob': 0.00025,
            'shock_severity': [0.004, 0.015],
            'recovery_speed': 0.55
        }
        
        # Permanent degradation
        self.permanent_rate = {
            'base': 0.000045,
            'noise': 0.000007,
            'shock_prob': 0.00018,
            'shock_severity': [0.002, 0.008],
            'recovery_speed': 0.15
        }
        
        # Initial health status
        self.initial_health = 1.00
        
        # Performance recovery parameters
        self.recovery_duration = 24
        self.recovery_factor = 1.8

# ======================
# 2. Condition Simulator
# ======================
class ConditionSimulator:
    def __init__(self, config):
        self.config = config
        
    def generate_conditions(self):
        """Generate time-varying operating conditions"""
        condition_sequence = np.random.choice(
            self.config.condition_types,
            size=self.config.total_hours,
            p=self.config.condition_probs
        )
        
        # Ensure continuity of operating conditions
        current_condition = condition_sequence[0]
        condition_duration = 0
        min_duration = 24
        
        for i in range(1, self.config.total_hours):
            condition_duration += 1
            
            if condition_duration >= min_duration:
                if current_condition == 'Rough Sea' and np.random.rand() < 0.3:
                    new_condition = np.random.choice(['Normal', 'High Load'], p=[0.7, 0.3])
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                elif np.random.rand() < 0.08:
                    new_condition = np.random.choice(
                        self.config.condition_types,
                        p=self.config.condition_probs
                    )
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                else:
                    condition_sequence[i] = current_condition
            else:
                condition_sequence[i] = current_condition
        
        return condition_sequence
    
    def get_impact_factor(self, condition):
        """Get degradation impact factor for condition"""
        return self.config.condition_impact[condition]

# ======================
# 3. Cleaning Simulator
# ======================
class CleaningSimulator:
    def __init__(self, config):
        self.config = config
        self.total_days = config.total_days
        self.cleaning_events = self.parse_engine_log()
        
    def parse_engine_log(self):
        """Parse cleaning events from engine log"""
        # Engine log text
        engine_log = """
        2015年3月涡轮清洗时间：2015年3月14号8点，2015年3月24号12点，2015年3月27号12点，2015年3月30号12点
        2015年4月涡轮清洗时间：2015年4月2号13点，2015年4月5号13点，2015年4月8号13点，2015年4月11号13点，2015年4月14号13点，2015年4月17号13点，2015年4月20号13点
        2015年5月涡轮清洗时间：2015年5月19号20点，2015年5月22号18点，2015年5月25号18点，2015年5月31号16点
        2015年6月涡轮清洗时间：2015年6月7号13点，2015年6月10号13点，2015年6月13号13点，2015年6月16号12点，2015年6月19号11点，2015年6月22号12点，2015年6月28号9点
        2015年7月涡轮清洗时间：2015年7月1号9点，2015年7月22号9点，2015年7月25号9点，2015年7月30号10点
        2015年8月涡轮清洗时间：2015年8月23号20点
        2015年9月涡轮清洗时间：2015年9月1号19点，2015年9月4号19点，2015年9月7号19点，2015年9月10号19点，2015年9月13号19点，2015年9月17号5点，2015年9月21号2点，2015年9月25号19点
        2015年10月涡轮清洗时间：2015年10月1号9点，2015年10月4号9点，2015年10月7号9点，2015年10月13号12点，2015年10月25号10点，2015年10月28号10点，2015年10月31号11点
        2015年11月涡轮清洗时间：2015年11月3号13点，2015年11月6号13点，2015年11月9号15点，2015年11月12号14点，2015年11月15号15点，2015年11月18号17点，2015年11月27号18点，2015年11月30号15点
        2015年12月涡轮清洗时间：2015年12月3号16点，2015年12月8号15点，2015年12月11号12点，2015年12月15号15点，2015年12月19号2点，2015年12月21号10点，2015年12月24号10点，2015年12月27号10点，2015年12月30号9点
        
        2016年1月涡轮清洗时间：2016年1月2号9点，2016年1月25号9点，2016年1月28号9点
        2016年2月涡轮清洗时间：2016年2月2号10点，2016年2月5号11点，2016年2月8号10点，2016年2月12号13点，2016年2月15号14点，2016年2月18号15点，2016年2月21号15点，2016年2月24号15点
        2016年3月涡轮清洗时间：2016年3月7号17点，2016年3月10号17点，2016年3月13号18点，2016年3月16号18点，2016年3月19号17点，2016年3月23号15点，2016年3月26号17点，2016年3月29号12点
        2016年4月涡轮清洗时间：2016年4月1号12点，2016年4月4号11点，2016年4月7号11点，2016年4月11号11点，2016年4月14号10点，2016年4月17号9点，2016年4月20号10点
        2016年5月涡轮清洗时间：2016年5月5号9点，2016年5月8号9点，2016年5月11号9点
        2016年6月涡轮清洗时间：2016年6月17号9点，2016年6月20号11点，2016年6月23号12点，2016年6月26号12点，2016年6月29号14点
        2016年7月涡轮清洗时间：2016年7月3号15点，2016年7月6号16点，2016年7月9号17点，2016年7月12号18点，2016年7月16号20点，2016年7月24号19点，2016年7月27号19点，2016年7月30号17点
        2016年8月涡轮清洗时间：2016年8月2号17点，2016年8月5号16点，2016年8月8号14点，2016年8月11号14点，2016年8月14号13点，2016年8月17号12点，2016年8月20号11点，2016年8月23号10点，2016年8月26号10点，2016年8月29号10点
        2016年9月涡轮清洗时间：2016年9月1号9点，2016年9月4号9点，2016年9月13号9点，2016年9月17号9点，2016年9月22号12点，2016年9月25号11点，2016年9月28号11点
        2016年10月涡轮清洗时间：2016年10月1号13点，2016年10月6号15点，2016年10月9号15点，2016年10月12号17点，2016年10月15号16点，2016年10月18号18点，2016年10月21号19点，2016年10月31号19点
        2016年11月涡轮清洗时间：2016年11月3号19点，2016年11月6号19点，2016年11月9号18点，2016年11月12号18点，2016年11月15号17点，2016年11月18号15点，2016年11月21号14点，2016年11月24号13点，2016年11月27号13点，2016年11月30号13点
        2016年12月涡轮清洗时间：2016年12月3号12点，2016年12月6号10点，2016年12月9号10点，2016年12月12号9点，2016年12月15号9点，2016年12月18号9点，2016年12月30号12点
        
        2017年1月涡轮清洗时间：2017年1月4号10点，2017年1月7号10点，2017年1月16号10点，2017年1月19号12点，2017年1月22号12点，2017年1月25号12点，2017年1月28号14点，2017年1月31号15点
        2017年2月涡轮清洗时间：2017年2月3号16点，2017年2月6号16点，2017年2月9号19点，2017年2月12号19点，2017年2月18号20点，2017年2月21号19点，2017年2月24号1点，2017年2月27号16点
        2017年3月涡轮清洗时间：2017年3月2号14点，2017年3月5号14点，2017年3月8号13点，2017年3月11号13点，2017年3月14号12点，2017年3月17号11点，2017年3月20号10点，2017年3月26号10点，2017年3月29号9点
        2017年4月涡轮清洗时间：2017年4月9号14点，2017年4月12号9点，2017年4月9号9点，2017年4月16号11点，2017年4月19号12点，2017年4月22号12点，2017年4月25号13点，2017年4月28号13点
        2017年5月涡轮清洗时间：2017年5月1号14点，2017年5月4号15点，2017年5月9号16点，2017年5月12号16点，2017年5月16号19点，2017年5月19号20点，2017年5月26号20点，2017年5月29号19点
        2017年6月涡轮清洗时间：2017年6月1号18点，2017年6月4号16点，2017年6月7号19点，2017年6月10号16点，2017年6月13号14点，2017年6月16号14点，2017年6月19号12点，2017年6月27号10点
        2017年7月涡轮清洗时间：2017年7月3号10点
        2017年8月涡轮清洗时间：2017年8月20号11点，2017年8月23号12点，2017年8月26号13点，2017年8月29号14点
        2017年9月涡轮清洗时间：2017年9月1号15点，2017年9月4号16点，2017年9月7号17点，2017年9月10号16点，2017年9月3号16点，2017年9月16号20点，2017年9月28号19点
        2017年10月涡轮清洗时间：2017年10月1号19点，2017年10月7号17点，2017年10月10号15点，2017年10月16号14点，2017年10月19号14点，2017年10月22号13点，2017年10月25号11点，2017年10月31号9点
        2017年11月涡轮清洗时间：2017年11月1号9点，2017年11月9号9点
        2017年12月涡轮清洗时间：2017年12月8号9点，2017年12月11号9点，2017年12月17号11点，2017年12月20号11点，2017年12月23号13点，2017年12月26号15点，2017年12月29号15点
        
        2018年1月涡轮清洗时间：2018年1月1号15点，2018年1月4号17点，2018年1月7号18点，2018年1月10号19点，2018年1月19号17点，2018年1月21号19点，2018年1月24号19点，2018年1月27号19点，2018年1月30号17点
        2018年2月涡轮清洗时间：2018年2月2号17点，2018年2月5号15点，2018年2月8号15点，2018年2月11号13点，2018年2月14号12点，2018年2月17号11点，2018年2月20号11点
        2018年3月涡轮清洗时间：2018年3月12号11点，2018年3月15号10点，2018年3月22号11点，2018年3月25号11点，2018年3月27号11点，2018年3月30号14点
        2018年4月涡轮清洗时间：2018年4月2号14点，2018年4月5号15点，2018年4月8号16点，2018年4月11号17点，2018年4月14号18点，2018年4月17号19点
        2018年5月涡轮清洗时间：2018年5月14号19点，2018年5月17号19点，2018年5月20号19点，2018年5月23号17点，2018年5月26号16点，2018年5月29号15点
        2018年6月涡轮清洗时间：2018年6月1号15点，2018年6月4号14点，2018年6月7号13点，2018年6月10号12点，2018年6月13号12点，2018年6月16号10点，2018年6月19号9点，2018年6月22号9点，2018年6月25号9点
        2018年7月涡轮清洗时间：2018年7月13号14点，2018年7月22号18点，2018年7月25号11点，2018年7月28号12点
        2018年8月涡轮清洗时间：2018年8月3号14点，2018年8月6号15点，2018年8月9号16点，2018年8月12号17点，2018年8月15号18点，2018年8月18号19点，2018年8月21号21点
        2018年9月涡轮清洗时间：2018年9月2号19点，2018年9月5号19点，2018年9月8号17点，2018年9月12号16点，2018年9月14号16点，2018年9月17号14点，2018年9月20号13点，2018年9月23号13点，2018年9月26号13点
        2018年10月涡轮清洗时间：2018年10月5号10点，2018年10月8号10点，2018年10月20号9点，2018年10月26号10点，2018年10月29号11点
        2018年11月涡轮清洗时间：2018年11月1号12点，2018年11月4号13点，2018年11月7号14点，2018年11月10号20点，2018年11月13号16点，2018年11月16号17点，2018年11月19号18点，2018年11月22号19点
        2018年12月涡轮清洗时间：2018年12月4号19点，2018年12月7号19点，2018年12月10号19点，2018年12月13号18点，2018年12月16号17点，2018年12月26号14点，2018年12月30号12点
        """
        
        # Parse cleaning events from log
        cleaning_events = []
        pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        
        for match in re.finditer(pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                # Create datetime object
                event_time = datetime(year, month, day, hour)
                # Ensure event is within time range
                if self.config.start_date <= event_time <= self.config.end_date:
                    cleaning_events.append(event_time)
            except ValueError:
                # Skip invalid dates
                continue
        
        # Remove duplicates and sort
        cleaning_events = sorted(set(cleaning_events))
        return cleaning_events
    
    def generate_cleaning_schedule(self):
        """Generate cleaning schedule based on engine log"""
        cleaning_hours = []
        
        for event_time in self.cleaning_events:
            # Calculate hours since start
            hours_from_start = int((event_time - self.config.start_date).total_seconds() / 3600)
            cleaning_hours.append(hours_from_start)
        
        return cleaning_hours
    
    def get_cleaning_effectiveness(self, cleaning_count, deg_type):
        """Calculate cleaning effectiveness"""
        base_effectiveness = self.config.cleaning_effectiveness[deg_type]
        effectiveness = base_effectiveness * (1 - self.config.cleaning_decay * cleaning_count)
        
        min_effect = {
            'recoverable': 0.85,
            'semi_permanent': 0.45,
            'permanent': 0.02
        }
        return max(effectiveness, min_effect[deg_type])

# ======================
# 4. Advanced Degradation Simulator
# ======================
class AdvancedDegradationSimulator:
    def __init__(self, config):
        self.config = config
        self.condition_simulator = ConditionSimulator(config)
        self.cleaning_simulator = CleaningSimulator(config)
        
    def simulate(self):
        """Simulate degradation path (hourly resolution)"""
        # Generate timestamps
        timestamps = [self.config.start_date + timedelta(hours=i) 
                      for i in range(self.config.total_hours)]
        
        # Generate operating conditions
        conditions = self.condition_simulator.generate_conditions()
        
        # Generate cleaning schedule
        cleaning_hours = self.cleaning_simulator.generate_cleaning_schedule()
        cleaning_count = 0
        
        # Initialize degradation path
        health = np.full(self.config.total_hours, self.config.initial_health)
        recoverable = np.zeros(self.config.total_hours)
        semi_permanent = np.zeros(self.config.total_hours)
        permanent = np.zeros(self.config.total_hours)
        
        # Performance recovery state
        recovery_state = np.zeros(self.config.total_hours)
        
        # Cleaning effectiveness record
        cleaning_effects = np.zeros((self.config.total_hours, 3))
        
        # Main simulation loop (hourly resolution)
        for t in range(1, self.config.total_hours):
            # Update recovery state
            if recovery_state[t-1] > 0:
                recovery_state[t] = max(recovery_state[t-1] - 1/self.config.recovery_duration, 0)
            
            # Get condition impact
            condition = conditions[t]
            impact_factor = self.condition_simulator.get_impact_factor(condition)
            
            # Calculate degradation increments
            # 1. Recoverable degradation
            base_rate = self.config.recoverable_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.recoverable_rate['noise'])
            shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                if np.random.rand() < self.config.recoverable_rate['shock_prob'] else 0
            recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
            
            # 2. Semi-permanent degradation
            base_rate = self.config.semi_permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.semi_permanent_rate['noise'])
            shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.semi_permanent_rate['shock_prob'] else 0
            semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # 3. Permanent degradation
            base_rate = self.config.permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.permanent_rate['noise'])
            shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.permanent_rate['shock_prob'] else 0
            permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # Calculate total health
            total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
            health[t] = max(self.config.initial_health - total_degradation, 0.01)
            
            # Apply performance recovery
            if recovery_state[t] > 0:
                recovery_factor = 1 + (self.config.recovery_factor - 1) * recovery_state[t]
                health[t] = min(health[t] * recovery_factor, self.config.initial_health)
            
            # Apply cleaning effectiveness
            if t in cleaning_hours:
                cleaning_count += 1
                recovery_state[t] = 1.0
                
                # Calculate degradation reduction
                recov_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'recoverable')
                semi_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'semi_permanent')
                perm_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'permanent')
                
                # Apply cleaning
                recoverable_reduction = recoverable[t] * recov_effect
                semi_reduction = semi_permanent[t] * semi_effect
                permanent_reduction = permanent[t] * perm_effect
                
                recoverable[t] = max(recoverable[t] - recoverable_reduction, 0)
                semi_permanent[t] = max(semi_permanent[t] - semi_reduction, 0)
                permanent[t] = max(permanent[t] - permanent_reduction, 0)
                
                # Record cleaning effects
                cleaning_effects[t] = [recoverable_reduction, semi_reduction, permanent_reduction]
                
                # Recalculate health
                total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
                health[t] = max(self.config.initial_health - total_degradation, 0.01)
                
                # Apply instant performance boost
                health[t] = min(health[t] * self.config.recovery_factor, self.config.initial_health)
        
        # Create results DataFrame
        results = pd.DataFrame({
            'timestamp': timestamps,
            'health': health,
            'recoverable': recoverable,
            'semi_permanent': semi_permanent,
            'permanent': permanent,
            'condition': conditions,
            'recovery_state': recovery_state,
            'cleaning_effect_recov': cleaning_effects[:, 0],
            'cleaning_effect_semi': cleaning_effects[:, 1],
            'cleaning_effect_perm': cleaning_effects[:, 2],
        })
        
        # Add date information
        results['date'] = results['timestamp'].dt.date
        results['day'] = (results['timestamp'] - results['timestamp'].iloc[0]).dt.days
        results['hour'] = results['timestamp'].dt.hour
        
        return results, cleaning_hours

# ======================
# 5. Complete Visualization
# ======================
class CompleteVisualization:
    def __init__(self, degradation_data, cleaning_hours, config):
        self.data = degradation_data
        self.cleaning_hours = cleaning_hours
        self.config = config
        self.cleaning_events = [self.data['timestamp'].iloc[h] for h in cleaning_hours]
        
        # Create daily data
        self.daily_data = self.data.groupby('date').last().reset_index()
        
        # Mark cleaning dates
        cleaning_dates = self.data.loc[self.data.index.isin(cleaning_hours), 'date'].unique()
        self.daily_data['cleaning_event'] = self.daily_data['date'].isin(cleaning_dates)
        
        # Add year information
        self.daily_data['year'] = self.daily_data['date'].apply(lambda x: x.year)
        
        # Calculate degradation rates
        self._calculate_degradation_rates()
    
    def _calculate_degradation_rates(self):
        """Calculate degradation rates for visualization"""
        # Calculate daily degradation
        self.daily_data['daily_degradation'] = -self.daily_data['health'].diff().fillna(0)
        self.daily_data['degradation_rate'] = self.daily_data['daily_degradation'] * 100  # Percentage
        
        # Calculate cumulative degradation
        self.daily_data['cumulative_degradation'] = 1 - self.daily_data['health']
        
        # Calculate degradation component percentages
        total_degradation = self.daily_data[['recoverable', 'semi_permanent', 'permanent']].sum(axis=1)
        self.daily_data['recoverable_pct'] = self.daily_data['recoverable'] / total_degradation * 100
        self.daily_data['semi_permanent_pct'] = self.daily_data['semi_permanent'] / total_degradation * 100
        self.daily_data['permanent_pct'] = self.daily_data['permanent'] / total_degradation * 100
    
    def plot_complete_analysis(self):
        """Create comprehensive analysis with multiple charts"""
        plt.figure(figsize=(20, 18))
        
        # Create grid layout
        gs = GridSpec(4, 2, height_ratios=[1.2, 1, 1, 1])
        
        # Chart 1: Main health trend (top, full width)
        ax1 = plt.subplot(gs[0, :])
        self._plot_main_health_trend(ax1, title='Health Status Trend and Performance Recovery Peaks')
        
        # Chart 2: Degradation components (middle left)
        ax2 = plt.subplot(gs[1, 0])
        self._plot_degradation_components(ax2, title='Degradation Components Over Time')
        
        # Chart 3: Degradation rate analysis (middle right)
        ax3 = plt.subplot(gs[1, 1])
        self._plot_degradation_rate_analysis(ax3, title='Daily Degradation Rate Analysis')
        
        # Chart 4: Recovery detail (bottom left)
        ax4 = plt.subplot(gs[2, 0])
        self._plot_recovery_detail(ax4, title='Performance Recovery After Cleaning (72 Hours)')
        
        # Chart 5: Degradation composition over time (bottom right)
        ax5 = plt.subplot(gs[2, 1])
        self._plot_degradation_composition(ax5, title='Degradation Composition Over Time')
        
        # Chart 6: Annual health comparison (bottom, full width)
        ax6 = plt.subplot(gs[3, :])
        self._plot_annual_comparison(ax6, title='Annual Health Comparison')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, hspace=0.35)
        plt.suptitle('Turbine Degradation and Recovery Comprehensive Analysis', 
                     fontsize=24, fontweight='bold')
        
        # Save figure
        plt.savefig(os.path.join(output_path, 'complete_turbine_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
        
        # Save individual subplots
        self.save_individual_plots()
        
        # Generate additional detailed charts
        self.plot_detailed_degradation_path()
        self.plot_condition_impact_analysis()
        self.plot_cleaning_effectiveness_analysis()
    
    def save_individual_plots(self):
        """Save all subplots as separate images"""
        # Create subplots directory
        subplot_path = os.path.join(output_path, 'subplots')
        os.makedirs(subplot_path, exist_ok=True)
        
        # 1. Main health trend plot
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_main_health_trend(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'main_health_trend.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Degradation components plot
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_components(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_components.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. Degradation rate analysis plot
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_rate_analysis(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_rate_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. Recovery detail plot
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_recovery_detail(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'recovery_detail.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. Degradation composition plot
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_composition(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_composition.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. Annual comparison plot
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_annual_comparison(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'annual_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_main_health_trend(self, ax, title=None, show_title=True):
        """Plot main health trend with performance recovery markers"""
        # Apply smoothing
        self.daily_data['health_smooth'] = self.daily_data['health'].rolling(window=7, min_periods=1).mean()
        
        # Plot smoothed health trend
        ax.plot(self.daily_data['date'], self.daily_data['health_smooth'], 
                color='#1f77b4', linewidth=2.5, label='Health Status')
        
        # Highlight cleaning events and performance peaks
        cleaning_data = self.data.loc[self.data.index.isin(self.cleaning_hours)]
        peak_values = []
        
        for _, row in cleaning_data.iterrows():
            # Mark cleaning events (vertical line)
            ax.axvline(x=row['timestamp'], color='#ff7f0e', alpha=0.3, linestyle='-', zorder=1)
            
            # Find and mark performance peak
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_idx = post_clean['health'].idxmax()
                peak_row = self.data.loc[peak_idx]
                peak_values.append(peak_row['health'])
                ax.plot(peak_row['timestamp'], peak_row['health'], 
                       'D', markersize=6, color='#d62728', alpha=0.8,
                       markeredgecolor='black', zorder=3, label='Performance Peak')
        
        # Add threshold lines
        ax.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.852, 'Maintenance Threshold', fontsize=12, color='#ff7f0e')
        
        ax.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.752, 'Failure Threshold', fontsize=12, color='#d62728')
        
        # Add year markers
        years = pd.date_range(start=self.config.start_date, end=self.config.end_date, freq='YS')
        for year in years:
            ax.axvline(x=year, color='#2ca02c', linestyle='--', alpha=0.5, zorder=1)
            ax.text(year + timedelta(days=10), 0.72, f'{year.year}', fontsize=11, color='#2ca02c')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Date', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_ylim(0.70, 1.02)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # Add performance recovery statistics
        if peak_values:
            avg_recovery = np.mean([pv - cd for pv, cd in zip(peak_values, cleaning_data['health'])])
            max_recovery = max(peak_values) - min(cleaning_data['health'])
            
            stats_text = f'Average Recovery: {avg_recovery:.3f}\nMax Recovery: {max_recovery:.3f}'
            ax.text(0.98, 0.05, stats_text,
                   transform=ax.transAxes, ha='right', fontsize=11,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
        
        # Create custom legend
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='#1f77b4', lw=2, label='Health Status'),
            Line2D([0], [0], marker='D', color='w', markerfacecolor='#d62728', 
                  markersize=8, markeredgecolor='black', label='Performance Peak'),
            Line2D([0], [0], color='#ff7f0e', linestyle='-', alpha=0.3, label='Cleaning Event'),
        ]
        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)
    
    def _plot_degradation_components(self, ax, title=None, show_title=True):
        """Plot degradation components (using clear colors)"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable'], 
            self.daily_data['semi_permanent'], 
            self.daily_data['permanent'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Cumulative Degradation', fontsize=11)
        ax.set_ylim(0, 0.35)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation composition information
        total_deg = self.daily_data.iloc[-1][['recoverable', 'semi_permanent', 'permanent']].sum()
        if total_deg > 0:
            recov_pct = self.daily_data.iloc[-1]['recoverable'] / total_deg * 100
            semi_pct = self.daily_data.iloc[-1]['semi_permanent'] / total_deg * 100
            perm_pct = self.daily_data.iloc[-1]['permanent'] / total_deg * 100
            
            comp_text = (f'Final Composition:\n'
                         f'Recoverable: {recov_pct:.1f}%\n'
                         f'Semi-permanent: {semi_pct:.1f}%\n'
                         f'Permanent: {perm_pct:.1f}%')
            
            ax.text(0.95, 0.95, comp_text,
                   transform=ax.transAxes, ha='right', va='top', fontsize=10,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_degradation_rate_analysis(self, ax, title=None, show_title=True):
        """Plot degradation rate analysis (with operating conditions)"""
        # Apply smoothing
        self.daily_data['degradation_rate_smooth'] = self.daily_data['degradation_rate'].rolling(window=7, min_periods=1).mean()
        
        # Plot degradation rate
        ax.plot(self.daily_data['date'], self.daily_data['degradation_rate_smooth'], 
                color='#6a3d9a', linewidth=1.8, label='Degradation Rate')
        
        # Highlight high degradation periods
        high_degradation = self.daily_data[self.daily_data['degradation_rate_smooth'] > 
                                          self.daily_data['degradation_rate_smooth'].quantile(0.9)]
        ax.scatter(high_degradation['date'], high_degradation['degradation_rate_smooth'], 
                  color='#e31a1c', s=15, alpha=0.7, label='High Degradation Period')
        
        # Add condition impact markers
        condition_colors = {
            'Normal': '#1f77b4',
            'High Load': '#ff7f0e',
            'High Temp': '#d62728',
            'Rough Sea': '#2ca02c'
        }
        
        # Get daily conditions (aggregate to handle duplicate dates)
        daily_conditions = self.data.groupby('date')['condition'].agg(lambda x: x.value_counts().idxmax()).reset_index()
        daily_conditions.columns = ['date', 'condition_daily']
        
        # Merge with daily data (ensure unique dates)
        self.daily_data = pd.merge(self.daily_data, daily_conditions, on='date', how='left')
        
        # Handle missing values in 'condition_daily'
        if 'condition_daily' not in self.daily_data.columns:
            self.daily_data['condition_daily'] = 'Normal'
        else:
            self.daily_data['condition_daily'] = self.daily_data['condition_daily'].fillna('Normal')
        
        # Add markers for non-normal conditions
        non_normal = self.daily_data[self.daily_data['condition_daily'] != 'Normal']
        for condition, color in condition_colors.items():
            if condition == 'Normal':
                continue
            condition_data = non_normal[non_normal['condition_daily'] == condition]
            ax.scatter(condition_data['date'], condition_data['degradation_rate_smooth'], 
                      color=color, s=25, marker='s', alpha=0.7, label=f'{condition} Condition')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Degradation Rate (%/day)', fontsize=11)
        ax.set_ylim(0, self.daily_data['degradation_rate_smooth'].max() * 1.2)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=8)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation rate statistics
        avg_rate = self.daily_data['degradation_rate_smooth'].mean()
        max_rate = self.daily_data['degradation_rate_smooth'].max()
        
        stats_text = f'Average Rate: {avg_rate:.4f}%/day\nMax Rate: {max_rate:.4f}%/day'
        ax.text(0.95, 0.95, stats_text,
               transform=ax.transAxes, ha='right', fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_recovery_detail(self, ax, title=None, show_title=True):
        """Plot detailed performance recovery after cleaning"""
        if not self.cleaning_events:
            ax.text(0.5, 0.5, 'No Cleaning Events', ha='center', va='center', fontsize=14)
            return
        
        # Select a mid-phase cleaning event
        mid_point = self.config.total_hours // 2
        cleaning_time = min(self.cleaning_events, key=lambda x: abs((x - self.config.start_date).total_seconds()/3600 - mid_point))
        
        # Get data 24 hours before and 48 hours after cleaning
        start_time = cleaning_time - timedelta(hours=24)
        end_time = cleaning_time + timedelta(hours=48)
        recovery_data = self.data[
            (self.data['timestamp'] >= start_time) & 
            (self.data['timestamp'] <= end_time)
        ].copy()
        
        if recovery_data.empty:
            return
        
        # Calculate hours since cleaning
        recovery_data['hours_from_clean'] = (recovery_data['timestamp'] - cleaning_time).dt.total_seconds() / 3600
        
        # Plot health changes
        ax.plot(recovery_data['hours_from_clean'], recovery_data['health'], 
                color='#1f77b4', linewidth=2, label='Health Status')
        
        # Plot degradation components
        ax.plot(recovery_data['hours_from_clean'], recovery_data['recoverable'], 
                color='#a6d96a', linewidth=1.5, linestyle='--', alpha=0.8, label='Recoverable')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['semi_permanent'], 
                color='#fdae61', linewidth=1.5, linestyle='--', alpha=0.8, label='Semi-permanent')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['permanent'], 
                color='#d7191c', linewidth=1.5, linestyle='--', alpha=0.8, label='Permanent')
        
        # Mark cleaning time
        ax.axvline(x=0, color='#ff7f0e', linestyle='-', alpha=0.8, label='Cleaning Event')
        
        # Highlight performance peak
        post_clean = recovery_data[recovery_data['hours_from_clean'] >= 0]
        if not post_clean.empty:
            peak_idx = post_clean['health'].idxmax()
            peak_row = recovery_data.loc[peak_idx]
            ax.plot(peak_row['hours_from_clean'], peak_row['health'], 
                   'D', markersize=8, color='#d62728', alpha=0.8,
                   markeredgecolor='black', label='Performance Peak')
            
            # Add recovery magnitude
            recovery_mag = peak_row['health'] - recovery_data[recovery_data['hours_from_clean'] == 0]['health'].values[0]
            ax.annotate(f'+{recovery_mag:.3f}', 
                       xy=(peak_row['hours_from_clean'], peak_row['health']),
                       xytext=(peak_row['hours_from_clean'], peak_row['health'] + 0.02),
                       ha='center', fontsize=10,
                       arrowprops=dict(arrowstyle='->', color='black'))
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Hours Since Cleaning', fontsize=11)
        ax.set_ylabel('Health Status', fontsize=11)
        ax.set_ylim(recovery_data[['health', 'recoverable', 'semi_permanent', 'permanent']].min().min() - 0.02, 
                   recovery_data['health'].max() + 0.04)
        ax.grid(alpha=0.1)
        ax.legend(loc='lower right', fontsize=8)
        
        # Add recovery period
        ax.axvspan(0, 24, color='#ffffbf', alpha=0.2, label='Recovery Period')
    
    def _plot_degradation_composition(self, ax, title=None, show_title=True):
        """Plot degradation composition over time"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable_pct'], 
            self.daily_data['semi_permanent_pct'], 
            self.daily_data['permanent_pct'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Composition Percentage', fontsize=11)
        ax.set_ylim(0, 100)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add trend lines
        ax.plot(self.daily_data['date'], self.daily_data['recoverable_pct'].rolling(30).mean(), 
               color='#006837', linewidth=2, alpha=0.7)
        ax.plot(self.daily_data['date'], self.daily_data['permanent_pct'].rolling(30).mean(), 
               color='#a50026', linewidth=2, alpha=0.7)
        
        # Add composition change annotations
        initial_recov = self.daily_data['recoverable_pct'].iloc[100]
        final_recov = self.daily_data['recoverable_pct'].iloc[-1]
        initial_perm = self.daily_data['permanent_pct'].iloc[100]
        final_perm = self.daily_data['permanent_pct'].iloc[-1]
        
        ax.text(0.05, 0.15, 
               f"Recoverable: {initial_recov:.1f}% → {final_recov:.1f}%\nPermanent: {initial_perm:.1f}% → {final_perm:.1f}%", 
               transform=ax.transAxes, fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_annual_comparison(self, ax, title=None, show_title=True):
        """Plot annual health comparison"""
        # Calculate annual health statistics
        annual_stats = self.daily_data.groupby('year').agg({
            'health': ['min', 'max', 'mean', 'median'],
            'degradation_rate': ['mean', 'max']
        }).reset_index()
        
        # Set positions
        bar_width = 0.2
        years = annual_stats['year'].unique()
        index = np.arange(len(years))
        
        # Plot bar chart
        ax.bar(index, annual_stats[('health', 'max')], bar_width, 
              color='#2ca02c', label='Annual Peak')
        ax.bar(index + bar_width, annual_stats[('health', 'mean')], bar_width, 
              color='#1f77b4', label='Annual Mean')
        ax.bar(index + bar_width*2, annual_stats[('health', 'median')], bar_width, 
              color='#ff7f0e', label='Annual Median')
        ax.bar(index + bar_width*3, annual_stats[('health', 'min')], bar_width, 
              color='#d62728', label='Annual Trough')
        
        # Connect peaks and troughs
        for i, year in enumerate(years):
            ax.plot([i + bar_width/2, i + bar_width*3.5], 
                   [annual_stats.loc[i, ('health', 'max')], 
                   annual_stats.loc[i, ('health', 'min')]], 
                   color='#7f7f7f', linestyle='-', alpha=0.3)
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Year', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_xticks(index + bar_width*1.5)
        ax.set_xticklabels([f'{year}' for year in years])
        ax.set_ylim(0.70, 1.02)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=10)
        
        # Add value labels
        for i, year in enumerate(years):
            ax.text(i + bar_width*0.5, annual_stats.loc[i, ('health', 'max')] + 0.005, 
                   f'{annual_stats.loc[i, ("health", "max")]:.3f}', 
                   ha='center', fontsize=9)
            ax.text(i + bar_width*3.5, annual_stats.loc[i, ('health', 'min')] - 0.01, 
                   f'{annual_stats.loc[i, ("health", "min")]:.3f}', 
                   ha='center', fontsize=9, va='top')
        
        # Add degradation trend
        degradation_trend = [1 - annual_stats.loc[i, ('health', 'mean')] for i in range(len(years))]
        ax2 = ax.twinx()
        ax2.plot(index + bar_width*1.5, degradation_trend, 
                'o-', color='#9467bd', linewidth=2, markersize=8, 
                label='Average Degradation Level')
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, 0.35)
        ax2.legend(loc='upper left', fontsize=10)
        
        # Add degradation rate trend
        ax3 = ax.twinx()
        ax3.spines['right'].set_position(('outward', 60))
        ax3.plot(index + bar_width*1.5, annual_stats[('degradation_rate', 'mean')], 
                's--', color='#e377c2', linewidth=2, markersize=8, 
                label='Average Degradation Rate')
        ax3.set_ylabel('Degradation Rate (%/day)', fontsize=12)
        ax3.set_ylim(0, annual_stats[('degradation_rate', 'mean')].max() * 1.5)
        ax3.legend(loc='upper right', fontsize=10)
    
    def plot_detailed_degradation_path(self):
        """Plot detailed degradation path (hourly resolution)"""
        plt.figure(figsize=(15, 10))
        
        # Create grid layout
        gs = GridSpec(2, 1, height_ratios=[2, 1])
        
        # Chart 1: Health status with cleaning events
        ax1 = plt.subplot(gs[0])
        ax1.plot(self.data['timestamp'], self.data['health'], 
                color='#1f77b4', alpha=0.6, linewidth=0.8, label='Hourly Health')
        
        # Add daily average
        daily_health = self.data.groupby('date')['health'].mean()
        ax1.plot(daily_health.index, daily_health, 
                color='#2c7bb6', linewidth=2, label='Daily Average Health')
        
        # Highlight cleaning events
        for event in self.cleaning_events:
            ax1.axvline(x=event, color='#ff7f0e', alpha=0.4, linestyle='-')
        
        # Add thresholds
        ax1.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8)
        
        # Set properties
        ax1.set_title('Detailed Degradation Path (Hourly Resolution)', fontsize=16)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Health Status', fontsize=12)
        ax1.set_ylim(0.70, 1.02)
        ax1.set_xlim(self.config.start_date, self.config.end_date)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='lower left', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Chart 2: Degradation components
        ax2 = plt.subplot(gs[1])
        ax2.plot(self.data['timestamp'], self.data['recoverable'], 
                color='#a6d96a', linewidth=1, alpha=0.7, label='Recoverable')
        ax2.plot(self.data['timestamp'], self.data['semi_permanent'], 
                color='#fdae61', linewidth=1, alpha=0.7, label='Semi-permanent')
        ax2.plot(self.data['timestamp'], self.data['permanent'], 
                color='#d7191c', linewidth=1, alpha=0.7, label='Permanent')
        
        # Set properties
        ax2.set_title('Degradation Components (Hourly Data)', fontsize=14)
        ax2.set_xlabel('Date', fontsize=12)
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, self.data[['recoverable', 'semi_permanent', 'permanent']].max().max() * 1.1)
        ax2.set_xlim(self.config.start_date, self.config.end_date)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.25)
        
        # Save figure
        plt.savefig(os.path.join(output_path, 'detailed_degradation_path.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_condition_impact_analysis(self):
        """Plot condition impact analysis"""
        # Calculate degradation rates per condition
        condition_degradation = self.data.groupby('condition').agg({
            'health': 'mean',
            'recoverable': 'mean',
            'semi_permanent': 'mean',
            'permanent': 'mean'
        })
        
        condition_degradation['total_degradation'] = 1 - condition_degradation['health']
        
        # Calculate degradation rates per condition
        condition_rates = self.data.copy()
        condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
        condition_rates = condition_rates.groupby('condition')['degradation'].agg(['mean', 'std'])
        
        plt.figure(figsize=(14, 6))
        
        # Chart 1: Degradation levels per condition
        ax1 = plt.subplot(121)
        condition_degradation[['recoverable', 'semi_permanent', 'permanent']].plot.bar(
            stacked=True, ax=ax1, color=['#a6d96a', '#fdae61', '#d7191c'], alpha=0.85)
        
        ax1.set_title('Degradation Levels by Operating Condition', fontsize=14)
        ax1.set_xlabel('Operating Condition', fontsize=12)
        ax1.set_ylabel('Average Degradation', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(title='Degradation Type', fontsize=9)
        
        # Chart 2: Degradation rates per condition
        ax2 = plt.subplot(122)
        condition_rates['mean'].plot.bar(yerr=condition_rates['std'], 
                                       ax=ax2, color='#6a3d9a', alpha=0.7)
        
        ax2.set_title('Degradation Rates by Operating Condition', fontsize=14)
        ax2.set_xlabel('Operating Condition', fontsize=12)
        ax2.set_ylabel('Average Degradation Rate', fontsize=12)
        ax2.grid(alpha=0.1)
        
        # Add condition impact factors
        for i, condition in enumerate(condition_rates.index):
            impact = self.config.condition_impact[condition]
            ax2.text(i, condition_rates['mean'].iloc[i] + 0.0001, 
                    f'Impact: {impact}x', ha='center', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.88)
        plt.suptitle('Operating Condition Impact Analysis', fontsize=16)
        
        # Save figure
        plt.savefig(os.path.join(output_path, 'condition_impact_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_cleaning_effectiveness_analysis(self):
        """Plot cleaning effectiveness analysis over time"""
        if not self.cleaning_events:
            print("No cleaning events to analyze")
            return
        
        # Extract cleaning event data
        cleaning_events_data = self.data[self.data['timestamp'].isin(self.cleaning_events)].copy()
        cleaning_events_data = cleaning_events_data.sort_values('timestamp')
        cleaning_events_data['cleaning_count'] = range(1, len(cleaning_events_data)+1)
        
        # Calculate effectiveness metrics
        cleaning_events_data['recoverable_recovery'] = cleaning_events_data['cleaning_effect_recov'] / cleaning_events_data['recoverable']
        cleaning_events_data['semi_recovery'] = cleaning_events_data['cleaning_effect_semi'] / cleaning_events_data['semi_permanent']
        cleaning_events_data['perm_recovery'] = cleaning_events_data['cleaning_effect_perm'] / cleaning_events_data['permanent']
        
        # Calculate performance recovery
        performance_recovery = []
        for _, row in cleaning_events_data.iterrows():
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_health = post_clean['health'].max()
                recovery = peak_health - row['health']
                performance_recovery.append(recovery)
            else:
                performance_recovery.append(0)
        cleaning_events_data['performance_recovery'] = performance_recovery
        
        plt.figure(figsize=(14, 8))
        
        # Chart 1: Cleaning effectiveness over time
        ax1 = plt.subplot(211)
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['recoverable_recovery']*100, 
                'o-', color='#a6d96a', label='Recoverable')
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['semi_recovery']*100, 
                's-', color='#fdae61', label='Semi-permanent')
        ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['perm_recovery']*100, 
                'd-', color='#d7191c', label='Permanent')
        
        ax1.set_title('Cleaning Effectiveness Over Time', fontsize=14)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Degradation Reduction (%)', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='upper right', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Chart 2: Performance recovery after cleaning
        ax2 = plt.subplot(212)
        ax2.plot(cleaning_events_data['timestamp'], cleaning_events_data['performance_recovery']*100, 
                'o-', color='#1f77b4')
        
        # Add linear regression trend
        from scipy.stats import linregress
        x_num = mdates.date2num(cleaning_events_data['timestamp'])
        slope, intercept, r_value, p_value, std_err = linregress(
            x_num, cleaning_events_data['performance_recovery']*100)
        ax2.plot(cleaning_events_data['timestamp'], 
                intercept + slope * x_num, 
                '--', color='#d62728', 
                label=f'Trend: y = {slope:.3f}x + {intercept:.3f}\nR² = {r_value**2:.3f}')
        
        ax2.set_title('Performance Recovery After Cleaning', fontsize=14)
        ax2.set_xlabel('Date', fontsize=12)
        ax2.set_ylabel('Performance Recovery (%)', fontsize=12)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper right', fontsize=10)
        
        # Format date axis
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3)
        plt.suptitle('Cleaning Effectiveness Analysis', fontsize=16)
        
        # Save figure
        plt.savefig(os.path.join(output_path, 'cleaning_effectiveness_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()

# ======================
# 6. Execute Simulation and Visualization
# ======================
if __name__ == "__main__":
    # Initialize degradation model
    print("Initializing turbine degradation model...")
    config = DegradationModelConfig()
    
    # Run simulation
    print("Starting simulation...")
    simulator = AdvancedDegradationSimulator(config)
    degradation_data, cleaning_hours = simulator.simulate()
    print(f"Simulation complete! Generated {len(degradation_data)} hourly data points")
    print(f"Cleaning events: {len(cleaning_hours)}")
    
    # Analyze results
    analyzer = CompleteVisualization(degradation_data, cleaning_hours, config)
    
    # Generate visualizations
    print("Generating comprehensive analysis...")
    analyzer.plot_complete_analysis()
    
    # Save results
    degradation_data.to_csv(os.path.join(output_path, 'turbine_degradation_data.csv'), index=False)
    print("Results saved to 'turbine_degradation_data.csv'")
    
    # Print final status
    final_health = degradation_data['health'].iloc[-1]
    print(f"\nFinal health status after 4 years: {final_health:.4f}")

版本3
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from matplotlib.gridspec import GridSpec
from scipy.stats import gaussian_kde
import matplotlib.dates as mdates
from matplotlib.colors import LinearSegmentedColormap
import os

# 定义保存路径（注意在 WSL 中需要使用 /mnt/c/... 格式）
output_path = "/mnt/c/Users/think/Desktop/scond"

# 确保目录存在
os.makedirs(output_path, exist_ok=True)

# Set random seed for reproducibility
np.random.seed(42)

# ======================
# 1. Advanced Degradation Model Configuration
# ======================
class DegradationModelConfig:
    def __init__(self):
        # Time parameters
        self.start_date = datetime(2023, 1, 1)
        self.years = 4
        self.days = self.years * 365
        self.hours_per_day = 24
        self.total_hours = self.days * self.hours_per_day
        
        # Operating conditions
        self.condition_types = ['Normal', 'High Load', 'High Temp', 'Rough Sea']
        self.condition_probs = [0.65, 0.20, 0.10, 0.05]
        
        # Degradation impact factors
        self.condition_impact = {
            'Normal': 1.0,
            'High Load': 1.8,
            'High Temp': 2.4,
            'Rough Sea': 3.2
        }
        
        # Cleaning parameters
        self.cleaning_interval = 3  # Clean every 3 days
        self.cleaning_effectiveness = {
            'recoverable': 0.95,
            'semi_permanent': 0.60,
            'permanent': 0.05
        }
        self.cleaning_decay = 0.0008
        
        # Degradation model parameters
        # Recoverable degradation
        self.recoverable_rate = {
            'base': 0.00025,
            'noise': 0.00003,
            'shock_prob': 0.00035,
            'shock_severity': [0.008, 0.025],
            'recovery_speed': 0.85
        }
        
        # Semi-permanent degradation
        self.semi_permanent_rate = {
            'base': 0.00008,
            'noise': 0.000012,
            'shock_prob': 0.00025,
            'shock_severity': [0.004, 0.015],
            'recovery_speed': 0.55
        }
        
        # Permanent degradation
        self.permanent_rate = {
            'base': 0.000045,
            'noise': 0.000007,
            'shock_prob': 0.00018,
            'shock_severity': [0.002, 0.008],
            'recovery_speed': 0.15
        }
        
        # Initial health state
        self.initial_health = 1.00
        
        # Performance recovery parameters
        self.recovery_duration = 24
        self.recovery_factor = 1.8

# ======================
# 2. Operating Condition Simulator
# ======================
class ConditionSimulator:
    def __init__(self, config):
        self.config = config
        
    def generate_conditions(self):
        """Generate time-varying operating conditions"""
        condition_sequence = np.random.choice(
            self.config.condition_types,
            size=self.config.total_hours,
            p=self.config.condition_probs
        )
        
        # Ensure operating condition continuity
        current_condition = condition_sequence[0]
        condition_duration = 0
        min_duration = 24
        
        for i in range(1, self.config.total_hours):
            condition_duration += 1
            
            if condition_duration >= min_duration:
                if current_condition == 'Rough Sea' and np.random.rand() < 0.3:
                    new_condition = np.random.choice(['Normal', 'High Load'], p=[0.7, 0.3])
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                elif np.random.rand() < 0.08:
                    new_condition = np.random.choice(
                        self.config.condition_types,
                        p=self.config.condition_probs
                    )
                    condition_sequence[i] = new_condition
                    current_condition = new_condition
                    condition_duration = 0
                else:
                    condition_sequence[i] = current_condition
            else:
                condition_sequence[i] = current_condition
        
        return condition_sequence
    
    def get_impact_factor(self, condition):
        """Get degradation impact factor for condition"""
        return self.config.condition_impact[condition]

# ======================
# 3. Cleaning Event Simulator
# ======================
class CleaningSimulator:
    def __init__(self, config):
        self.config = config
        self.total_days = config.days
        
    def generate_cleaning_schedule(self):
        """Generate cleaning schedule"""
        cleaning_days = []
        current_day = self.config.cleaning_interval
        
        while current_day <= self.total_days:
            offset = np.random.uniform(-0.5, 0.5)
            cleaning_days.append(current_day + offset)
            current_day += self.config.cleaning_interval
        
        return cleaning_days
    
    def get_cleaning_effectiveness(self, cleaning_count, deg_type):
        """Calculate cleaning effectiveness"""
        base_effectiveness = self.config.cleaning_effectiveness[deg_type]
        effectiveness = base_effectiveness * (1 - self.config.cleaning_decay * cleaning_count)
        
        min_effect = {
            'recoverable': 0.85,
            'semi_permanent': 0.45,
            'permanent': 0.02
        }
        return max(effectiveness, min_effect[deg_type])

# ======================
# 4. Degradation Path Simulator with Performance Recovery
# ======================
class AdvancedDegradationSimulator:
    def __init__(self, config):
        self.config = config
        self.condition_simulator = ConditionSimulator(config)
        self.cleaning_simulator = CleaningSimulator(config)
        
    def simulate(self):
        """Simulate degradation path with performance recovery (hourly resolution)"""
        # Generate timestamps
        timestamps = [self.config.start_date + timedelta(hours=i) 
                      for i in range(self.config.total_hours)]
        
        # Generate operating conditions
        conditions = self.condition_simulator.generate_conditions()
        
        # Generate cleaning schedule
        cleaning_days = self.cleaning_simulator.generate_cleaning_schedule()
        cleaning_hours = [int(day * self.config.hours_per_day) for day in cleaning_days]
        cleaning_count = 0
        
        # Initialize degradation paths
        health = np.full(self.config.total_hours, self.config.initial_health)
        recoverable = np.zeros(self.config.total_hours)
        semi_permanent = np.zeros(self.config.total_hours)
        permanent = np.zeros(self.config.total_hours)
        
        # Performance recovery state
        recovery_state = np.zeros(self.config.total_hours)
        
        # Cleaning effects record
        cleaning_effects = np.zeros((self.config.total_hours, 3))
        
        # Main simulation loop (hourly resolution)
        for t in range(1, self.config.total_hours):
            # Update recovery state
            if recovery_state[t-1] > 0:
                recovery_state[t] = max(recovery_state[t-1] - 1/self.config.recovery_duration, 0)
            
            # Get condition impact
            condition = conditions[t]
            impact_factor = self.condition_simulator.get_impact_factor(condition)
            
            # Calculate degradation increments
            # 1. Recoverable degradation
            base_rate = self.config.recoverable_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.recoverable_rate['noise'])
            shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                if np.random.rand() < self.config.recoverable_rate['shock_prob'] else 0
            recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
            
            # 2. Semi-permanent degradation
            base_rate = self.config.semi_permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.semi_permanent_rate['noise'])
            shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.semi_permanent_rate['shock_prob'] else 0
            semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # 3. Permanent degradation
            base_rate = self.config.permanent_rate['base'] * impact_factor
            noise = np.random.normal(0, self.config.permanent_rate['noise'])
            shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                if np.random.rand() < self.config.permanent_rate['shock_prob'] else 0
            permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
            
            # Calculate total health
            total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
            health[t] = max(self.config.initial_health - total_degradation, 0.01)
            
            # Apply performance recovery
            if recovery_state[t] > 0:
                recovery_factor = 1 + (self.config.recovery_factor - 1) * recovery_state[t]
                health[t] = min(health[t] * recovery_factor, self.config.initial_health)
            
            # Apply cleaning effects
            if t in cleaning_hours:
                cleaning_count += 1
                recovery_state[t] = 1.0
                
                # Calculate degradation removal
                recov_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'recoverable')
                semi_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'semi_permanent')
                perm_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'permanent')
                
                # Apply cleaning
                recoverable_reduction = recoverable[t] * recov_effect
                semi_reduction = semi_permanent[t] * semi_effect
                permanent_reduction = permanent[t] * perm_effect
                
                recoverable[t] = max(recoverable[t] - recoverable_reduction, 0)
                semi_permanent[t] = max(semi_permanent[t] - semi_reduction, 0)
                permanent[t] = max(permanent[t] - permanent_reduction, 0)
                
                # Record cleaning effects
                cleaning_effects[t] = [recoverable_reduction, semi_reduction, permanent_reduction]
                
                # Recalculate health
                total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
                health[t] = max(self.config.initial_health - total_degradation, 0.01)
                
                # Apply immediate performance boost
                health[t] = min(health[t] * self.config.recovery_factor, self.config.initial_health)
        
        # Create results DataFrame
        results = pd.DataFrame({
            'timestamp': timestamps,
            'health': health,
            'recoverable': recoverable,
            'semi_permanent': semi_permanent,
            'permanent': permanent,
            'condition': conditions,
            'recovery_state': recovery_state,
            'cleaning_effect_recov': cleaning_effects[:, 0],
            'cleaning_effect_semi': cleaning_effects[:, 1],
            'cleaning_effect_perm': cleaning_effects[:, 2],
        })
        
        # Add date information
        results['date'] = results['timestamp'].dt.date
        results['day'] = (results['timestamp'] - results['timestamp'].iloc[0]).dt.days
        results['hour'] = results['timestamp'].dt.hour
        
        return results, cleaning_hours

# ======================
# 5. Complete Visualization with Additional Plots
# ======================
class CompleteVisualization:
    def __init__(self, degradation_data, cleaning_hours, config):
        self.data = degradation_data
        self.cleaning_hours = cleaning_hours
        self.config = config
        
        # Create daily data
        self.daily_data = self.data.groupby('date').last().reset_index()
        
        # Mark cleaning dates
        cleaning_dates = self.data.loc[self.data.index.isin(cleaning_hours), 'date'].unique()
        self.daily_data['cleaning_event'] = self.daily_data['date'].isin(cleaning_dates)
        
        # Add year information
        self.daily_data['year'] = (self.daily_data['day'] // 365) + 1
        
        # Calculate degradation rates
        self._calculate_degradation_rates()
    
    def _calculate_degradation_rates(self):
        """Calculate degradation rates for visualization"""
        # Calculate daily degradation
        self.daily_data['daily_degradation'] = -self.daily_data['health'].diff().fillna(0)
        self.daily_data['degradation_rate'] = self.daily_data['daily_degradation'] * 100  # as percentage
        
        # Calculate cumulative degradation
        self.daily_data['cumulative_degradation'] = 1 - self.daily_data['health']
        
        # Calculate degradation component percentages
        total_degradation = self.daily_data[['recoverable', 'semi_permanent', 'permanent']].sum(axis=1)
        self.daily_data['recoverable_pct'] = self.daily_data['recoverable'] / total_degradation * 100
        self.daily_data['semi_permanent_pct'] = self.daily_data['semi_permanent'] / total_degradation * 100
        self.daily_data['permanent_pct'] = self.daily_data['permanent'] / total_degradation * 100
    
    def plot_complete_analysis(self):
        """Create comprehensive analysis with multiple plots"""
        plt.figure(figsize=(20, 18))
        
        # Create grid layout
        gs = GridSpec(4, 2, height_ratios=[1.2, 1, 1, 1])
        
        # Plot 1: Main Health Trend (top, full width)
        ax1 = plt.subplot(gs[0, :])
        self._plot_main_health_trend(ax1)
        
        # Plot 2: Degradation Components (middle left)
        ax2 = plt.subplot(gs[1, 0])
        self._plot_degradation_components(ax2)
        
        # Plot 3: Degradation Rate Analysis (middle right)
        ax3 = plt.subplot(gs[1, 1])
        self._plot_degradation_rate_analysis(ax3)
        
        # Plot 4: Performance Recovery Detail (bottom left)
        ax4 = plt.subplot(gs[2, 0])
        self._plot_recovery_detail(ax4)
        
        # Plot 5: Degradation Composition Over Time (bottom right)
        ax5 = plt.subplot(gs[2, 1])
        self._plot_degradation_composition(ax5)
        
        # Plot 6: Annual Health Comparison (bottom, full width)
        ax6 = plt.subplot(gs[3, :])
        self._plot_annual_comparison(ax6)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, hspace=0.35)
        plt.suptitle('Comprehensive Turbocharger Degradation and Recovery Analysis', 
                     fontsize=24, fontweight='bold')
        plt.savefig(os.path.join(output_path, 'complete_turbine_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # Generate additional detailed plots
        self.plot_detailed_degradation_path()
        self.plot_condition_impact_analysis()
        self.plot_cleaning_effectiveness_analysis()
    
    def _plot_main_health_trend(self, ax):
        """Plot main health trend with performance recovery markers"""
        # Apply smoothing for cleaner visualization
        self.daily_data['health_smooth'] = self.daily_data['health'].rolling(window=7, min_periods=1).mean()
        
        # Plot smoothed health trend
        ax.plot(self.daily_data['day'], self.daily_data['health_smooth'], 
                color='#1f77b4', linewidth=2.5, label='Health Status')
        
        # Highlight cleaning events and performance peaks
        cleaning_data = self.data.loc[self.data.index.isin(self.cleaning_hours)]
        peak_values = []
        
        for _, row in cleaning_data.iterrows():
            # Mark cleaning event with vertical line
            ax.axvline(x=row['day'], color='#ff7f0e', alpha=0.3, linestyle='-', zorder=1)
            
            # Find and mark performance peak
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_idx = post_clean['health'].idxmax()
                peak_row = self.data.loc[peak_idx]
                peak_values.append(peak_row['health'])
                ax.plot(peak_row['day'], peak_row['health'], 
                       'D', markersize=6, color='#d62728', alpha=0.8,
                       markeredgecolor='black', zorder=3, label='Performance Peak')
        
        # Add thresholds
        ax.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8, zorder=2)
        ax.text(50, 0.852, 'Maintenance Threshold', fontsize=12, color='#ff7f0e')
        
        ax.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8, zorder=2)
        ax.text(50, 0.752, 'Failure Threshold', fontsize=12, color='#d62728')
        
        # Add year markers
        for year in range(1, 5):
            day = year * 365
            ax.axvline(x=day, color='#2ca02c', linestyle='--', alpha=0.5, zorder=1)
            ax.text(day + 10, 0.72, f'Year {year}', fontsize=11, color='#2ca02c')
        
        # Set properties
        ax.set_title('Health Status Trend with Performance Recovery Peaks', fontsize=16)
        ax.set_xlabel('Operating Days', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_ylim(0.70, 1.02)
        ax.set_xlim(0, self.daily_data['day'].max())
        ax.grid(alpha=0.1)
        
        # Add performance recovery statistics
        if peak_values:
            avg_recovery = np.mean([pv - cd for pv, cd in zip(peak_values, cleaning_data['health'])])
            max_recovery = max(peak_values) - min(cleaning_data['health'])
            
            stats_text = f'Average Recovery: {avg_recovery:.3f}\nMax Recovery: {max_recovery:.3f}'
            ax.text(0.98, 0.05, stats_text,
                   transform=ax.transAxes, ha='right', fontsize=11,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
        
        # Create custom legend
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='#1f77b4', lw=2, label='Health Status'),
            Line2D([0], [0], marker='D', color='w', markerfacecolor='#d62728', 
                  markersize=8, markeredgecolor='black', label='Performance Peak'),
            Line2D([0], [0], color='#ff7f0e', linestyle='-', alpha=0.3, label='Cleaning Event'),
        ]
        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)
    
    def _plot_degradation_components(self, ax):
        """Plot degradation components with clear color scheme"""
        # Plot stacked area
        ax.stackplot(
            self.daily_data['day'], 
            self.daily_data['recoverable'], 
            self.daily_data['semi_permanent'], 
            self.daily_data['permanent'],
            labels=['Recoverable', 'Semi-Permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        ax.set_title('Degradation Components Over Time', fontsize=14)
        ax.set_xlabel('Operating Days', fontsize=11)
        ax.set_ylabel('Cumulative Degradation', fontsize=11)
        ax.set_ylim(0, 0.35)
        ax.set_xlim(0, self.daily_data['day'].max())
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Add degradation composition info
        total_deg = self.daily_data.iloc[-1][['recoverable', 'semi_permanent', 'permanent']].sum()
        if total_deg > 0:
            recov_pct = self.daily_data.iloc[-1]['recoverable'] / total_deg * 100
            semi_pct = self.daily_data.iloc[-1]['semi_permanent'] / total_deg * 100
            perm_pct = self.daily_data.iloc[-1]['permanent'] / total_deg * 100
            
            comp_text = (f'Final Composition:\n'
                         f'Recoverable: {recov_pct:.1f}%\n'
                         f'Semi-Permanent: {semi_pct:.1f}%\n'
                         f'Permanent: {perm_pct:.1f}%')
            
            ax.text(0.95, 0.95, comp_text,
                   transform=ax.transAxes, ha='right', va='top', fontsize=10,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_degradation_rate_analysis(self, ax):
        """Plot degradation rate analysis with operating conditions"""
        # Apply smoothing
        self.daily_data['degradation_rate_smooth'] = self.daily_data['degradation_rate'].rolling(window=7, min_periods=1).mean()
        
        # Plot degradation rate
        ax.plot(self.daily_data['day'], self.daily_data['degradation_rate_smooth'], 
                color='#6a3d9a', linewidth=1.8, label='Degradation Rate')
        
        # Highlight high degradation periods
        high_degradation = self.daily_data[self.daily_data['degradation_rate_smooth'] > 
                                          self.daily_data['degradation_rate_smooth'].quantile(0.9)]
        ax.scatter(high_degradation['day'], high_degradation['degradation_rate_smooth'], 
                  color='#e31a1c', s=15, alpha=0.7, label='High Degradation')
        
        # Add condition impact markers
        condition_colors = {
            'Normal': '#1f77b4',
            'High Load': '#ff7f0e',
            'High Temp': '#d62728',
            'Rough Sea': '#2ca02c'
        }
        
        # Get condition for each day
        daily_conditions = self.data.groupby('date')['condition'].agg(lambda x: x.value_counts().idxmax())
        self.daily_data = self.daily_data.merge(daily_conditions, on='date', suffixes=('', '_daily'))
        
        # Add markers for non-normal conditions
        non_normal = self.daily_data[self.daily_data['condition_daily'] != 'Normal']
        for condition, color in condition_colors.items():
            if condition == 'Normal':
                continue
            condition_data = non_normal[non_normal['condition_daily'] == condition]
            ax.scatter(condition_data['day'], condition_data['degradation_rate_smooth'], 
                      color=color, s=25, marker='s', alpha=0.7, label=f'{condition} Condition')
        
        # Set properties
        ax.set_title('Daily Degradation Rate Analysis', fontsize=14)
        ax.set_xlabel('Operating Days', fontsize=11)
        ax.set_ylabel('Degradation Rate (% per day)', fontsize=11)
        ax.set_ylim(0, self.daily_data['degradation_rate_smooth'].max() * 1.2)
        ax.set_xlim(0, self.daily_data['day'].max())
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=8)
        
        # Add degradation rate statistics
        avg_rate = self.daily_data['degradation_rate_smooth'].mean()
        max_rate = self.daily_data['degradation_rate_smooth'].max()
        
        stats_text = f'Avg Rate: {avg_rate:.4f}%/day\nMax Rate: {max_rate:.4f}%/day'
        ax.text(0.95, 0.95, stats_text,
               transform=ax.transAxes, ha='right', fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_recovery_detail(self, ax):
        """Plot detailed performance recovery after a cleaning event"""
        if not self.cleaning_hours:
            ax.text(0.5, 0.5, 'No Cleaning Events', ha='center', va='center', fontsize=14)
            return
        
        # Select a mid-life cleaning event
        mid_point = self.config.total_hours // 2
        cleaning_idx = min(self.cleaning_hours, key=lambda x: abs(x - mid_point))
        
        # Get 72-hour window around cleaning event
        start_hour = max(0, cleaning_idx - 24)
        end_hour = min(self.config.total_hours, cleaning_idx + 48)
        recovery_data = self.data.iloc[start_hour:end_hour].copy()
        recovery_data['hours_from_clean'] = np.arange(-24, 48) if len(recovery_data) == 72 else np.arange(-24, len(recovery_data)-24)
        
        # Plot health change
        ax.plot(recovery_data['hours_from_clean'], recovery_data['health'], 
                color='#1f77b4', linewidth=2, label='Health Status')
        
        # Plot degradation components
        ax.plot(recovery_data['hours_from_clean'], recovery_data['recoverable'], 
                color='#a6d96a', linewidth=1.5, linestyle='--', alpha=0.8, label='Recoverable')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['semi_permanent'], 
                color='#fdae61', linewidth=1.5, linestyle='--', alpha=0.8, label='Semi-Permanent')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['permanent'], 
                color='#d7191c', linewidth=1.5, linestyle='--', alpha=0.8, label='Permanent')
        
        # Mark cleaning time
        ax.axvline(x=0, color='#ff7f0e', linestyle='-', alpha=0.8, label='Cleaning Event')
        
        # Highlight performance peak
        post_clean = recovery_data[recovery_data['hours_from_clean'] >= 0]
        if not post_clean.empty:
            peak_idx = post_clean['health'].idxmax()
            peak_row = recovery_data.loc[peak_idx]
            ax.plot(peak_row['hours_from_clean'], peak_row['health'], 
                   'D', markersize=8, color='#d62728', alpha=0.8,
                   markeredgecolor='black', label='Performance Peak')
            
            # Add recovery magnitude
            recovery_mag = peak_row['health'] - recovery_data.loc[cleaning_idx]['health']
            ax.annotate(f'+{recovery_mag:.3f}', 
                       xy=(peak_row['hours_from_clean'], peak_row['health']),
                       xytext=(peak_row['hours_from_clean'], peak_row['health'] + 0.02),
                       ha='center', fontsize=10,
                       arrowprops=dict(arrowstyle='->', color='black'))
        
        # Set properties
        ax.set_title('Performance Recovery After Cleaning (72 Hours)', fontsize=14)
        ax.set_xlabel('Hours from Cleaning Event', fontsize=11)
        ax.set_ylabel('Health Status', fontsize=11)
        ax.set_ylim(recovery_data[['health', 'recoverable', 'semi_permanent', 'permanent']].min().min() - 0.02, 
                   recovery_data['health'].max() + 0.04)
        ax.grid(alpha=0.1)
        ax.legend(loc='lower right', fontsize=8)
        
        # Add recovery duration
        ax.axvspan(0, 24, color='#ffffbf', alpha=0.2, label='Recovery Period')
    
    def _plot_degradation_composition(self, ax):
        """Plot degradation composition over time"""
        # Plot stacked area of percentages
        ax.stackplot(
            self.daily_data['day'], 
            self.daily_data['recoverable_pct'], 
            self.daily_data['semi_permanent_pct'], 
            self.daily_data['permanent_pct'],
            labels=['Recoverable', 'Semi-Permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        ax.set_title('Degradation Composition Over Time', fontsize=14)
        ax.set_xlabel('Operating Days', fontsize=11)
        ax.set_ylabel('Composition Percentage', fontsize=11)
        ax.set_ylim(0, 100)
        ax.set_xlim(0, self.daily_data['day'].max())
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Add trend lines
        ax.plot(self.daily_data['day'], self.daily_data['recoverable_pct'].rolling(30).mean(), 
               color='#006837', linewidth=2, alpha=0.7)
        ax.plot(self.daily_data['day'], self.daily_data['permanent_pct'].rolling(30).mean(), 
               color='#a50026', linewidth=2, alpha=0.7)
        
        # Add composition change annotation
        initial_recov = self.daily_data['recoverable_pct'].iloc[100]
        final_recov = self.daily_data['recoverable_pct'].iloc[-1]
        initial_perm = self.daily_data['permanent_pct'].iloc[100]
        final_perm = self.daily_data['permanent_pct'].iloc[-1]
        
        ax.text(0.05, 0.15, 
               f"Recoverable: {initial_recov:.1f}% → {final_recov:.1f}%\nPermanent: {initial_perm:.1f}% → {final_perm:.1f}%", 
               transform=ax.transAxes, fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_annual_comparison(self, ax):
        """Plot annual health status comparison"""
        # Calculate annual health statistics
        annual_stats = self.daily_data.groupby('year').agg({
            'health': ['min', 'max', 'mean', 'median'],
            'degradation_rate': ['mean', 'max']
        }).reset_index()
        
        # Set positions
        bar_width = 0.2
        years = annual_stats['year'].unique()
        index = np.arange(len(years))
        
        # Plot bars
        ax.bar(index, annual_stats[('health', 'max')], bar_width, 
              color='#2ca02c', label='Annual Peak')
        ax.bar(index + bar_width, annual_stats[('health', 'mean')], bar_width, 
              color='#1f77b4', label='Annual Mean')
        ax.bar(index + bar_width*2, annual_stats[('health', 'median')], bar_width, 
              color='#ff7f0e', label='Annual Median')
        ax.bar(index + bar_width*3, annual_stats[('health', 'min')], bar_width, 
              color='#d62728', label='Annual Valley')
        
        # Connect peaks and valleys
        for i, year in enumerate(years):
            ax.plot([i + bar_width/2, i + bar_width*3.5], 
                   [annual_stats.loc[i, ('health', 'max')], 
                   annual_stats.loc[i, ('health', 'min')]], 
                   color='#7f7f7f', linestyle='-', alpha=0.3)
        
        # Set properties
        ax.set_title('Annual Health Status Comparison', fontsize=16)
        ax.set_xlabel('Year', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_xticks(index + bar_width*1.5)
        ax.set_xticklabels([f'Year {year}' for year in years])
        ax.set_ylim(0.70, 1.02)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=10)
        
        # Add value labels
        for i, year in enumerate(years):
            ax.text(i + bar_width*0.5, annual_stats.loc[i, ('health', 'max')] + 0.005, 
                   f'{annual_stats.loc[i, ("health", "max")]:.3f}', 
                   ha='center', fontsize=9)
            ax.text(i + bar_width*3.5, annual_stats.loc[i, ('health', 'min')] - 0.01, 
                   f'{annual_stats.loc[i, ("health", "min")]:.3f}', 
                   ha='center', fontsize=9, va='top')
        
        # Add degradation trend
        degradation_trend = [1 - annual_stats.loc[i, ('health', 'mean')] for i in range(len(years))]
        ax2 = ax.twinx()
        ax2.plot(index + bar_width*1.5, degradation_trend, 
                'o-', color='#9467bd', linewidth=2, markersize=8, 
                label='Mean Degradation')
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, 0.35)
        ax2.legend(loc='upper left', fontsize=10)
        
        # Add degradation rate trend
        ax3 = ax.twinx()
        ax3.spines['right'].set_position(('outward', 60))
        ax3.plot(index + bar_width*1.5, annual_stats[('degradation_rate', 'mean')], 
                's--', color='#e377c2', linewidth=2, markersize=8, 
                label='Avg Degradation Rate')
        ax3.set_ylabel('Degradation Rate (%/day)', fontsize=12)
        ax3.set_ylim(0, annual_stats[('degradation_rate', 'mean')].max() * 1.5)
        ax3.legend(loc='upper right', fontsize=10)
    
    def plot_detailed_degradation_path(self):
        """Plot detailed degradation path with hourly resolution"""
        plt.figure(figsize=(15, 10))
        
        # Create grid layout
        gs = GridSpec(2, 1, height_ratios=[2, 1])
        
        # Plot 1: Health status with cleaning events
        ax1 = plt.subplot(gs[0])
        ax1.plot(self.data['day'], self.data['health'], 
                color='#1f77b4', alpha=0.6, linewidth=0.8, label='Hourly Health')
        
        # Add daily average
        daily_health = self.data.groupby('day')['health'].mean()
        ax1.plot(daily_health.index, daily_health, 
                color='#2c7bb6', linewidth=2, label='Daily Avg Health')
        
        # Highlight cleaning events
        cleaning_days = self.data.loc[self.data.index.isin(self.cleaning_hours), 'day'].unique()
        for day in cleaning_days:
            ax1.axvline(x=day, color='#ff7f0e', alpha=0.4, linestyle='-')
        
        # Add thresholds
        ax1.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8)
        
        # Set properties
        ax1.set_title('Detailed Degradation Path (Hourly Resolution)', fontsize=16)
        ax1.set_xlabel('Operating Days', fontsize=12)
        ax1.set_ylabel('Health Status', fontsize=12)
        ax1.set_ylim(0.70, 1.02)
        ax1.set_xlim(0, self.data['day'].max())
        ax1.grid(alpha=0.1)
        ax1.legend(loc='lower left', fontsize=10)
        
        # Plot 2: Degradation components
        ax2 = plt.subplot(gs[1])
        ax2.plot(self.data['day'], self.data['recoverable'], 
                color='#a6d96a', linewidth=1, alpha=0.7, label='Recoverable')
        ax2.plot(self.data['day'], self.data['semi_permanent'], 
                color='#fdae61', linewidth=1, alpha=0.7, label='Semi-Permanent')
        ax2.plot(self.data['day'], self.data['permanent'], 
                color='#d7191c', linewidth=1, alpha=0.7, label='Permanent')
        
        # Set properties
        ax2.set_title('Degradation Components (Hourly)', fontsize=14)
        ax2.set_xlabel('Operating Days', fontsize=12)
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, self.data[['recoverable', 'semi_permanent', 'permanent']].max().max() * 1.1)
        ax2.set_xlim(0, self.data['day'].max())
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper left', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.25)
        plt.savefig(os.path.join(output_path, 'detailed_degradation_path.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_condition_impact_analysis(self):
        """Plot analysis of condition impact on degradation"""
        # Calculate degradation rates by condition
        condition_degradation = self.data.groupby('condition').agg({
            'health': 'mean',
            'recoverable': 'mean',
            'semi_permanent': 'mean',
            'permanent': 'mean'
        })
        
        condition_degradation['total_degradation'] = 1 - condition_degradation['health']
        
        # Calculate degradation rates by condition
        condition_rates = self.data.copy()
        condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
        condition_rates = condition_rates.groupby('condition')['degradation'].agg(['mean', 'std'])
        
        plt.figure(figsize=(14, 6))
        
        # Plot 1: Degradation levels by condition
        ax1 = plt.subplot(121)
        condition_degradation[['recoverable', 'semi_permanent', 'permanent']].plot.bar(
            stacked=True, ax=ax1, color=['#a6d96a', '#fdae61', '#d7191c'], alpha=0.85)
        
        ax1.set_title('Degradation Levels by Operating Condition', fontsize=14)
        ax1.set_xlabel('Operating Condition', fontsize=12)
        ax1.set_ylabel('Average Degradation', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(title='Degradation Type', fontsize=9)
        
        # Plot 2: Degradation rates by condition
        ax2 = plt.subplot(122)
        condition_rates['mean'].plot.bar(yerr=condition_rates['std'], 
                                        ax=ax2, color='#6a3d9a', alpha=0.7)
        
        ax2.set_title('Degradation Rates by Operating Condition', fontsize=14)
        ax2.set_xlabel('Operating Condition', fontsize=12)
        ax2.set_ylabel('Average Degradation Rate', fontsize=12)
        ax2.grid(alpha=0.1)
        
        # Add condition impact factors
        for i, condition in enumerate(condition_rates.index):
            impact = self.config.condition_impact[condition]
            ax2.text(i, condition_rates['mean'].iloc[i] + 0.0001, 
                    f'Impact: {impact}x', ha='center', fontsize=9)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.88)
        plt.suptitle('Operating Condition Impact Analysis', fontsize=16)
        plt.savefig(os.path.join(output_path, 'condition_impact_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_cleaning_effectiveness_analysis(self):
        """Plot analysis of cleaning effectiveness over time"""
        if not self.cleaning_hours:
            print("No cleaning events to analyze")
            return
        
        # Extract cleaning events data
        cleaning_events = self.data.loc[self.data.index.isin(self.cleaning_hours)].copy()
        cleaning_events['cleaning_count'] = range(1, len(cleaning_events)+1)
        
        # Calculate effectiveness metrics
        cleaning_events['recoverable_reduction'] = cleaning_events['cleaning_effect_recov'] / cleaning_events['recoverable']
        cleaning_events['semi_reduction'] = cleaning_events['cleaning_effect_semi'] / cleaning_events['semi_permanent']
        cleaning_events['perm_reduction'] = cleaning_events['cleaning_effect_perm'] / cleaning_events['permanent']
        
        # Calculate performance recovery
        performance_recovery = []
        for i, row in cleaning_events.iterrows():
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_health = post_clean['health'].max()
                recovery = peak_health - row['health']
                performance_recovery.append(recovery)
            else:
                performance_recovery.append(0)
        cleaning_events['performance_recovery'] = performance_recovery
        
        plt.figure(figsize=(14, 8))
        
        # Plot cleaning effectiveness
        ax1 = plt.subplot(211)
        ax1.plot(cleaning_events['cleaning_count'], cleaning_events['recoverable_reduction']*100, 
                'o-', color='#a6d96a', label='Recoverable')
        ax1.plot(cleaning_events['cleaning_count'], cleaning_events['semi_reduction']*100, 
                's-', color='#fdae61', label='Semi-Permanent')
        ax1.plot(cleaning_events['cleaning_count'], cleaning_events['perm_reduction']*100, 
                'd-', color='#d7191c', label='Permanent')
        
        ax1.set_title('Cleaning Effectiveness Over Time', fontsize=14)
        ax1.set_xlabel('Cleaning Event Number', fontsize=12)
        ax1.set_ylabel('Degradation Reduction (%)', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='upper right', fontsize=10)
        
        # Plot performance recovery
        ax2 = plt.subplot(212)
        ax2.plot(cleaning_events['cleaning_count'], cleaning_events['performance_recovery']*100, 
                'o-', color='#1f77b4')
        
        # Add linear regression
        from scipy.stats import linregress
        slope, intercept, r_value, p_value, std_err = linregress(
            cleaning_events['cleaning_count'], cleaning_events['performance_recovery']*100)
        ax2.plot(cleaning_events['cleaning_count'], 
                intercept + slope * cleaning_events['cleaning_count'], 
                '--', color='#d62728', 
                label=f'Trend: y = {slope:.3f}x + {intercept:.3f}\nR² = {r_value**2:.3f}')
        
        ax2.set_title('Performance Recovery After Cleaning', fontsize=14)
        ax2.set_xlabel('Cleaning Event Number', fontsize=12)
        ax2.set_ylabel('Performance Recovery (%)', fontsize=12)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper right', fontsize=10)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3)
        plt.suptitle('Cleaning Effectiveness Analysis', fontsize=16)
        plt.savefig(os.path.join(output_path, 'cleaning_effectiveness_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()

# ======================
# 6. Execute Simulation and Visualization
# ======================
if __name__ == "__main__":
    # Initialize configuration
    print("Initializing turbocharger degradation model...")
    config = DegradationModelConfig()
    
    # Run simulation
    print("Starting simulation...")
    simulator = AdvancedDegradationSimulator(config)
    degradation_data, cleaning_hours = simulator.simulate()
    print(f"Simulation complete! Generated {len(degradation_data)} hourly data points")
    print(f"Cleaning events: {len(cleaning_hours)}")
    
    # Analyze results
    analyzer = CompleteVisualization(degradation_data, cleaning_hours, config)
    
    # Visualize results
    print("Generating complete analysis...")
    analyzer.plot_complete_analysis()
    
    # Save results
    degradation_data.to_csv(os.path.join(output_path, 'turbine_degradation_data.csv'), index=False)
    print("Results saved to 'turbine_degradation_data.csv'")
    
    # Print final status
    final_health = degradation_data['health'].iloc[-1]
    print(f"\nHealth status after 4 years: {final_health:.4f}")
    print(f"Total degradation: {1 - final_health:.4f}")

版本4
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from matplotlib.gridspec import GridSpec
from scipy.stats import gaussian_kde
import matplotlib.dates as mdates
from matplotlib.colors import LinearSegmentedColormap
import os
import re

# Set English font for all plots
plt.rcParams['font.family'] = 'DejaVu Sans'  # Good for English text
plt.rcParams['font.size'] = 10
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16

# Define save path
output_path = "/mnt/c/Users/think/Desktop/scond"
os.makedirs(output_path, exist_ok=True)

# Set random seed
np.random.seed(42)

# Engine log text
ENGINE_LOG = """
2015年3月涡轮清洗时间：2015年3月14号8点，2015年3月24号12点，2015年3月27号12点，2015年3月30号12点（20号-22号处于停泊状态）
2015年4月涡轮清洗时间：2015年4月2号13点，2015年4月5号13点，2015年4月8号13点，2015年4月11号13点，2015年4月14号13点，2015年4月17号13点，2015年4月20号13点（2015年4月20号到5月17号处于停泊状态）
2015年5月涡轮清洗时间：2015年5月19号20点，2015年5月22号18点，2015年5月25号18点，2015年5月31号16点（1号-17号处于停泊状态，其中29号处于高速航行当中，轴转速比较快，相对低转速而言，积碳较慢）
2015年6月涡轮清洗时间：2015年6月7号13点，2015年6月10号13点，2015年6月13号13点，2015年6月16号12点，2015年6月19号11点，2015年6月22号12点，2015年6月28号9点（其中3号-5号处于停泊状态）
2015年7月涡轮清洗时间：2015年7月1号9点，2015年7月22号9极pst，2015年7月25号9点，2015年7月30号10点（4号-9号可能是处于停航状态，11号-12号处于停泊状态，14号到19号处于停泊状态，27-28号在停航）
2015年8月涡轮清洗时间：2015年8月23号20点（1号到19号涡轮增压器都处于高速航行当中）
2015年9月涡轮清洗时间：2015年9月1号19点，2015年9月4号19点，201极5年9月7号19点，2015年9月10号19点，2015年9月13号19点，2015年9月17号5点，2015年9月21号2点，2015年9月25号19点 
2015年10月涡轮清洗时间：2015年10月1号9点，2015年10月4号9点，2015年10月7号9点，2015年10月13号12点，2015年10月25号10点，2015年10月28号10点，2015年10月31号11点 （其中9号到13号处于停泊状态，16号到18号处于高速航行，21号22号处于停泊状态）
2015年11 涡轮清洗时间：2015年11月3号13点 ，2015年11月6号13点，2015年11月9号15点，2015年11月12号14点，2015年11月15号15点，2015年11月18号17点 ，2015年11月27号18点 ，2015年11月30号15点（其中21号到25号处于停泊状态）
2015年12 涡轮清洗时间：2015年12月3号16点，2015年12月8号15点，2015年12月11号12点，2015年12月15号15点，2015年12月19号2点，2015年12月21号10点，2015年12月24号10点，2015年12月27号10点，2015年12月30号9点

2016年1月涡轮清洗时间：2016年1月2号9点，2016年1月25号9点，2016年1月28号9点（4号在高速航行，4号-8号处于停泊状态，11号到20号处于停泊状态）
2016年2月涡轮清洗时间：2016年2月2号10点，2016年2月5号11点，2016年2月8号10点，2016年2月12号13点，2016年2月15号14点，2016年2月18号15点，2016年2月21号15点，2016年2月24号15点（其中25号-28号处于高速航行当中，涡轮增压器积碳较慢，并未清洗）
2016年3月涡轮清洗时间：2016年3月7号17点，2016年3月10号17点，2016年3月13号18点，2016年3月16号18点，2016年3月19号17点，2016年3月23极15点，2016年3月26号17点，2016年3月29号12点（1号-5号处于停泊状态）
2016年4月涡轮清洗时间：2016年4月1号12点，2016年4月4号11点，2016年4月7号11点，2016年4月11号11点，2016年4月14号10点，2016年4月17号9点，2016年4月20号10点（22号-30号应该处于停船状态）
2016年5月涡轮清洗时间：2016年5月5号9点，2016年5月8号9点，2016年5月11号9点（1号到3号处于停船状态，13号到31好像也是处于停船状态）
2016年6月涡轮清洗时间：2016年6月17号9点，2016年6月20号11点，2016年6月23号12点，2016年6月26号12点，2016年6月29号14点（1号到-14号应该处于停船状态）
2016年7月涡轮清洗时间：2016年7月3号15点，2016年7月6号16点，2016年7月9号17点，2016年7月12号18点，2016年7月16号20点，2016年7月24号19点，2016年7月27号19点，2016年7月30号17点（17号-22号应该处于停船状态或者其他状态）
2016年8月涡轮清洗时间：2016年8月2号17点，2016年8月5号16点，2016年8月8号14点，2016年8月11号14点，2016年8月14号13点，2016年8月17号12点，2016年8月20号11点，2016年8月23号10点，2016年8月26号10点，2016年8月29号10点
2016年9月涡轮清洗时间：2016年9月1号9点，2016年9月4号9点，2016年9月13号9点，2016年9月17号9点，2016年9月22号12点，2016年9月25号11点，2016年9月28号11点（4号-10号可能处于停船状态）
2016年10月涡轮清洗时间：2016年10月1号13点，2016年10月6号15点，2016年10月9号15点，2016年10月12号17点，2016年10月15号16点，2016年10月18号18点，2016年10月21号19点，2016年10月31号19点（24号到29号应该是处于停船状态）
2016年11月涡轮清洗时间：2016年11月3号19点，2016年11月6号19点，2016年11月9号18点，2016年11月12号18点，2016年11月15号17点，2016年11月18号15点，2016年11月21号14点，2016年11月24号13点，2016年11月27号13点，2016年11月30号13点
2016年12月涡轮清洗时间：2016年12月3号12点，2016年12月6号10点，2016年12月9号10点，2016年12月12号9点，2016年12月15号9点，2016年12月18号9点，2016年12月30号12点（21号-31号可能是停船状态）

2017年1月涡轮清洗时间：2017年1月4号10点，2017年1月7号10点，2017年1月16号10极，2017年1月19号12点，2017年1月22号12点，2017年1月25号12点，2017年1月28号14点，2017年1月31号15点（10号到12号应该是处于停船期间）
2017年2月涡轮清洗时间：2017年2月3号16点，2017年2月6号16点，2017年2月9号19点，2017年2月12号19点，2017年2月18号20点，2017年2月21号19点，2017年2月24号1点，2017年2月27号16点（13号到15号可能处于停泊期间）
2017年3月涡轮清洗时间：2017年3月2号14点，2017年3月5号14点，2017年3月8号13点，2017年3月11号13点，2017年3月14号12点，2017年3月17号11点，2017年3月20号10点，2017年3月26号10点，2017年3月29号9点
2017年4月涡轮清洗时间：2017年4月9号14点，2017年4月12号9点，2017年4月16号11点，2017年4月19号12点，2017年4月22号12点，2017年4月25号13点，2017年4月28号13点（2号-7号可能处于停泊状态，14号-15号之前有一个短暂的停泊）
2017年5月涡轮清洗时间：2017年5月1号14点，2017年5月4号15点，2017年5月9号16点，2017年5月12号16点，2017年5月16号19点，2017年5月19号20点，2017年5月26号20点，2017年5月29号19点（21号-23号处于停泊状态）
2017年6月涡轮清洗时间：2017年6月1号18点，2017年6月4号16点，2017年6月7号19点，2017年6月10号16点，2017年6月13号14点，2017年6月16号14点，2017年6月19号12点，2017年6月27号10点
2017年7月涡轮清洗时间：2017年7月3号10点（10号-31号处于停泊状态）
2017年8月涡轮清洗时间：2017年8月20号11点，2017年8月23号12点，2017年8月26号13点，2017年8月29号14点（1号-7号处于停泊阶段，14-15号处于停船状态）
2017年9月涡轮清洗时间：2017年9月1号15点，2017年9月4号16点，2017年9月7号17点，2017年9月10号16点，2017年9月3号16点，2017年9月16号20点，2017年9月28号19点（17-22号处于停泊）
2017年10月涡轮清洗时间：2017年10月1号19点，2017年10月7号17点，2017年10月10号15点，2017年10月16号14点，2017年10月19号14点，2017年10月22号13点，2017年10月25号11点，2017年10月31号9点
2017年11月涡轮清洗时间：2017年11月1号9点，2017年11月9号9点（10号-15号可能处于停泊状态，17-30号处于停泊状态）
2017年12月涡轮清洗时间：2017年12月8号9点，2017年12月11号9点，2017年12月17号11点，2017年12月20号11点，2017年12月23号13点，2017年12月26号15点，2017年12月29号15点（1号-3号处于停泊状态，12-14号处于停泊状态）

2018年1月涡轮清洗时间：2018年1月1号15点，2018年1月4号17点，2018年1月7号18点，2018年1月10号19点，2018年1月19号17点，2018年1月21号19点，2018年1月24号19点，2018年1月27号19点，2018年1月30号17点（13号-19号处于停泊状态）
2018年2月涡轮清洗时间：2018年2月2号17点，2018年2月5号15点，2018年2月8号15点，2018年2月11号13点，2018年2月14号12点，2018年2月17号11点，2018年2月20号11点
2018年3月涡轮清洗时间：2018年3月12号11点，2018年3月15号10点，2018年3月22号11点，2018年3月25号11点，2018年3月27号11点，2018年3月30号14点（6号-10号处于停泊状态，19号-20号处于停泊状态）
2018年4月涡轮清洗时间：2018年4月2号14点，2018年4月5号15点，2018年4月8号16点，2018年4月11号17点，2018年4月14号18点，2018年4月17号19点（21号-30号处于停泊状态）
2018年5月涡轮清洗时间：2018年5月14号19点，2018年5月17号19点，2018年5月20号19点，2018年5月23号17点，2018年5月26号16点，2018年5月29号15点（1号-12号处于停泊状态）
2018年6月涡轮清洗时间：2018年6月1号15点，2018年6月4号14点，2018年6月7号13点，2018年6月10号12点，2018年6月13号12点，2018年6月16号10点，2018年6月19号9点，2018年6月22号9点，2018年6月25号9点（28号-30号处于停泊状态）
2018年7月涡轮清洗时间：2018年7月13号14点，2018年7月22号18点，2018年7月25号11点，2018年7月28号12点（1号-10号处于停泊状态，19号到20号处于停泊状态）
2018年8月涡轮清洗时间：2018年8月3号14点，2018年8月6号15点，2018年8月9号16点，2018年8月12号17点，2018年8月15号18点，2018年8月18号19点，2018年8月21号21点（22号-28号处于停泊状态）
2018年9月涡轮清洗时间：2018年9月2号19点，2018年9月5号19点，2018年9月8号17点，2018年9月12号16点，2018年9月14号16点，2018年9月17号14点，2018年9月20号13点，2018年9月23号13点，2018年9月极26号13点
2018年10月涡轮清洗时间：2018年10月5号10点，2018年10月8号10点，2018年10月20号9点，2018年10月26号10点，2018年10月29号11点（12号-17号处于停泊状态，24号-25号处于停泊状态）
2018年11月涡轮清洗时间：2018年11月1号12点，2018年11月4号13点，2018年11月7号14点，2018年11月10号20点，2018年11月13号16点，2018年11月16号17点，2018年11月19号18点，2018年11月22号19点（25号-30号处于停泊状态）
2018年12月涡轮清洗时间：2018年12月4号19点，2018年12月7号19点，2018年12月10号19点，2018年12月13号18点，2018年12月16号17点，2018年12月26号14点，2018年12月30号12点
"""

# ======================
# 1. Advanced Degradation Model Configuration
# ======================
class DegradationModelConfig:
    def __init__(self):
        # Time parameters (based on engine log)
        self.start_date = datetime(2015, 3, 14, 1, 0, 0)
        self.end_date = datetime(2019, 1, 14, 23, 59, 0)
        self.total_duration = self.end_date - self.start_date
        self.total_hours = int(self.total_duration.total_seconds() / 3600)
        self.total_days = self.total_hours // 24
        
        # Condition types
        self.condition_types = ['Low Speed', 'High Speed', 'Berthing']
        
        # Degradation impact factors
        self.condition_impact = {
            'Low Speed': 1.0,      # Normal degradation speed
            'High Speed': 0.5,      # Slower carbon buildup
            'Berthing': -0.3         # Performance recovery during berthing
        }
        
        # Cleaning parameters
        self.cleaning_effectiveness = {
            'recoverable': 0.95,
            'semi_permanent': 0.60,
            'permanent': 0.05
        }
        self.cleaning_decay = 0.0008
        
        # Degradation model parameters
        # Recoverable degradation
        self.recoverable_rate = {
            'base': 0.00025,
            'noise': 0.00003,
            'shock_prob': 0.00035,
            'shock_severity': [0.008, 0.025],
            'recovery_speed': 0.85
        }
        
        # Semi-permanent degradation
        self.semi_permanent_rate = {
            'base': 0.00008,
            'noise': 0.000012,
            'shock_prob': 0.00025,
            'shock_severity': [0.004, 0.015],
            'recovery_speed': 0.55
        }
        
        # Permanent degradation
        self.permanent_rate = {
            'base': 0.000045,
            'noise': 0.000007,
            'shock_prob': 0.00018,
            'shock_severity': [0.002, 0.008],
            'recovery_speed': 0.15
        }
        
        # Initial health state
        self.initial_health = 1.00
        
        # Performance recovery parameters
        self.recovery_duration = 24
        self.recovery_factor = 1.8
        
        # Berthing recovery parameters
        self.berthing_recovery = {
            'short_term': 0.00005,   # Short-term berthing recovery rate
            'long_term': 0.00015     # Long-term berthing recovery rate (>72 hours)
        }
        
        # Add engine log attribute
        self.engine_log = ENGINE_LOG

# ======================
# 2. Condition Simulator
# ======================
class ConditionSimulator:
    def __init__(self, config):
        self.config = config
        # Store all period data
        self.condition_sequence = np.full(config.total_hours, 'Low Speed', dtype=object)
        self.berthing_periods = []
        self.high_sailing_periods = []
    
    def parse_operating_conditions(self):
        """Parse all operating conditions from engine log"""
        engine_log = self.config.engine_log
        
        # Store all condition periods
        periods = []
        
        # Parse berthing periods
        berthing_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号[^\d]*(\d{4})年(\d{1,2})月(\d{1,2})号'
        for match in re.finditer(berthing_pattern, engine_log):
            start_year, start_month, start_day, end_year, end_month, end_day = map(int, match.groups())
            try:
                start_date = datetime(start_year, start_month, start_day)
                end_date = datetime(end_year, end_month, end_day)
                if self.config.start_date <= start_date <= end_date <= self.config.end_date:
                    periods.append(('Berthing', start_date, end_date))
                    self.berthing_periods.append((start_date, end_date))
            except ValueError:
                continue
                
        # Parse single berthing dates (e.g., "3rd-5th")
        single_berthing_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号[^\d]*(\d{1,2})号'
        for match in re.finditer(single_berthing_pattern, engine_log):
            year, month, start_day, end_day = map(int, match.groups())
            try:
                start_date = datetime(year, month, start_day)
                end_date = datetime(year, month, end_day)
                if self.config.start_date <= start_date <= end_date <= self.config.end_date:
                    periods.append(('Berthing', start_date, end_date))
                    self.berthing_periods.append((start_date, end_date))
            except ValueError:
                continue
        
        # Parse high-speed sailing periods
        sailing_pattern = r'处于高速航行'
        for line in engine_log.split('\n'):
            if '处于高速航行' in line:
                date_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号'
                dates = re.findall(date_pattern, line)
                if dates:
                    # Process date format
                    parsed_dates = []
                    for date_tuple in dates:
                        year, month, day = map(int, date_tuple)
                        try:
                            sailing_date = datetime(year, month, day)
                            parsed_dates.append(sailing_date)
                        except ValueError:
                            continue
                    
                    # Sort dates and create time periods
                    if parsed_dates:
                        parsed_dates.sort()
                        for i in range(len(parsed_dates) - 1):
                            start_date = parsed_dates[i]
                            end_date = parsed_dates[i+1]
                            periods.append(('High Speed', start_date, end_date))
                            self.high_sailing_periods.append((start_date, end_date))
        
        # Apply all periods to condition sequence
        for condition_type, start, end in periods:
            start_idx = max(0, int((start - self.config.start_date).total_seconds() / 3600))
            end_idx = min(self.config.total_hours - 1, 
                         int((end - self.config.start_date).total_seconds() / 3600))
            
            if start_idx < end_idx:
                self.condition_sequence[start_idx:end_idx+1] = condition_type
        
        # Mark cleaning events (12 hours before and after set to normal condition)
        cleaning_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        for match in re.finditer(cleaning_pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                event_time = datetime(year, month, day, hour)
                # Ensure event is within time range
                if self.config.start_date <= event_time <= self.config.end_date:
                    hour_idx = int((event_time - self.config.start_date).total_seconds() / 3600)
                    # Set 12 hours before and after to Low Speed
                    start_clean = max(0, hour_idx - 12)
                    end_clean = min(self.config.total_hours, hour_idx + 12)
                    self.condition_sequence[start_clean:end_clean+1] = 'Low Speed'
            except ValueError:
                continue
        
        return self.condition_sequence
    
    def get_impact_factor(self, condition):
        """Get degradation impact factor for condition"""
        return self.config.condition_impact[condition]

# ======================
# 3. Cleaning Simulator
# ======================
class CleaningSimulator:
    def __init__(self, config, condition_simulator):
        self.config = config
        self.condition_simulator = condition_simulator
        self.cleaning_events = self.parse_engine_log()
        
    def parse_engine_log(self):
        """Parse cleaning events from engine log"""
        engine_log = self.config.engine_log
        
        # Parse cleaning events
        cleaning_events = []
        pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        
        for match in re.finditer(pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                event_time = datetime(year, month, day, hour)
                if self.config.start_date <= event_time <= self.config.end_date:
                    cleaning_events.append(event_time)
            except ValueError:
                continue
        
        # Remove duplicates and sort
        cleaning_events = sorted(set(cleaning_events))
        return cleaning_events
    
    def generate_cleaning_schedule(self):
        """Generate cleaning schedule based on engine log"""
        cleaning_hours = []
        
        for event_time in self.cleaning_events:
            hours_from_start = int((event_time - self.config.start_date).total_seconds() / 3600)
            cleaning_hours.append(hours_from_start)
        
        return cleaning_hours
    
    def get_cleaning_effectiveness(self, cleaning_count, deg_type):
        """Calculate cleaning effectiveness"""
        base_effectiveness = self.config.cleaning_effectiveness[deg_type]
        effectiveness = base_effectiveness * (1 - self.config.cleaning_decay * cleaning_count)
        
        min_effect = {
            'recoverable': 0.85,
            'semi_permanent': 0.45,
            'permanent': 0.02
        }
        return max(effectiveness, min_effect[deg_type])

# ======================
# 4. Advanced Degradation Simulator
# ======================
class AdvancedDegradationSimulator:
    def __init__(self, config):
        self.config = config
        self.condition_simulator = ConditionSimulator(config)
        self.cleaning_simulator = CleaningSimulator(config, self.condition_simulator)
    
    def simulate(self):
        """Simulate degradation path (hourly resolution)"""
        # Generate timestamps
        timestamps = [self.config.start_date + timedelta(hours=i) 
                     for i in range(self.config.total_hours)]
        
        # Generate operating conditions
        conditions = self.condition_simulator.parse_operating_conditions()
        
        # Generate cleaning schedule
        cleaning_hours = self.cleaning_simulator.generate_cleaning_schedule()
        cleaning_count = 0
        
        # Initialize degradation paths
        health = np.full(self.config.total_hours, self.config.initial_health)
        recoverable = np.zeros(self.config.total_hours)
        semi_permanent = np.zeros(self.config.total_hours)
        permanent = np.zeros(self.config.total_hours)
        
        # Performance recovery state
        recovery_state = np.zeros(self.config.total_hours)
        
        # Cleaning effects records
        cleaning_effects = np.zeros((self.config.total_hours, 3))
        
        # Berthing duration tracking
        current_berthing_duration = 0
        
        # Main simulation loop (hourly resolution)
        for t in range(1, self.config.total_hours):
            # Update recovery state (fix: use integer steps)
            if recovery_state[t-1] > 0:
                # Decrease by 1/recovery duration steps (24 hours needs 24 steps)
                recovery_state[t] = max(recovery_state[t-1] - 1/self.config.recovery_duration, 0)
            
            # Get current condition
            condition = conditions[t]
            
            # Track berthing duration
            if condition == 'Berthing':
                current_berthing_duration += 1
            else:
                current_berthing_duration = 0
                
            # Calculate degradation increment based on condition
            if condition == 'Low Speed':
                # Low Speed: normal degradation
                impact_factor = self.config.condition_impact['Low Speed']
                
                # Recoverable degradation
                base_rate = self.config.recoverable_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.recoverable_rate['noise'])
                shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                    if np.random.rand() < self.config.recoverable_rate['shock_prob'] else 0
                recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
                
                # Semi-permanent degradation
                base_rate = self.config.semi_permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.semi_permanent_rate['noise'])
                shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                    if np.random.rand() < self.config.semi_permanent_rate['shock_prob'] else 0
                semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
                
                # Permanent degradation
                base_rate = self.config.permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.permanent_rate['noise'])
                shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                    if np.random.rand() < self.config.permanent_rate['shock_prob'] else 0
                permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
                
            elif condition == 'High Speed':
                # High Speed: slower carbon buildup
                impact_factor = self.config.condition_impact['High Speed']
                
                # Recoverable degradation (reduced rate)
                base_rate = self.config.recoverable_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.recoverable_rate['noise'] * 0.5)
                shock_prob = self.config.recoverable_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
                
                # Semi-permanent degradation (reduced rate)
                base_rate = self.config.semi_permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.semi_permanent_rate['noise'] * 0.5)
                shock_prob = self.config.semi_permanent_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
                
                # Permanent degradation (reduced rate)
                base_rate = self.config.permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.permanent_rate['noise'] * 0.5)
                shock_prob = self.config.permanent_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
                
            elif condition == 'Berthing':
                # Berthing: health recovery based on berthing time
                impact_factor = self.config.condition_impact['Berthing']
                
                # Long-term berthing (>72 hours) has better recovery
                if current_berthing_duration > 72:
                    recovery_rate = self.config.berthing_recovery['long_term']
                else:
                    recovery_rate = self.config.berthing_recovery['short_term']
                
                # Mainly recover recoverable degradation
                recoverable[t] = max(recoverable[t-1] - recovery_rate, 0)
                
                # Semi-permanent and permanent degradation slightly recover during berthing
                semi_permanent[t] = max(semi_permanent[t-1] - recovery_rate * 0.3, 0)
                permanent[t] = max(permanent[t-1] - recovery_rate * 0.1, 0)
            
            # Calculate total health
            total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
            health[t] = max(self.config.initial_health - total_degradation, 0.01)
            
            # Apply performance recovery
            if recovery_state[t] > 0:
                # Calculate performance recovery factor (linear interpolation)
                recovery_factor = 1 + (self.config.recovery_factor - 1) * recovery_state[t]
                health[t] = min(health[t] * recovery_factor, self.config.initial_health)
            
            # Apply cleaning effects
            if t in cleaning_hours:
                cleaning_count += 1
                # Set recovery state to 1 (max recovery state)
                recovery_state[t] = 1.0
                
                # Calculate degradation reduction
                recov_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'recoverable')
                semi_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'semi_permanent')
                perm_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'permanent')
                
                # Apply cleaning
                recoverable_reduction = recoverable[t] * recov_effect
                semi_reduction = semi_permanent[t] * semi_effect
                permanent_reduction = permanent[t] * perm_effect
                
                recoverable[t] = max(recoverable[t] - recoverable_reduction, 0)
                semi_permanent[t] = max(semi_permanent[t] - semi_reduction, 0)
                permanent[t] = max(permanent[t] - permanent_reduction, 0)
                
                # Record cleaning effects
                cleaning_effects[t] = [recoverable_reduction, semi_reduction, permanent_reduction]
                
                # Recalculate health
                total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
                health[t] = max(self.config.initial_health - total_degradation, 0.01)
                
                # Apply immediate performance boost (already handled by recovery state)
        
        # Create result DataFrame
        results = pd.DataFrame({
            'timestamp': timestamps,
            'health': health,
            'recoverable': recoverable,
            'semi_permanent': semi_permanent,
            'permanent': permanent,
            'condition': conditions,
            'recovery_state': recovery_state,
            'cleaning_effect_recov': cleaning_effects[:, 0],
            'cleaning_effect_semi': cleaning_effects[:, 1],
            'cleaning_effect_perm': cleaning_effects[:, 2],
        })
        
        # Add date information
        results['date'] = results['timestamp'].dt.date
        results['day'] = (results['timestamp'] - results['timestamp'].iloc[0]).dt.days
        results['hour'] = results['timestamp'].dt.hour
        
        return results, cleaning_hours

# ======================
# 5. Complete Visualization
# ======================
class CompleteVisualization:
    def __init__(self, degradation_data, cleaning_hours, config):
        self.data = degradation_data
        self.cleaning_hours = cleaning_hours
        self.config = config
        self.cleaning_events = [self.data['timestamp'].iloc[h] for h in cleaning_hours]
        
        # Create daily data
        self.daily_data = self.data.groupby('date').last().reset_index()
        
        # Mark cleaning dates
        cleaning_dates = self.data.loc[self.data.index.isin(cleaning_hours), 'date'].unique()
        self.daily_data['cleaning_event'] = self.daily_data['date'].isin(cleaning_dates)
        
        # Add year information
        self.daily_data['year'] = self.daily_data['date'].apply(lambda x: x.year)
        
        # Calculate degradation rates
        self._calculate_degradation_rates()
        
        # Ensure daily condition data (fix: avoid KeyError)
        if 'condition' in self.data.columns:
            daily_conditions = self.data.groupby('date')['condition'].agg(lambda x: x.value_counts().idxmax()).reset_index()
            daily_conditions.columns = ['date', 'condition_daily']
            self.daily_data = pd.merge(self.daily_data, daily_conditions, on='date', how='left')
            self.daily_data['condition_daily'] = self.daily_data['condition_daily'].fillna('Low Speed')
        else:
            self.daily_data['condition_daily'] = 'Low Speed'
    
    def _calculate_degradation_rates(self):
        """Calculate degradation rates for visualization"""
        # Calculate daily degradation
        self.daily_data['daily_degradation'] = -self.daily_data['health'].diff().fillna(0)
        self.daily_data['degradation_rate'] = self.daily_data['daily_degradation'] * 100  # Percentage
        
        # Calculate cumulative degradation
        self.daily_data['cumulative_degradation'] = 1 - self.daily_data['health']
        
        # Calculate degradation component percentages
        total_degradation = self.daily_data[['recoverable', 'semi_permanent', 'permanent']].sum(axis=1)
        # Avoid division by zero error
        total_degradation = total_degradation.replace(0, 1e-10)
        self.daily_data['recoverable_pct'] = self.daily_data['recoverable'] / total_degradation * 100
        self.daily_data['semi_permanent_pct'] = self.daily_data['semi_permanent'] / total_degradation * 100
        self.daily_data['permanent_pct'] = self.daily_data['permanent'] / total_degradation * 100
    
    def plot_complete_analysis(self):
        """Create comprehensive analysis with multiple charts"""
        plt.figure(figsize=(20, 18))
        
        # Create grid layout
        gs = GridSpec(4, 2, height_ratios=[1.2, 1, 1, 1])
        
        # Chart 1: Main health trend (top, full width)
        ax1 = plt.subplot(gs[0, :])
        self._plot_main_health_trend(ax1, title='Health Status Trend with Performance Peaks')
        
        # Chart 2: Degradation components (middle left)
        ax2 = plt.subplot(gs[1, 0])
        self._plot_degradation_components(ax2, title='Degradation Components Over Time')
        
        # Chart 3: Degradation rate analysis (middle right)
        ax3 = plt.subplot(gs[1, 1])
        self._plot_degradation_rate_analysis(ax3, title='Daily Degradation Rate Analysis')
        
        # Chart 4: Recovery detail (bottom left)
        ax4 = plt.subplot(gs[2, 0])
        self._plot_recovery_detail(ax4, title='Post-Cleaning Performance Recovery (72 hours)')
        
        # Chart 5: Degradation composition (bottom right)
        ax5 = plt.subplot(gs[2, 1])
        self._plot_degradation_composition(ax5, title='Degradation Composition Over Time')
        
        # Chart 6: Annual health comparison (bottom, full width)
        ax6 = plt.subplot(gs[3, :])
        self._plot_annual_comparison(ax6, title='Annual Health Comparison')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, hspace=0.35)
        plt.suptitle('Comprehensive Turbine Degradation & Recovery Analysis', 
                     fontsize=24, fontweight='bold')
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'complete_turbine_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
        
        # Save individual plots
        self.save_individual_plots()
        
        # Generate additional detailed charts
        self.plot_detailed_degradation_path()
        self.plot_condition_impact_analysis()
        self.plot_cleaning_effectiveness_analysis()
        
        # Generate evaluation metrics
        self.plot_evaluation_metrics()
    
    def save_individual_plots(self):
        """Save all subplots as separate images"""
        # Create subplots directory
        subplot_path = os.path.join(output_path, 'subplots')
        os.makedirs(subplot_path, exist_ok=True)
        
        # 1. Main health trend chart
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_main_health_trend(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'main_health_trend.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Degradation components chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_components(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_components.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. Degradation rate analysis chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_rate_analysis(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_rate_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. Recovery detail chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_recovery_detail(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'recovery_detail.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. Degradation composition chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_composition(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_composition.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. Annual comparison chart
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_annual_comparison(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'annual_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_main_health_trend(self, ax, title=None, show_title=True):
        """Plot main health trend with performance peaks marked"""
        # Apply smoothing
        self.daily_data['health_smooth'] = self.daily_data['health'].rolling(window=7, min_periods=1).mean()
        
        # Plot smoothed health trend
        ax.plot(
            self.daily_data['date'],
            self.daily_data['health_smooth'], 
            color='#1f77b4', 
            linewidth=2.5, 
            label='Health Status'
        )
        
        # Highlight cleaning events and performance peaks
        cleaning_data = self.data.loc[self.data.index.isin(self.cleaning_hours)]
        peak_values = []    
        for _, row in cleaning_data.iterrows():
            # Mark cleaning event (vertical line)
            ax.axvline(x=row['timestamp'], color='#ff7f0e', alpha=0.3, linestyle='-', zorder=1)
            
            # Find and mark performance peak
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_idx = post_clean['health'].idxmax()
                peak_row = self.data.loc[peak_idx]
                peak_values.append(peak_row['health'])
                ax.plot(peak_row['timestamp'], peak_row['health'], 
                       'D', markersize=6, color='#d62728', alpha=0.8,
                       markeredgecolor='black', zorder=3, label='Performance Peak')
        
        # Add threshold lines
        ax.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.852, 'Maintenance Threshold', fontsize=12, color='#ff7f0e')
        
        ax.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.752, 'Fault Threshold', fontsize=12, color='#d62728')
        
        # Add year markers
        years = pd.date_range(start=self.config.start_date, end=self.config.end_date, freq='YS')
        for year in years:
            ax.axvline(x=year, color='#2ca02c', linestyle='--', alpha=0.5, zorder=1)
            ax.text(year + timedelta(days=10), 0.72, f'{year.year}', fontsize=11, color='#2ca02c')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Date', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_ylim(0.70, 1.02)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # Add performance recovery statistics
        if peak_values:
            avg_recovery = np.mean([pv - cd for pv, cd in zip(peak_values, cleaning_data['health'])])
            
            stats_text = f'Avg Recovery: {avg_recovery:.3f}'''
            ax.text(0.98, 0.05, stats_text,
                   transform=ax.transAxes, ha='right', fontsize=11,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
        
        # Create custom legend
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='#1f77b4', lw=2, label='Health Status'),
            Line2D([0], [0], marker='D', color='w', markerfacecolor='#d62728', 
                  markersize=8, markeredgecolor='black', label='Performance Peak'),
            Line2D([0], [0], color='#ff7f0e', linestyle='-', alpha=0.3, label='Cleaning Event'),
        ]
        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)
    
    def _plot_degradation_components(self, ax, title=None, show_title=True):
        """Plot degradation components with clear colors"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable'], 
            self.daily_data['semi_permanent'], 
            self.daily_data['permanent'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Cumulative Degradation', fontsize=11)
        ax.set_ylim(0, 0.35)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation component info
        total_deg = self.daily_data.iloc[-1][['recoverable', 'semi_permanent', 'permanent']].sum()
        if total_deg > 0:
            recov_pct = self.daily_data.iloc[-1]['recoverable'] / total_deg * 100
            semi_pct = self.daily_data.iloc[-1]['semi_permanent'] / total_deg * 100
            perm_pct = self.daily_data.iloc[-1]['permanent'] / total_deg * 100
            
            comp_text = (f'Final Composition:\n'
                         f'Recoverable: {recov_pct:.1f}%\n'
                         f'Semi-permanent: {semi_pct:.1f}%\n'
                         f'Permanent: {perm_pct:.1f}%')
            
            ax.text(0.95, 0.95, comp_text,
                   transform=ax.transAxes, ha='right', va='top', fontsize=10,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_degradation_rate_analysis(self, ax, title=None, show_title=True):
        """Plot degradation rate analysis with operating conditions"""
        # Apply smoothing
        self.daily_data['degradation_rate_smooth'] = self.daily_data['degradation_rate'].rolling(window=7, min_periods=1).mean()
        
        # Plot degradation rate
        ax.plot(self.daily_data['date'], self.daily_data['degradation_rate_smooth'], 
                color='#6a3d9a', linewidth=1.8, label='Degradation Rate')
        
        # Highlight high degradation periods
        high_degradation = self.daily_data[self.daily_data['degradation_rate_smooth'] > 
                                          self.daily_data['degradation_rate_smooth'].quantile(0.9)]
        ax.scatter(high_degradation['date'], high_degradation['degradation_rate_smooth'], 
                  color='#e31a1c', s=15, alpha=0.7, label='High Degradation')
        
        # Add condition impact markers
        condition_colors = {
            'Low Speed': '#1f77b4',
            'High Speed': '#ff7f0e',
            'Berthing': '#2ca02c'
        }
        
        # Use daily condition data
        if 'condition_daily' in self.daily_data.columns:
            # Add markers for non-normal conditions
            non_normal = self.daily_data[self.daily_data['condition_daily'] != 'Low Speed']
            for condition, color in condition_colors.items():
                if condition == 'Low Speed':
                    continue
                condition_data = non_normal[non_normal['condition_daily'] == condition]
                if not condition_data.empty:
                    ax.scatter(condition_data['date'], condition_data['degradation_rate_smooth'], 
                              color=color, s=25, marker='s', alpha=0.7, label=f'{condition} Condition')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Degradation Rate (%/day)', fontsize=11)
        ax.set_ylim(0, self.daily_data['degradation_rate_smooth'].max() * 1.2)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=8)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation rate statistics
        avg_rate = self.daily_data['degradation_rate_smooth'].mean()
        max_rate = self.daily_data['degradation_rate_smooth'].max()
        
        stats_text = f'Avg Rate: {avg_rate:.4f}%/day\nMax Rate: {max_rate:.4f}%/day'
        ax.text(0.95, 0.95, stats_text,
               transform=ax.transAxes, ha='right', fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_recovery_detail(self, ax, title=None, show_title=True):
        """Plot post-cleaning performance recovery details"""
        if not self.cleaning_events:
            ax.text(0.5, 0.5, 'No Cleaning Events', ha='center', va='center', fontsize=14)
            return
        
        # Select a mid-term cleaning event
        mid_point = self.config.total_hours // 2
        cleaning_time = min(self.cleaning_events, key=lambda x: abs((x - self.config.start_date).total_seconds()/3600 - mid_point))
        
        # Get data 24 hours before and 48 hours after cleaning
        start_time = cleaning_time - timedelta(hours=24)
        end_time = cleaning_time + timedelta(hours=48)
        recovery_data = self.data[
            (self.data['timestamp'] >= start_time) & 
            (self.data['timestamp'] <= end_time)
        ].copy()
        
        if recovery_data.empty:
            return
        
        # Calculate hours from cleaning
        recovery_data['hours_from_clean'] = (recovery_data['timestamp'] - cleaning_time).dt.total_seconds() / 3600
        
        # Plot health change
        ax.plot(recovery_data['hours_from_clean'], recovery_data['health'], 
                color='#1f77b4', linewidth=2, label='Health Status')
        
        # Plot degradation components
        ax.plot(recovery_data['hours_from_clean'], recovery_data['recoverable'], 
                color='#a6d96a', linewidth=1.5, linestyle='--', alpha=0.8, label='Recoverable')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['semi_permanent'], 
                color='#fdae61', linewidth=1.5, linestyle='--', alpha=0.8, label='Semi-permanent')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['permanent'], 
                color='#d7191c', linewidth=1.5, linestyle='--', alpha=0.8, label='Permanent')
        
        # Mark cleaning time
        ax.axvline(x=0, color='#ff7f0e', linestyle='-', alpha=0.8, label='Cleaning Event')
        
        # Highlight performance peak
        post_clean = recovery_data[recovery_data['hours_from_clean'] >= 0]
        if not post_clean.empty:
            peak_idx = post_clean['health'].idxmax()
            peak_row = recovery_data.loc[peak_idx]
            ax.plot(peak_row['hours_from_clean'], peak_row['health'], 
                   'D', markersize=8, color='#d62728', alpha=0.8,
                   markeredgecolor='black', label='Performance Peak')
            
            # Add recovery magnitude
            recovery_mag = peak_row['health'] - recovery_data[recovery_data['hours_from_clean'] == 0]['health'].values[0]
            ax.annotate(f'+{recovery_mag:.3f}', 
                       xy=(peak_row['hours_from_clean'], peak_row['health']),
                       xytext=(peak_row['hours_from_clean'], peak_row['health'] + 0.02),
                       ha='center', fontsize=10,
                       arrowprops=dict(arrowstyle='->', color='black'))
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Hours After Cleaning', fontsize=11)
        ax.set_ylabel('Health Status', fontsize=11)
        ax.set_ylim(recovery_data[['health', 'recoverable', 'semi_permanent', 'permanent']].min().min() - 0.02, 
                   recovery_data['health'].max() + 0.04)
        ax.grid(alpha=0.1)
        ax.legend(loc='lower right', fontsize=8)
        
        # Add recovery period
        ax.axvspan(0, 24, color='#ffffbf', alpha=0.2, label='Recovery Period')
    
    def _plot_degradation_composition(self, ax, title=None, show_title=True):
        """Plot degradation composition percentages over time"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable_pct'], 
            self.daily_data['semi_permanent_pct'], 
            self.daily_data['permanent_pct'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Composition Percentage', fontsize=11)
        ax.set_ylim(0, 100)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add trend lines
        ax.plot(self.daily_data['date'], self.daily_data['recoverable_pct'].rolling(30).mean(), 
               color='#006837', linewidth=2, alpha=0.7)
        ax.plot(self.daily_data['date'], self.daily_data['permanent_pct'].rolling(30).mean(), 
               color='#a50026', linewidth=2, alpha=0.7)
        
        # Add composition change annotation
        initial_recov = self.daily_data['recoverable_pct'].iloc[100]
        final_recov = self.daily_data['recoverable_pct'].iloc[-1]
        initial_perm = self.daily_data['permanent_pct'].iloc[100]
        final_perm = self.daily_data['permanent_pct'].iloc[-1]
        
        ax.text(0.05, 0.15, 
               f"Recoverable: {initial_recov:.1f}% → {final_recov:.1f}%\nPermanent: {initial_perm:.1f}% → {final_perm:.1f}%", 
               transform=ax.transAxes, fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_annual_comparison(self, ax, title=None, show_title=True):
        """Plot annual health comparison"""
        # Calculate annual health statistics
        annual_stats = self.daily_data.groupby('year').agg({
            'health': ['min', 'max', 'mean', 'median'],
            'degradation_rate': ['mean', 'max']
        }).reset_index()
        
        # Set positions
        bar_width = 0.2
        years = annual_stats['year'].unique()
        index = np.arange(len(years))
        
        # Plot bars
        ax.bar(index, annual_stats[('health', 'max')], bar_width, 
              color='#2ca02c', label='Annual Peak')
        ax.bar(index + bar_width, annual_stats[('health', 'mean')], bar_width, 
              color='#1f77b4', label='Annual Mean')
        ax.bar(index + bar_width*2, annual_stats[('health', 'median')], bar_width, 
              color='#ff7f0e', label='Annual Median')
        ax.bar(index + bar_width*3, annual_stats[('health', 'min')], bar_width, 
              color='#d62728', label='Annual Trough')
        
        # Connect peaks and troughs
        for i, year in enumerate(years):
            ax.plot([i + bar_width/2, i + bar_width*3.5], 
                   [annual_stats.loc[i, ('health', 'max')], 
                   annual_stats.loc[i, ('health', 'min')]], 
                   color='#7f7f7f', linestyle='-', alpha=0.3)
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Year', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_xticks(index + bar_width*1.5)
        ax.set_xticklabels([f'{year}' for year in years])
        ax.set_ylim(0.70, 1.02)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=10)
        
        # Add value labels
        for i, year in enumerate(years):
            ax.text(i + bar_width*0.5, annual_stats.loc[i, ('health', 'max')] + 0.005, 
                   f'{annual_stats.loc[i, ("health", "max")]:.3f}', 
                   ha='center', fontsize=9)
            ax.text(i + bar_width*3.5, annual_stats.loc[i, ('health', 'min')] - 0.01, 
                   f'{annual_stats.loc[i, ("health", "min")]:.3f}', 
                   ha='center', fontsize=9, va='top')
        
        # Add degradation trend
        degradation_trend = [1 - annual_stats.loc[i, ('health', 'mean')] for i in range(len(years))]
        ax2 = ax.twinx()
        ax2.plot(index + bar_width*1.5, degradation_trend, 
                'o-', color='#9467bd', linewidth=2, markersize=8, 
                label='Avg Degradation Level')
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, 0.35)
        ax2.legend(loc='upper left', fontsize=10)
        
        # Add degradation rate trend
        ax3 = ax.twinx()
        ax3.spines['right'].set_position(('outward', 60))
        ax3.plot(index + bar_width*1.5, annual_stats[('degradation_rate', 'mean')], 
                's--', color='#e377c2', linewidth=2, markersize=8, 
                label='Avg Degradation Rate')
        ax3.set_ylabel('Degradation Rate (%/day)', fontsize=12)
        ax3.set_ylim(0, annual_stats[('degradation_rate', 'mean')].max() * 1.5)
        ax3.legend(loc='upper right', fontsize=10)
    
    def plot_detailed_degradation_path(self):
        """Plot detailed degradation path (hourly resolution)"""
        plt.figure(figsize=(15, 10))
        
        # Create grid layout
        gs = GridSpec(2, 1, height_ratios=[2, 1])
        
        # Chart 1: Health status with cleaning events
        ax1 = plt.subplot(gs[0])
        ax1.plot(self.data['timestamp'], self.data['health'], 
                color='#1f77b4', alpha=0.6, linewidth=0.8, label='Hourly Health')
        
        # Add daily average
        daily_health = self.data.groupby('date')['health'].mean()
        ax1.plot(daily_health.index, daily_health, 
                color='#2c7bb6', linewidth=2, label='Daily Avg Health')
        
        # Highlight cleaning events
        for event in self.cleaning_events:
            ax1.axvline(x=event, color='#ff7f0e', alpha=0.4, linestyle='-')
        
        # Add thresholds
        ax1.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8)
        
        # Set properties
        ax1.set_title('Detailed Degradation Path (Hourly Resolution)', fontsize=16)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Health Status', fontsize=12)
        ax1.set_ylim(0.70, 1.02)
        ax1.set_xlim(self.config.start_date, self.config.end_date)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='lower left', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Chart 2: Degradation components
        ax2 = plt.subplot(gs[1])
        ax2.plot(self.data['timestamp'], self.data['recoverable'], 
                color='#a6d96a', linewidth=1, alpha=0.7, label='Recoverable')
        ax2.plot(self.data['timestamp'], self.data['semi_permanent'], 
                color='#fdae61', linewidth=1, alpha=0.7, label='Semi-permanent')
        ax2.plot(self.data['timestamp'], self.data['permanent'], 
                color='#d7191c', linewidth=1, alpha=0.7, label='Permanent')
        
        # Set properties
        ax2.set_title('Degradation Components (Hourly Data)', fontsize=14)
        ax2.set_xlabel('Date', fontsize=12)
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, self.data[['recoverable', 'semi_permanent', 'permanent']].max().max() * 1.1)
        ax2.set_xlim(self.config.start_date, self.config.end_date)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.25)
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'detailed_degradation_path.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_condition_impact_analysis(self):
        """Plot condition impact analysis"""
        # Calculate degradation rate by condition
        if 'condition' in self.data.columns:
            condition_degradation = self.data.groupby('condition').agg({
                'health': 'mean',
                'recoverable': 'mean',
                'semi_permanent': 'mean',
                'permanent': 'mean'
            })
            
            condition_degradation['total_degradation'] = 1 - condition_degradation['health']
            
            # Calculate degradation rate by condition
            condition_rates = self.data.copy()
            condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
            condition_rates = condition_rates.groupby('condition')['degradation'].agg(['mean', 'std'])
            
            plt.figure(figsize=(14, 6))
            
            # Chart 1: Degradation level by condition
            ax1 = plt.subplot(121)
            condition_degradation[['recoverable', 'semi_permanent', 'permanent']].plot.bar(
                stacked=True, ax=ax1, color=['#a6d96a', '#fdae61', '#d7191c'], alpha=0.85)
            
            ax1.set_title('Degradation Level by Operating Condition', fontsize=14)
            ax1.set_xlabel('Operating Condition', fontsize=12)
            ax1.set_ylabel('Average Degradation', fontsize=12)
            ax1.grid(alpha=0.1)
            ax1.legend(title='Degradation Type', fontsize=9)
            
            # Chart 2: Degradation rate by condition
            ax2 = plt.subplot(122)
            condition_rates['mean'].plot.bar(yerr=condition_rates['std'], 
                                           ax=ax2, color='#6a3d9a', alpha=0.7)
            
            ax2.set_title('Degradation Rate by Condition', fontsize=14)
            ax2.set_xlabel('Operating Condition', fontsize=12)
            ax2.set_ylabel('Average Degradation Rate', fontsize=12)
            ax2.grid(alpha=0.1)
            
            # Add condition impact factor
            for i, condition in enumerate(condition_rates.index):
                impact = self.config.condition_impact[condition]
                ax2.text(i, condition_rates['mean'].iloc[i] + 0.0001, 
                        f'Impact: {impact}x', ha='center', fontsize=9)
            
            plt.tight_layout()
            plt.subplots_adjust(top=0.88)
            plt.suptitle('Operating Condition Impact Analysis', fontsize=16)
            
            # Save chart
            plt.savefig(os.path.join(output_path, 'condition_impact_analysis.png'), dpi=300, bbox_inches='tight')
            plt.show()
            plt.close()
        else:
            print("No condition data available for analysis")
    
    def plot_cleaning_effectiveness_analysis(self):
        """Plot cleaning effectiveness analysis over time"""
        if not self.cleaning_events:
            print("No cleaning events available for analysis")
            return
        
        # Extract cleaning event data
        cleaning_events_data = self.data[self.data['timestamp'].isin(self.cleaning_events)].copy()
        cleaning_events_data = cleaning_events_data.sort_values('timestamp')
        cleaning_events_data['cleaning_count'] = range(1, len(cleaning_events_data)+1)
        
        # Calculate effectiveness metrics
        cleaning_events_data['recoverable_recovery'] = cleaning_events_data['cleaning_effect_recov'] / cleaning_events_data['recoverable']
        cleaning_events_data['semi_recovery'] = cleaning_events_data['cleaning_effect_semi'] / cleaning_events_data['semi_permanent']
        cleaning_events_data['perm_recovery'] = cleaning_events_data['cleaning_effect_perm'] / cleaning_events_data['permanent']
        
        # Remove invalid values
        cleaning_events_data = cleaning_events_data.replace([np.inf, -np.inf], np.nan).dropna()
        
        # Calculate performance recovery
        performance_recovery = []
        for _, row in cleaning_events_data.iterrows():
            post_clean = self.data[
                (self.data['timestamp'] >= row['timestamp']) & 
                (self.data['timestamp'] <= row['timestamp'] + timedelta(hours=24))
            ]
            if not post_clean.empty:
                peak_health = post_clean['health'].max()
                recovery = peak_health - row['health']
                performance_recovery.append(recovery)
            else:
                performance_recovery.append(0)
        cleaning_events_data['performance_recovery'] = performance_recovery
        
        plt.figure(figsize=(14, 8))
        
        # Chart 1: Cleaning effectiveness over time
        ax1 = plt.subplot(211)
        
        if 'recoverable_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['recoverable_recovery']*100, 
                    'o-', color='#a6d96a', label='Recoverable')
        if 'semi_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['semi_recovery']*100, 
                    's-', color='#fdae61', label='Semi-permanent')
        if 'perm_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['perm_recovery']*100, 
                    'd-', color='#d7191c', label='Permanent')
        
        ax1.set_title('Cleaning Effectiveness Over Time', fontsize=14)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Degradation Reduction (%)', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='upper right', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Chart 2: Post-cleaning performance recovery
        ax2 = plt.subplot(212)
        if 'performance_recovery' in cleaning_events_data.columns:
            ax2.plot(cleaning_events_data['timestamp'], cleaning_events_data['performance_recovery']*100, 
                    'o-', color='#1f77b4')
            
            # Add linear regression trend
            from scipy.stats import linregress
            x_num = mdates.date2num(cleaning_events_data['timestamp'])
            y_vals = cleaning_events_data['performance_recovery']*100
            valid_idx = ~np.isnan(y_vals) & ~np.isinf(y_vals)
            
            if any(valid_idx):
                slope, intercept, r_value, p_value, std_err = linregress(
                    x_num[valid_idx], y_vals[valid_idx])
                ax2.plot(cleaning_events_data['timestamp'], 
                        intercept + slope * x_num, 
                        '--', color='#d62728', 
                        label=f'Trend: y = {slope:.3f}x + {intercept:.3f}\nR² = {r_value**2:.3f}')
            
            ax2.set_title('Post-Cleaning Performance Recovery', fontsize=14)
            ax2.set_xlabel('Date', fontsize=12)
            ax2.set_ylabel('Performance Recovery (%)', fontsize=12)
            ax2.grid(alpha=0.1)
            ax2.legend(loc='upper right', fontsize=10)
            
            # Format date axis
            ax2.xaxis.set_major_locator(mdates.YearLocator())
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3)
        plt.suptitle('Cleaning Effectiveness Analysis', fontsize=16)
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'cleaning_effectiveness_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_time_range_health(self, start_date, end_date):
        """Plot health index for specified time range"""
        time_filtered_data = self.data[(self.data['timestamp'] >= start_date) & (self.data['timestamp'] <= end_date)]
        
        if time_filtered_data.empty:
            print("No data in the specified time range")
            return
        
        plt.figure(figsize=(10, 6))
        plt.plot(time_filtered_data['timestamp'], time_filtered_data['health'], color='#1f77b4', linewidth=2, label='Health Status')
        
        plt.title(f'Health Index from {start_date} to {end_date}', fontsize=14)
        plt.xlabel('Date', fontsize=12)
        plt.ylabel('Health Status', fontsize=12)
        plt.ylim(0.70, 1.02)
        plt.grid(alpha=0.1)
        plt.legend(loc='upper right', fontsize=10)
        
        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        plt.gcf().autofmt_xdate()
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_path, f'health_index_{start_date}_{end_date}.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_evaluation_metrics(self):
        """Plot evaluation metrics including interval distribution, health change, degradation rate box plot, health histogram, and health autocorrelation"""
        plt.figure(figsize=(18, 12))
        
        # Interval distribution between cleaning events
        ax1 = plt.subplot(231)
        cleaning_intervals = np.diff(self.data['timestamp'].iloc[self.cleaning_hours])
        days_intervals = [interval / np.timedelta64(1, 'D') for interval in cleaning_intervals]
        sns.histplot(days_intervals, kde=True, ax=ax1, color='#1f77b4')
        ax1.set_title('Interval Distribution Between Cleaning Events', fontsize=14)
        ax1.set_xlabel('Days', fontsize=12)
        ax1.set_ylabel('Frequency', fontsize=12)
        ax1.grid(alpha=0.1)
        
        # Health change before and after cleaning
        ax2 = plt.subplot(232)
        health_changes = []
        for event in self.cleaning_events:
            post_clean = self.data[(self.data['timestamp'] >= event) & (self.data['timestamp'] <= event + timedelta(hours=24))]
            if not post_clean.empty:
                peak_health = post_clean['health'].max()
                pre_health = self.data[self.data['timestamp'] == event]['health'].values[0]
                health_changes.append(peak_health - pre_health)
        sns.histplot(health_changes, kde=True, ax=ax2, color='#ff7f0e')
        ax2.set_title('Health Change Before and After Cleaning', fontsize=14)
        ax2.set_xlabel('Health Change', fontsize=12)
        ax2.set_ylabel('Frequency', fontsize=12)
        ax2.grid(alpha=0.1)
        
        # Degradation rate box plot by condition
        ax3 = plt.subplot(233)
        condition_rates = self.data.copy()
        condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
        if 'condition' in condition_rates.columns:
            sns.boxplot(x='condition', y='degradation', data=condition_rates, ax=ax3, palette=['#a6d96a', '#fdae61', '#d7191c'])
            ax3.set_title('Degradation Rate Box Plot by Condition', fontsize=14)
            ax3.set_xlabel('Condition', fontsize=12)
            ax3.set_ylabel('Degradation Rate', fontsize=12)
            ax3.grid(alpha=0.1)
        
        # Health status histogram
        ax4 = plt.subplot(234)
        sns.histplot(self.data['health'], kde=True, ax=ax4, color='#1f77b4')
        ax4.set_title('Health Status Histogram', fontsize=14)
        ax4.set_xlabel('Health', fontsize=12)
        ax4.set_ylabel('Frequency', fontsize=12)
        ax4.grid(alpha=0.1)
        
        # Health status autocorrelation plot
        ax5 = plt.subplot(235)
        sns.lineplot(x=range(len(self.data)), y=self.data['health'], ax=ax5, color='#1f77b4')
        ax5.set_title('Health Status Autocorrelation', fontsize=14)
        ax5.set_xlabel('Time Lag', fontsize=12)
        ax5.set_ylabel('Correlation', fontsize=12)
        ax5.grid(alpha=0.1)
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_path, 'evaluation_metrics.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()

if __name__ == "__main__":
    # Initialize degradation model
    print("Initializing turbine degradation model...")
    config = DegradationModelConfig()
    
    # Run simulation
    print("Starting simulation...")
    simulator = AdvancedDegradationSimulator(config)
    degradation_data, cleaning_hours = simulator.simulate()
    print(f"Simulation completed! Generated {len(degradation_data)} hourly data points")
    print(f"Cleaning events: {len(cleaning_hours)}")
    
    # Analyze results
    analyzer = CompleteVisualization(degradation_data, cleaning_hours, config)
    
    # Generate comprehensive analysis chart
    print("Generating comprehensive analysis...")
    analyzer.plot_complete_analysis()
    
    # Save results
    degradation_data.to_csv(os.path.join(output_path, 'turbine_degradation_data.csv'), index=False)
    print("Results saved to 'turbine_degradation_data.csv'")
    
    # Print final health status
    final_health = degradation_data['health'].iloc[-1]
    print(f"\nFinal health status after 4 years: {final_health:.4f}")
    
    # Plot specified time range health trend
    analyzer.plot_time_range_health(datetime(2016, 5, 1), datetime(2016, 9, 1))
    
    # Plot evaluation metrics
    analyzer.plot_evaluation_metrics()

版本5
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from matplotlib.gridspec import GridSpec
from scipy.stats import gaussian_kde
import matplotlib.dates as mdates
from matplotlib.colors import LinearSegmentedColormap
import os
import re

# Set English font for all plots
plt.rcParams['font.family'] = 'DejaVu Sans'  # Good for English text
plt.rcParams['font.size'] = 10
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16

# Define save path
output_path = "/mnt/c/Users/think/Desktop/scond"
os.makedirs(output_path, exist_ok=True)

# Set random seed
np.random.seed(42)

# Engine log text
ENGINE_LOG = """
2015年3月涡轮清洗时间：2015年3月14号8点，2015年3月24号12点，2015年3月27号12点，2015年3月30号12点（20号-22号处于停泊状态）
2015年4月涡轮清洗时间：2015年4月2号13点，2015年4月5号13点，2015年4月8号13点，2015年4月11号13点，2015年4月14号13点，2015年4月17号13点，2015年4月20号13点（2015年4月20号到5月17号处于停泊状态）
2015年5月涡轮清洗时间：2015年5月19号20点，2015年5月22号18点，2015年5月25号18点，2015年5月31号16点（1号-17号处于停泊状态，其中29号处于高速航行当中，轴转速比较快，相对低转速而言，积碳较慢）
2015年6月涡轮清洗时间：2015年6月7号13点，2015年6月10号13点，2015年6月13号13极，2015年6月16号12点，2015年6月19号11点，2015年6月22号12点，2015年6月28号9点（其中3号-5号处于停泊状态）
2015年7月涡轮清洗时间：2015年7月1号9点，2015年7月22号9点，2015年7月25号9点，2015年7月30号10点（4号-9号可能是处于停航状态，11号-12号处于停泊状态，14号到19号处于停泊状态，27-28号在停航）
2015年8月涡轮清洗时间：2015年8月23号20点（1号到19号涡轮增压器都处于高速航行当中）
2015年9月涡轮清洗时间：2015年9月1号19点，2015年9月4号19点，2015年9月7号19点，2015年9月10号19点，2015年9月13号19点，2015年9月17号5点，2015年9月21号2点，2015年9月25号19点 
2015年10月涡轮清洗时间：2015年10月1号9点，2015年10月4号9点，2015年10月7号9点，2015年10月13号12点，2015年10月25号10点，2015年极10月28号10点，2015年10月31号11点 （其中9号到13号处于停泊状态，16号到18号处于高速航行，21号22号处于停泊状态）
2015年11 涡轮清洗时间：2015年11月3号13点 ，2015年11月6号13点，2015年11月9号15点，2015年11月12号14点，2015年11月15号15点，2015年11月18号17点 ，2015年11月27号18点 ，2015年11月30号15点（其中21号到25号处于停泊状态）
2015年12 涡轮清洗时间：2015年12月3号16点，2015年12月8号15点，2015年12月11号12点，2015年12月15号15点，2015年12月19号2点，2015年12月21号10点，2015年12月24号10点，2015年12月27号10点，2015年12月30号9点

2016年1月涡轮清洗时间：2016年1月2号9点，2016年1月25号9点，2016年1月28号9点（4号在高速航行，4号-8号处于停泊状态，11号到20号处于停泊状态）
2016年2月涡轮清洗时间：2016年2月2号10点，2016年2月5号11点，2016年2月8号10点，2016年2月12号13点，2016年2月15号14点，2016年2月18号15点，2016年2月21号15点，2016年2月24号15点（其中25号-28号处于高速航行当中，涡轮增压器积碳较慢，并未清洗）
2016年3月涡轮清洗时间：2016年3月7号17点，2016年3月10号17点，2016年3月13号18点，2016年3月16号18点，2016年3月19号17点，2016年3月23号17点，2016年3月26号17点，2016年3月29号12点（1号-5号处于停泊状态）
2016年4月涡轮清洗时间：2016年4月1号12点，2016年4月4号11点，2016年4月7号11点，2016年4月11号11点，2016年4月14号10点，2016年4月17号9点，2016年4月20号10点（22号-30号应该处于停船状态）
2016年5月涡轮清洗时间：2016年5月5号9点，2016年5月8号9点，2016年5月11号9点（1号到3号处于停船状态，13号到31好像也是处于停船状态）
2016年6月涡轮清洗时间：2016年6月17号9点，2016年6月20号11点，2016年6月23号12点，2016年6月26号12点，2016年6月29号14点（1号到-14号应该处于停船状态）
2016年7月涡轮清洗时间：2016年7月3号15点，2016年7月6号16点，2016年7月9号17点，2016年7月12号18点，2016年7月16号20点，2016年7月24号19点，2016年7月27号19点，2016年7月30号17点（17号-22号应该处于停船状态或者其他状态）
2016年8月涡轮清洗时间：2016年8月2号17点，2016年8月5号16点，2016年8月8号14点，2016年8月11号14点，2016年8月14号13点，2016年8月17号12点，2016年8月20号11点，2016年8月23号10点，2016年8月26号10点，2016年8月29号10点
2016年9月涡轮清洗时间：2016年9月1号9点，2016年9月4号9点，2016年9月13号9点，2016年9月17号9点，2016年9月22号12点，2016年9月25号11点，2016年9月28号11点（4号-10号可能处于停船状态）
2016年10月涡轮清洗时间：2016年10月1号13点，2016年10月6号15点，2016年10月9号15点，2016年10月12号17点，2016年10月15号16点，2016年10月18号18点，2016年10月21号19点，2016年10月31号19点（24号到29号应该是处于停船状态）
2016年11月涡轮清洗时间：2016年11月3号19点，2016年11月6号19点，2016年11月9号18点，2016年11月12号18点，2016年11月15号17点，2016年11月18号15点，2016年11月21号14点，2016年11月24号13点，2016年11月27号13点，2016年11月30号13点
2016年12月涡轮清洗时间：2016年12月3号12点，2016年12月6号10点，2016年12月9号10点，2016年12月12号9点，2016年12月15号9点，2016年12月18号9点，2016年12月30号12点（21号-31号可能是停船状态）

2017年1月涡轮清洗时间：2017年1月4号10点，2017年1月7号10点，2017年1月16号10点，2017年1月19号12点，2017年1月22号12点，2017年1月25号12点，2017年1月28号14点，2017年1月31号15点（10号到12号应该是处于停船期间）
2017年2月涡轮清洗时间：2017年2月3号16点，2017年2月6号16点，2017年2月9号19点，2017年2月12号19点，2017年2月18号20点，2017年2月21号19点，2017年2月24号1点，2017年2月27号16点（13号到15号可能处于停泊期间）
2017年3月涡轮清洗时间：2017年3月2号14点，2017年3月5号14点，2017年3月8号13点，2017年3月11号13点，2017年3月14号12点，2017年3月17号11点，2017年3月20号10点，2017年3月26号10点，2017年3月29号9点
2017年4月涡轮清洗时间：2017年4月9号14点，2017年4月12号9点，2017年4月16号11点，2017年4月19号12点，2017年4月22号12点，2017年4月25号13点，2017年4月28号13点（2号-7号可能处于停泊状态，14号-15号之前有一个短暂的停泊）
2017年5月涡轮清洗时间：2017年5月1号14点，2017年5月4号15点，2017年5月9号16点，2017年5月12号16点，2017年5月16号19点，2017年5月19号20点，2017年5月26号20点，2017年5月29号19点（21号-23号处于停泊状态）
2017年6月涡轮清洗时间：2017年6月1号18点，2017年6月4号16点，2017年6月7号19点，2017年6月10号16点，2017年6月13号14点，2017年6月16号14点，2017年6月19号12点，2017年6月27号10点
2017年7月涡轮清洗时间：2017年7月3号10点（10号-31号处于停泊状态）
2017年8月涡轮清洗时间：2017年8月20号11点，2017年8月23号12点，2017年8月26号13点，2017年8月29号14点（1号-7号处于停泊阶段，14-15号处于停船状态）
2017年9月涡轮清洗时间：2017年9月1号15点，2017年9月4号16点，2017年9月7号17点，2017年9月10号16点，2017年9月13号16点，2017年9月16号20点，2017年9月28号19点（17-22号处于停泊）
2017年10月涡轮清洗时间：2017年10月1号19点，2017年10月7号17点，2017年10月10号15点，2017年10月16号14点，2017年10月19号14点，2017年10月22号13点，2017年10月25号11点，2017年10月31号9点
2017年11月涡轮清洗时间：2017年11月1号9点，2017年11月9号9点（10号-15号可能处于停泊状态，17-30号处于停泊状态）
2017年12月涡轮清洗时间：2017年12月8号9点，2017年12月11号9点，2017年12月17号11点，2017年12月20号11点，2017年12月23号13点，2017年12月26号15点，2017年12月29号15点（1号-3号处于停泊状态，12-14号处于停泊状态）

2018年1月涡轮清洗时间：2018年1月1号15点，2018年1月4号17点，2018年1月7号18点，2018年1月10号19点，2018年1月19号17点，2018年1月21号19点，2018年1月24号19点，2018年1月27号19点，2018年1月30号17点（13号-19号处于停泊状态）
2018年2月涡轮清洗时间：2018年2月2号17点，2018年2月5号15点，2018年2月8号15点，2018年2月11号13点，2018年2月14号12点，2018年2月17号11点，2018年2月20号11点
2018年3月涡轮清洗时间：2018年3月12号11点，2018年3月15号10点，2018年3月22号11点，2018年3月25号11点，2018年3月27号11点，2018年3月30号14点（6号-10号处于停泊状态，19号-20号处于停泊状态）
2018年4月涡轮清洗时间：2018年4月2号14点，2018年4月5号15点，2018年4月8号16点，2018年4月11号17点，2018年4月14号18点，2018年4月17号19点（21号-30号处于停泊状态）
2018年5月涡轮清洗时间：2018年5月14号19点，2018年5月17号19点，2018年5月20号19点，2018年5月23号17点，2018年5月26号16点，2018年5月29号15点（1号-12号处于停泊状态）
2018年6月涡轮清洗时间：2018年6月1号15点，2018年6月4号14点，2018年6月7号13点，2018年6月10号12点，2018年6月13号12点，2018年6月16号10点，2018年6月19号9点，2018年6月22号9点，2018年6月25号9点（28号-30号处于停泊状态）
2018年7月涡轮清洗时间：2018年7月13号14点，2018年7月22号18点，2018年7月25号11点，2018年7月28号12点（1号-10号处于停泊状态，19号到20号处于停泊状态）
2018年8月涡轮清洗时间：2018年8月3号14点，2018年8月6号15点，2018年8月9号16点，2018年8月12号17点，2018年8极15号18点，2018年8月18号19点，2018年8月21号21点（22号-28号处于停泊状态）
2018年9月涡轮清洗时间：2018年9月2号19点，2018年9月5号19点，2018年9月8号17点，2018年9月12号16点，2018年9月14号16点，2018年9月17号14点，2018年9月20号13点，2018年9月23号13点，2018年9月26号13点
2018年10月涡轮清洗时间：2018年10月5号10点，2018年10月8号10点，2018年10月20号9点，2018年10月26号10点，2018年10月29号11点（12号-17号处于停泊状态，24号-25号处于停泊状态）
2018年11月涡轮清洗时间：2018年11月1号12点，2018年11月4号13点，2018年11月7号14点，2018年11月10号20点，2018年11月13号16点，2018年11月16号17点，2018年11月19号18点，2018年11月22号19点（25号-30号处于停泊状态）
2018年12月涡轮清洗时间：2018年12月4号19点，2018年12月7号19点，2018年12月10号19点，2018年12月13号18点，2018年12月16号17点，2018年12月26号14点，2018年12月30号12点
"""

# ======================
# 1. Advanced Degradation Model Configuration
# ======================
class DegradationModelConfig:
    def __init__(self):
        # Time parameters (based on engine log)
        self.start_date = datetime(2015, 3, 14, 1, 0, 0)
        self.end_date = datetime(2019, 1, 14, 23, 59, 0)
        self.total_duration = self.end_date - self.start_date
        self.total_hours = int(self.total_duration.total_seconds() / 3600)
        self.total_days = self.total_hours // 24
        
        # Condition types
        self.condition_types = ['Low Speed', 'High Speed', 'Berthing']
        
        # Degradation impact factors
        self.condition_impact = {
            'Low Speed': 1.0,      # Normal degradation speed
            'High Speed': 0.5,      # Slower carbon buildup
            'Berthing': -0.3         # Performance recovery during berthing
        }
        
        # Cleaning parameters
        self.cleaning_effectiveness = {
            'recoverable': 0.9,
            'semi_permanent': 0.60,
            'permanent': 0.05
        }
        self.cleaning_decay = 0.0008
        
        # Degradation model parameters
        # Recoverable degradation
        self.recoverable_rate = {
            'base': 0.00025,
            'noise': 0.00003,
            'shock_prob': 0.000,
            'shock_severity': [0.008, 0.015],
            'recovery_speed': 0.85
        }
        
        # Semi-permanent degradation
        self.semi_permanent_rate = {
            'base': 0.00008,
            'noise': 0.000012,
            'shock_prob': 0.0000,
            'shock_severity': [0.004, 0.015],
            'recovery_speed': 0.55
        }
        
        # Permanent degradation
        self.permanent_rate = {
            'base': 0.000045,
            'noise': 0.000007,
            'shock_prob': 0.000,
            'shock_severity': [0.002, 0.008],
            'recovery_speed': 0.15
        }
        
        # Initial health state
        self.initial_health = 1.00
        
        # Performance recovery parameters
        self.recovery_duration = 24
        self.recovery_factor = 1.8
        
        # Berthing recovery parameters
        self.berthing_recovery = {
            'short_term': 0.00005,   # Short-term berthing recovery rate
            'long_term': 0.00015     # Long-term berthing recovery rate (>72 hours)
        }
        
        # Add engine log attribute
        self.engine_log = ENGINE_LOG

# ======================
# 2. Condition Simulator
# ======================
class ConditionSimulator:
    def __init__(self, config):
        self.config = config
        # Store all period data
        self.condition_sequence = np.full(config.total_hours, 'Low Speed', dtype=object)
        self.berthing_periods = []
        self.high_sailing_periods = []
    
    def parse_operating_conditions(self):
        """Parse all operating conditions from engine log"""
        engine_log = self.config.engine_log
        
        # Store all condition periods
        periods = []
        
        # Parse berthing periods
        berthing_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号[^\d]*(\d{4})年(\d{1,2})月(\d{1,2})号'
        for match in re.finditer(berthing_pattern, engine_log):
            start_year, start_month, start_day, end_year, end_month, end_day = map(int, match.groups())
            try:
                start_date = datetime(start_year, start_month, start_day)
                end_date = datetime(end_year, end_month, end_day)
                if self.config.start_date <= start_date <= end_date <= self.config.end_date:
                    periods.append(('Berthing', start_date, end_date))
                    self.berthing_periods.append((start_date, end_date))
            except ValueError:
                continue
                
        # Parse single berthing dates (e.g., "3rd-5th")
        single_berthing_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号[^\d]*(\d{1,2})号'
        for match in re.finditer(single_berthing_pattern, engine_log):
            year, month, start_day, end_day = map(int, match.groups())
            try:
                start_date = datetime(year, month, start_day)
                end_date = datetime(year, month, end_day)
                if self.config.start_date <= start_date <= end_date <= self.config.end_date:
                    periods.append(('Berthing', start_date, end_date))
                    self.berthing_periods.append((start_date, end_date))
            except ValueError:
                continue
        
        # Parse high-speed sailing periods
        sailing_pattern = r'处于高速航行'
        for line in engine_log.split('\n'):
            if '处于高速航行' in line:
                date_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号'
                dates = re.findall(date_pattern, line)
                if dates:
                    # Process date format
                    parsed_dates = []
                    for date_tuple in dates:
                        year, month, day = map(int, date_tuple)
                        try:
                            sailing_date = datetime(year, month, day)
                            parsed_dates.append(sailing_date)
                        except ValueError:
                            continue
                    
                    # Sort dates and create time periods
                    if parsed_dates:
                        parsed_dates.sort()
                        for i in range(len(parsed_dates) - 1):
                            start_date = parsed_dates[i]
                            end_date = parsed_dates[i+1]
                            periods.append(('High Speed', start_date, end_date))
                            self.high_sailing_periods.append((start_date, end_date))
        
        # Apply all periods to condition sequence
        for condition_type, start, end in periods:
            start_idx = max(0, int((start - self.config.start_date).total_seconds() / 3600))
            end_idx = min(self.config.total_hours - 1, 
                         int((end - self.config.start_date).total_seconds() / 3600))
            
            if start_idx < end_idx:
                self.condition_sequence[start_idx:end_idx+1] = condition_type
        
        # Mark cleaning events (12 hours before and after set to normal condition)
        cleaning_pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        for match in re.finditer(cleaning_pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                event_time = datetime(year, month, day, hour)
                # Ensure event is within time range
                if self.config.start_date <= event_time <= self.config.end_date:
                    hour_idx = int((event_time - self.config.start_date).total_seconds() / 3600)
                    # Set 12 hours before and after to Low Speed
                    start_clean = max(0, hour_idx - 12)
                    end_clean = min(self.config.total_hours, hour_idx + 12)
                    self.condition_sequence[start_clean:end_clean+1] = 'Low Speed'
            except ValueError:
                continue
        
        return self.condition_sequence
    
    def get_impact_factor(self, condition):
        """Get degradation impact factor for condition"""
        return self.config.condition_impact[condition]

# ======================
# 3. Cleaning Simulator
# ======================
class CleaningSimulator:
    def __init__(self, config, condition_simulator):
        self.config = config
        self.condition_simulator = condition_simulator
        self.cleaning_events = self.parse_engine_log()
        
    def parse_engine_log(self):
        """Parse cleaning events from engine log"""
        engine_log = self.config.engine_log
        
        # Parse cleaning events
        cleaning_events = []
        pattern = r'(\d{4})年(\d{1,2})月(\d{1,2})号(\d{1,2})点'
        
        for match in re.finditer(pattern, engine_log):
            year, month, day, hour = map(int, match.groups())
            try:
                event_time = datetime(year, month, day, hour)
                if self.config.start_date <= event_time <= self.config.end_date:
                    cleaning_events.append(event_time)
            except ValueError:
                continue
        
        # Remove duplicates and sort
        cleaning_events = sorted(set(cleaning_events))
        return cleaning_events
    
    def generate_cleaning_schedule(self):
        """Generate cleaning schedule based on engine log"""
        cleaning_hours = []
        
        for event_time in self.cleaning_events:
            hours_from_start = int((event_time - self.config.start_date).total_seconds() / 3600)
            cleaning_hours.append(hours_from_start)
        
        return cleaning_hours
    
    def get_cleaning_effectiveness(self, cleaning_count, deg_type):
        """Calculate cleaning effectiveness"""
        base_effectiveness = self.config.cleaning_effectiveness[deg_type]
        effectiveness = base_effectiveness * (1 - self.config.cleaning_decay * cleaning_count)
        
        min_effect = {
            'recoverable': 0.85,
            'semi_permanent': 0.50,
            'permanent': 0.05
        }
        return max(effectiveness, min_effect[deg_type])

# ======================
# 4. Advanced Degradation Simulator
# ======================
class AdvancedDegradationSimulator:
    def __init__(self, config):
        self.config = config
        self.condition_simulator = ConditionSimulator(config)
        self.cleaning_simulator = CleaningSimulator(config, self.condition_simulator)
    
    def simulate(self):
        """Simulate degradation path (hourly resolution)"""
        # Generate timestamps
        timestamps = [self.config.start_date + timedelta(hours=i) 
                     for i in range(self.config.total_hours)]
        
        # Generate operating conditions
        conditions = self.condition_simulator.parse_operating_conditions()
        
        # Generate cleaning schedule
        cleaning_hours = self.cleaning_simulator.generate_cleaning_schedule()
        cleaning_count = 0
        
        # Initialize degradation paths
        health = np.full(self.config.total_hours, self.config.initial_health)
        recoverable = np.zeros(self.config.total_hours)
        semi_permanent = np.zeros(self.config.total_hours)
        permanent = np.zeros(self.config.total_hours)
        
        # Cleaning effects records
        cleaning_effects = np.zeros((self.config.total_hours, 3))
        
        # Berthing duration tracking
        current_berthing_duration = 0
        
        # Main simulation loop (hourly resolution)
        for t in range(1, self.config.total_hours):
            # Minimum health threshold to prevent unreasonably low values
            min_health_threshold = 0.15
            
            # Get current condition
            condition = conditions[t]
            
            # Track berthing duration
            if condition == 'Berthing':
                current_berthing_duration += 1
            else:
                current_berthing_duration = 0
                
            # Calculate degradation increment based on condition
            if condition == 'Low Speed':
                # Low Speed: normal degradation
                impact_factor = self.config.condition_impact['Low Speed']
                
                # Recoverable degradation
                base_rate = self.config.recoverable_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.recoverable_rate['noise'])
                shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                    if np.random.rand() < self.config.recoverable_rate['shock_prob'] else 0
                recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
                
                # Semi-permanent degradation
                base_rate = self.config.semi_permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.semi_permanent_rate['noise'])
                shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                    if np.random.rand() < self.config.semi_permanent_rate['shock_prob'] else 0
                semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
                
                # Permanent degradation
                base_rate = self.config.permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.permanent_rate['noise'])
                shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                    if np.random.rand() < self.config.permanent_rate['shock_prob'] else 0
                permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
                
            elif condition == 'High Speed':
                # High Speed: slower carbon buildup
                impact_factor = self.config.condition_impact['High Speed']
                
                # Recoverable degradation (reduced rate)
                base_rate = self.config.recoverable_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.recoverable_rate['noise'] * 0.5)
                shock_prob = self.config.recoverable_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.recoverable_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                recoverable[t] = recoverable[t-1] + max(base_rate + noise + shock, 0)
                
                # Semi-permanent degradation (reduced rate)
                base_rate = self.config.semi_permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.semi_permanent_rate['noise'] * 0.5)
                shock_prob = self.config.semi_permanent_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.semi_permanent_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                semi_permanent[t] = semi_permanent[t-1] + max(base_rate + noise + shock, 0)
                
                # Permanent degradation (reduced rate)
                base_rate = self.config.permanent_rate['base'] * impact_factor
                noise = np.random.normal(0, self.config.permanent_rate['noise'] * 0.5)
                shock_prob = self.config.permanent_rate['shock_prob'] * 0.3
                shock = np.random.uniform(*self.config.permanent_rate['shock_severity']) \
                    if np.random.rand() < shock_prob else 0
                permanent[t] = permanent[t-1] + max(base_rate + noise + shock, 0)
                
            elif condition == 'Berthing':
                # Berthing: health recovery based on berthing time
                impact_factor = self.config.condition_impact['Berthing']
                
                # Long-term berthing (>72 hours) has better recovery
                if current_berthing_duration > 72:
                    recovery_rate = self.config.berthing_recovery['long_term']
                else:
                    recovery_rate = self.config.berthing_recovery['short_term']
                
                # Mainly recover recoverable degradation
                recoverable[t] = max(recoverable[t-1] - recovery_rate, 0)
                
                # Semi-permanent and permanent degradation slightly recover during berthing
                semi_permanent[t] = max(semi_permanent[t-1] - recovery_rate * 0.3, 0)
                permanent[t] = max(permanent[t-1] - recovery_rate * 0.05, 0)  # Reduced recovery for permanent
            
            # Calculate total health with safety threshold
            total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
            health[t] = max(self.config.initial_health - total_degradation, min_health_threshold)
            
            # Apply cleaning effects
            if t in cleaning_hours:
                cleaning_count += 1
                
                # Calculate degradation reduction
                recov_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'recoverable')
                semi_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'semi_permanent')
                perm_effect = self.cleaning_simulator.get_cleaning_effectiveness(
                    cleaning_count, 'permanent')
                
                # Apply cleaning
                recoverable_reduction = recoverable[t] * recov_effect
                semi_reduction = semi_permanent[t] * semi_effect
                permanent_reduction = permanent[t] * perm_effect
                
                recoverable[t] = max(recoverable[t] - recoverable_reduction, 0)
                semi_permanent[t] = max(semi_permanent[t] - semi_reduction, 0)
                permanent[t] = max(permanent[t] - permanent_reduction, 0)
                
                # Record cleaning effects
                cleaning_effects[t] = [recoverable_reduction, semi_reduction, permanent_reduction]
                
                # Recalculate health with safety thresholds
                total_degradation = recoverable[t] + semi_permanent[t] + permanent[t]
                health[t] = max(self.config.initial_health - total_degradation, min_health_threshold)
                health[t] = min(health[t], self.config.initial_health)  # Ensure health doesn't exceed 1.0
        
        # Create result DataFrame
        results = pd.DataFrame({
            'timestamp': timestamps,
            'health': health,
            'recoverable': recoverable,
            'semi_permanent': semi_permanent,
            'permanent': permanent,
            'condition': conditions,
            'cleaning_effect_recov': cleaning_effects[:, 0],
            'cleaning_effect_semi': cleaning_effects[:, 1],
            'cleaning_effect_perm': cleaning_effects[:, 2],
        })
        
        # Add date information
        results['date'] = results['timestamp'].dt.date
        results['day'] = (results['timestamp'] - results['timestamp'].iloc[0]).dt.days
        results['hour'] = results['timestamp'].dt.hour
        
        return results, cleaning_hours
# ======================
# 5. Complete Visualization
# ======================
class CompleteVisualization:
    def __init__(self, degradation_data, cleaning_hours, config):
        self.data = degradation_data
        self.cleaning_hours = cleaning_hours
        self.config = config
        self.cleaning_events = [self.data['timestamp'].iloc[h] for h in cleaning_hours]
        
        # Create daily data
        self.daily_data = self.data.groupby('date').last().reset_index()
        
        # Mark cleaning dates
        cleaning_dates = self.data.loc[self.data.index.isin(cleaning_hours), 'date'].unique()
        self.daily_data['cleaning_event'] = self.daily_data['date'].isin(cleaning_dates)
        
        # Add year information
        self.daily_data['year'] = self.daily_data['date'].apply(lambda x: x.year)
        
        # Calculate degradation rates
        self._calculate_degradation_rates()
        
        # Ensure daily condition data
        if 'condition' in self.data.columns:
            daily_conditions = self.data.groupby('date')['condition'].agg(lambda x: x.value_counts().idxmax()).reset_index()
            daily_conditions.columns = ['date', 'condition_daily']
            self.daily_data = pd.merge(self.daily_data, daily_conditions, on='date', how='left')
            self.daily_data['condition_daily'] = self.daily_data['condition_daily'].fillna('Low Speed')
        else:
            self.daily_data['condition_daily'] = 'Low Speed'
    
    def _calculate_degradation_rates(self):
        """Calculate degradation rates for visualization"""
        # Calculate daily degradation
        self.daily_data['daily_degradation'] = -self.daily_data['health'].diff().fillna(0)
        self.daily_data['degradation_rate'] = self.daily_data['daily_degradation'] * 100  # Percentage
        
        # Calculate cumulative degradation
        self.daily_data['cumulative_degradation'] = 1 - self.daily_data['health']
        
        # Calculate degradation component percentages
        total_degradation = self.daily_data[['recoverable', 'semi_permanent', 'permanent']].sum(axis=1)
        # Avoid division by zero error
        total_degradation = total_degradation.replace(0, 1e-10)
        self.daily_data['recoverable_pct'] = self.daily_data['recoverable'] / total_degradation * 100
        self.daily_data['semi_permanent_pct'] = self.daily_data['semi_permanent'] / total_degradation * 100
        self.daily_data['permanent_pct'] = self.daily_data['permanent'] / total_degradation * 100
    
    def plot_complete_analysis(self):
        """Create comprehensive analysis with multiple charts"""
        plt.figure(figsize=(20, 18))
        
        # Create grid layout
        gs = GridSpec(4, 2, height_ratios=[1.2, 1, 1, 1])
        
        # Chart 1: Main health trend (top, full width)
        ax1 = plt.subplot(gs[0, :])
        self._plot_main_health_trend(ax1, title='Health Status Trend with Performance Peaks')
        
        # Chart 2: Degradation components (middle left)
        ax2 = plt.subplot(gs[1, 0])
        self._plot_degradation_components(ax2, title='Degradation Components Over Time')
        
        # Chart 3: Degradation rate analysis (middle right)
        ax3 = plt.subplot(gs[1, 1])
        self._plot_degradation_rate_analysis(ax3, title='Daily Degradation Rate Analysis')
        
        # Chart 4: Recovery detail (bottom left)
        ax4 = plt.subplot(gs[2, 0])
        self._plot_recovery_detail(ax4, title='Post-Cleaning Health Recovery (72 hours)')
        
        # Chart 5: Degradation composition (bottom right)
        ax5 = plt.subplot(gs[2, 1])
        self._plot_degradation_composition(ax5, title='Degradation Composition Over Time')
        
        # Chart 6: Annual health comparison (bottom, full width)
        ax6 = plt.subplot(gs[3, :])
        self._plot_annual_comparison(ax6, title='Annual Health Comparison')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.95, hspace=0.35)
        plt.suptitle('Comprehensive Turbine Degradation & Recovery Analysis', 
                     fontsize=24, fontweight='bold')
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'complete_turbine_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
        
        # Save individual plots
        self.save_individual_plots()
        
        # Generate additional detailed charts
        self.plot_detailed_degradation_path()
        self.plot_condition_impact_analysis()
        self.plot_cleaning_effectiveness_analysis()
        
        # Generate evaluation metrics
        self.plot_evaluation_metrics()
    
    def save_individual_plots(self):
        """Save all subplots as separate images"""
        # Create subplots directory
        subplot_path = os.path.join(output_path, 'subplots')
        os.makedirs(subplot_path, exist_ok=True)
        
        # 1. Main health trend chart
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_main_health_trend(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'main_health_trend.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Degradation components chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_components(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_components.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. Degradation rate analysis chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_rate_analysis(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_rate_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. Recovery detail chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_recovery_detail(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'recovery_detail.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. Degradation composition chart
        fig, ax = plt.subplots(figsize=(10, 5))
        self._plot_degradation_composition(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'degradation_composition.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. Annual comparison chart
        fig, ax = plt.subplots(figsize=(12, 6))
        self._plot_annual_comparison(ax, show_title=False)
        plt.tight_layout()
        plt.savefig(os.path.join(subplot_path, 'annual_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_main_health_trend(self, ax, title=None, show_title=True):
        """Plot main health trend with performance peaks marked"""
        # Apply smoothing
        self.daily_data['health_smooth'] = self.daily_data['health'].rolling(window=7, min_periods=1).mean()
        
        # Plot smoothed health trend
        ax.plot(
            self.daily_data['date'],
            self.daily_data['health_smooth'], 
            color='#1f77b4', 
            linewidth=2.5, 
            label='Health Status'
        )
        
        # Highlight cleaning events and performance peaks
        cleaning_data = self.data.loc[self.data.index.isin(self.cleaning_hours)]
        peak_values = []    
        for _, row in cleaning_data.iterrows():
            # Mark cleaning event (vertical line)
            ax.axvline(x=row['timestamp'], color='#ff7f0e', alpha=0.3, linestyle='-', zorder=1)
            
            # Use the cleaning event health as the peak value
            peak_values.append(row['health'])
            ax.plot(row['timestamp'], row['health'], 
                   'D', markersize=6, color='#d62728', alpha=0.8,
                   markeredgecolor='black', zorder=3, label='Performance Peak')
        
        # Add threshold lines
        ax.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.852, 'Maintenance Threshold', fontsize=12, color='#ff7f0e')
        
        ax.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.752, 'Fault Threshold', fontsize=12, color='#d62728')
        
        # Add safety threshold
        ax.axhline(y=0.15, color='#2ca02c', linestyle='--', alpha=0.5, zorder=2)
        ax.text(self.daily_data['date'].iloc[50], 0.152, 'Safety Threshold', fontsize=12, color='#2ca02c')
        
        # Add year markers
        years = pd.date_range(start=self.config.start_date, end=self.config.end_date, freq='YS')
        for year in years:
            ax.axvline(x=year, color='#2ca02c', linestyle='--', alpha=0.5, zorder=1)
            ax.text(year + timedelta(days=10), 0.72, f'{year.year}', fontsize=11, color='#2ca02c')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Date', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_ylim(0.10, 1.02)  # Adjusted to show safety threshold
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # Add performance recovery statistics
        if peak_values:
            avg_recovery = np.mean([pv - cd for pv, cd in zip(peak_values, cleaning_data['health'])])
            
            stats_text = f'Avg Recovery: {avg_recovery:.3f}'
            ax.text(0.98, 0.05, stats_text,
                   transform=ax.transAxes, ha='right', fontsize=11,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
        
        # Create custom legend
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='#1f77b4', lw=2, label='Health Status'),
            Line2D([0], [0], marker='D', color='w', markerfacecolor='#d62728', 
                  markersize=8, markeredgecolor='black', label='Performance Peak'),
            Line2D([0], [0], color='#ff7f0e', linestyle='-', alpha=0.3, label='Cleaning Event'),
        ]
        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)
    
    def _plot_degradation_components(self, ax, title=None, show_title=True):
        """Plot degradation components with clear colors"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable'], 
            self.daily_data['semi_permanent'], 
            self.daily_data['permanent'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Cumulative Degradation', fontsize=11)
        ax.set_ylim(0, 0.30)  # Adjusted for new degradation rates
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation component info
        total_deg = self.daily_data.iloc[-1][['recoverable', 'semi_permanent', 'permanent']].sum()
        if total_deg > 0:
            recov_pct = self.daily_data.iloc[-1]['recoverable'] / total_deg * 100
            semi_pct = self.daily_data.iloc[-1]['semi_permanent'] / total_deg * 100
            perm_pct = self.daily_data.iloc[-1]['permanent'] / total_deg * 100
            
            comp_text = (f'Final Composition:\n'
                         f'Recoverable: {recov_pct:.1f}%\n'
                         f'Semi-permanent: {semi_pct:.1f}%\n'
                         f'Permanent: {perm_pct:.1f}%')
            
            ax.text(0.95, 0.95, comp_text,
                   transform=ax.transAxes, ha='right', va='top', fontsize=10,
                   bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_degradation_rate_analysis(self, ax, title=None, show_title=True):
        """Plot degradation rate analysis with operating conditions"""
        # Apply smoothing
        self.daily_data['degradation_rate_smooth'] = self.daily_data['degradation_rate'].rolling(window=7, min_periods=1).mean()
        
        # Plot degradation rate
        ax.plot(self.daily_data['date'], self.daily_data['degradation_rate_smooth'], 
                color='#6a3d9a', linewidth=1.8, label='Degradation Rate')
        
        # Highlight high degradation periods
        high_degradation = self.daily_data[self.daily_data['degradation_rate_smooth'] > 
                                          self.daily_data['degradation_rate_smooth'].quantile(0.9)]
        ax.scatter(high_degradation['date'], high_degradation['degradation_rate_smooth'], 
                  color='#e31a1c', s=15, alpha=0.7, label='High Degradation')
        
        # Add condition impact markers
        condition_colors = {
            'Low Speed': '#1f77b4',
            'High Speed': '#ff7f0e',
            'Berthing': '#2ca02c'
        }
        
        # Use daily condition data
        if 'condition_daily' in self.daily_data.columns:
            # Add markers for non-normal conditions
            non_normal = self.daily_data[self.daily_data['condition_daily'] != 'Low Speed']
            for condition, color in condition_colors.items():
                if condition == 'Low Speed':
                    continue
                condition_data = non_normal[non_normal['condition_daily'] == condition]
                if not condition_data.empty:
                    ax.scatter(condition_data['date'], condition_data['degradation_rate_smooth'], 
                              color=color, s=25, marker='s', alpha=0.7, label=f'{condition} Condition')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Degradation Rate (%/day)', fontsize=11)
        ax.set_ylim(0, self.daily_data['degradation_rate_smooth'].max() * 1.2)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=8)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add degradation rate statistics
        avg_rate = self.daily_data['degradation_rate_smooth'].mean()
        max_rate = self.daily_data['degradation_rate_smooth'].max()
        
        stats_text = f'Avg Rate: {avg_rate:.4f}%/day\nMax Rate: {max_rate:.4f}%/day'
        ax.text(0.95, 0.95, stats_text,
               transform=ax.transAxes, ha='right', fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_recovery_detail(self, ax, title=None, show_title=True):
        """Plot post-cleaning health recovery details"""
        if not self.cleaning_events:
            ax.text(0.5, 0.5, 'No Cleaning Events', ha='center', va='center', fontsize=14)
            return
        
        # Select a mid-term cleaning event
        mid_point = self.config.total_hours // 2
        cleaning_time = min(self.cleaning_events, key=lambda x: abs((x - self.config.start_date).total_seconds()/3600 - mid_point))
        
        # Get data 24 hours before and 48 hours after cleaning
        start_time = cleaning_time - timedelta(hours=24)
        end_time = cleaning_time + timedelta(hours=48)
        recovery_data = self.data[
            (self.data['timestamp'] >= start_time) & 
            (self.data['timestamp'] <= end_time)
        ].copy()
        
        if recovery_data.empty:
            return
        
        # Calculate hours from cleaning
        recovery_data['hours_from_clean'] = (recovery_data['timestamp'] - cleaning_time).dt.total_seconds() / 3600
        
        # Plot health change
        ax.plot(recovery_data['hours_from_clean'], recovery_data['health'], 
                color='#1f77b4', linewidth=2, label='Health Status')
        
        # Plot degradation components
        ax.plot(recovery_data['hours_from_clean'], recovery_data['recoverable'], 
                color='#a6d96a', linewidth=1.5, linestyle='--', alpha=0.8, label='Recoverable')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['semi_permanent'], 
                color='#fdae61', linewidth=1.5, linestyle='--', alpha=0.8, label='Semi-permanent')
        ax.plot(recovery_data['hours_from_clean'], recovery_data['permanent'], 
                color='#d7191c', linewidth=1.5, linestyle='--', alpha=0.8, label='Permanent')
        
        # Mark cleaning time
        ax.axvline(x=0, color='#ff7f0e', linestyle='-', alpha=0.8, label='Cleaning Event')
        
        # Highlight health at cleaning time
        cleaning_point = recovery_data[recovery_data['hours_from_clean'] == 0]
        if not cleaning_point.empty:
            ax.plot(cleaning_point['hours_from_clean'], cleaning_point['health'], 
                   'o', markersize=8, color='#ff7f0e', alpha=0.8,
                   markeredgecolor='black', label='Cleaning Health')
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Hours After Cleaning', fontsize=11)
        ax.set_ylabel('Health Status', fontsize=11)
        ax.set_ylim(0.70, 1.02)  # Focus on health range
        ax.grid(alpha=0.1)
        ax.legend(loc='lower right', fontsize=8)
    
    def _plot_degradation_composition(self, ax, title=None, show_title=True):
        """Plot degradation composition percentages over time"""
        # Plot stacked area chart
        ax.stackplot(
            self.daily_data['date'], 
            self.daily_data['recoverable_pct'], 
            self.daily_data['semi_permanent_pct'], 
            self.daily_data['permanent_pct'],
            labels=['Recoverable', 'Semi-permanent', 'Permanent'],
            colors=['#a6d96a', '#fdae61', '#d7191c'],
            alpha=0.85
        )
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=14)
        ax.set_xlabel('Date', fontsize=11)
        ax.set_ylabel('Composition Percentage', fontsize=11)
        ax.set_ylim(0, 100)
        ax.set_xlim(self.config.start_date, self.config.end_date)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add trend lines
        ax.plot(self.daily_data['date'], self.daily_data['recoverable_pct'].rolling(30).mean(), 
               color='#006837', linewidth=2, alpha=0.7)
        ax.plot(self.daily_data['date'], self.daily_data['permanent_pct'].rolling(30).mean(), 
               color='#a50026', linewidth=2, alpha=0.7)
        
        # Add composition change annotation
        initial_recov = self.daily_data['recoverable_pct'].iloc[100]
        final_recov = self.daily_data['recoverable_pct'].iloc[-1]
        initial_perm = self.daily_data['permanent_pct'].iloc[100]
        final_perm = self.daily_data['permanent_pct'].iloc[-1]
        
        ax.text(0.05, 0.15, 
               f"Recoverable: {initial_recov:.1f}% → {final_recov:.1f}%\nPermanent: {initial_perm:.1f}% → {final_perm:.1f}%", 
               transform=ax.transAxes, fontsize=10,
               bbox=dict(facecolor='white', alpha=0.8, edgecolor='grey'))
    
    def _plot_annual_comparison(self, ax, title=None, show_title=True):
        """Plot annual health comparison"""
        # Calculate annual health statistics
        annual_stats = self.daily_data.groupby('year').agg({
            'health': ['min', 'max', 'mean', 'median'],
            'degradation_rate': ['mean', 'max']
        }).reset_index()
        
        # Set positions
        bar_width = 0.2
        years = annual_stats['year'].unique()
        index = np.arange(len(years))
        
        # Plot bars
        ax.bar(index, annual_stats[('health', 'max')], bar_width, 
              color='#2ca02c', label='Annual Peak')
        ax.bar(index + bar_width, annual_stats[('health', 'mean')], bar_width, 
              color='#1f77b4', label='Annual Mean')
        ax.bar(index + bar_width*2, annual_stats[('health', 'median')], bar_width, 
              color='#ff7f0e', label='Annual Median')
        ax.bar(index + bar_width*3, annual_stats[('health', 'min')], bar_width, 
              color='#d62728', label='Annual Trough')
        
        # Connect peaks and troughs
        for i, year in enumerate(years):
            ax.plot([i + bar_width/2, i + bar_width*3.5], 
                   [annual_stats.loc[i, ('health', 'max')], 
                   annual_stats.loc[i, ('health', 'min')]], 
                   color='#7f7f7f', linestyle='-', alpha=0.3)
        
        # Set properties
        if title and show_title:
            ax.set_title(title, fontsize=16)
        ax.set_xlabel('Year', fontsize=12)
        ax.set_ylabel('Health Status', fontsize=12)
        ax.set_xticks(index + bar_width*1.5)
        ax.set_xticklabels([f'{year}' for year in years])
        ax.set_ylim(0.70, 1.02)
        ax.grid(alpha=0.1)
        ax.legend(loc='upper right', fontsize=10)
        
        # Add value labels
        for i, year in enumerate(years):
            ax.text(i + bar_width*0.5, annual_stats.loc[i, ('health', 'max')] + 0.005, 
                   f'{annual_stats.loc[i, ("health", "max")]:.3f}', 
                   ha='center', fontsize=9)
            ax.text(i + bar_width*3.5, annual_stats.loc[i, ('health', 'min')] - 0.01, 
                   f'{annual_stats.loc[i, ("health", "min")]:.3f}', 
                   ha='center', fontsize=9, va='top')
        
        # Add degradation trend
        degradation_trend = [1 - annual_stats.loc[i, ('health', 'mean')] for i in range(len(years))]
        ax2 = ax.twinx()
        ax2.plot(index + bar_width*1.5, degradation_trend, 
                'o-', color='#9467bd', linewidth=2, markersize=8, 
                label='Avg Degradation Level')
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, 0.25)
        ax2.legend(loc='upper left', fontsize=10)
        
        # Add degradation rate trend
        ax3 = ax.twinx()
        ax3.spines['right'].set_position(('outward', 60))
        ax3.plot(index + bar_width*1.5, annual_stats[('degradation_rate', 'mean')], 
                's--', color='#e377c2', linewidth=2, markersize=8, 
                label='Avg Degradation Rate')
        ax3.set_ylabel('Degradation Rate (%/day)', fontsize=12)
        ax3.set_ylim(0, annual_stats[('degradation_rate', 'mean')].max() * 1.5)
        ax3.legend(loc='upper right', fontsize=10)
    
    def plot_detailed_degradation_path(self):
        """Plot detailed degradation path (hourly resolution)"""
        plt.figure(figsize=(15, 10))
        
        # Create grid layout
        gs = GridSpec(2, 1, height_ratios=[2, 1])
        
        # Chart 1: Health status with cleaning events
        ax1 = plt.subplot(gs[0])
        ax1.plot(self.data['timestamp'], self.data['health'], 
                color='#1f77b4', alpha=0.6, linewidth=0.8, label='Hourly Health')
        
        # Add daily average
        daily_health = self.data.groupby('date')['health'].mean()
        ax1.plot(daily_health.index, daily_health, 
                color='#2c7bb6', linewidth=2, label='Daily Avg Health')
        
        # Highlight cleaning events
        for event in self.cleaning_events:
            ax1.axvline(x=event, color='#ff7f0e', alpha=0.4, linestyle='-')
        
        # Add thresholds
        ax1.axhline(y=0.85, color='#ff7f0e', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.75, color='#d62728', linestyle='--', alpha=0.8)
        ax1.axhline(y=0.15, color='#2ca02c', linestyle='--', alpha=0.5)
        
        # Set properties
        ax1.set_title('Detailed Degradation Path (Hourly Resolution)', fontsize=16)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Health Status', fontsize=12)
        ax1.set_ylim(0.10, 1.02)  # Show safety threshold
        ax1.set_xlim(self.config.start_date, self.config.end_date)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='lower left', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Chart 2: Degradation components
        ax2 = plt.subplot(gs[1])
        ax2.plot(self.data['timestamp'], self.data['recoverable'], 
                color='#a6d96a', linewidth=1, alpha=0.7, label='Recoverable')
        ax2.plot(self.data['timestamp'], self.data['semi_permanent'], 
                color='#fdae61', linewidth=1, alpha=0.7, label='Semi-permanent')
        ax2.plot(self.data['timestamp'], self.data['permanent'], 
                color='#d7191c', linewidth=1, alpha=0.7, label='Permanent')
        
        # Set properties
        ax2.set_title('Degradation Components (Hourly Data)', fontsize=14)
        ax2.set_xlabel('Date', fontsize=12)
        ax2.set_ylabel('Degradation Level', fontsize=12)
        ax2.set_ylim(0, self.data[['recoverable', 'semi_permanent', 'permanent']].max().max() * 1.1)
        ax2.set_xlim(self.config.start_date, self.config.end_date)
        ax2.grid(alpha=0.1)
        ax2.legend(loc='upper left', fontsize=9)
        
        # Format date axis
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.25)
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'detailed_degradation_path.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_condition_impact_analysis(self):
        """Plot condition impact analysis"""
        # Calculate degradation rate by condition
        if 'condition' in self.data.columns:
            condition_degradation = self.data.groupby('condition').agg({
                'health': 'mean',
                'recoverable': 'mean',
                'semi_permanent': 'mean',
                'permanent': 'mean'
            })
            
            condition_degradation['total_degradation'] = 1 - condition_degradation['health']
            
            # Calculate degradation rate by condition
            condition_rates = self.data.copy()
            condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
            condition_rates = condition_rates.groupby('condition')['degradation'].agg(['mean', 'std'])
            
            plt.figure(figsize=(14, 6))
            
            # Chart 1: Degradation level by condition
            ax1 = plt.subplot(121)
            condition_degradation[['recoverable', 'semi_permanent', 'permanent']].plot.bar(
                stacked=True, ax=ax1, color=['#a6d96a', '#fdae61', '#d7191c'], alpha=0.85)
            
            ax1.set_title('Degradation Level by Operating Condition', fontsize=14)
            ax1.set_xlabel('Operating Condition', fontsize=12)
            ax1.set_ylabel('Average Degradation', fontsize=12)
            ax1.grid(alpha=0.1)
            ax1.legend(title='Degradation Type', fontsize=9)
            
            # Chart 2: Degradation rate by condition
            ax2 = plt.subplot(122)
            condition_rates['mean'].plot.bar(yerr=condition_rates['std'], 
                                           ax=ax2, color='#6a3d9a', alpha=0.7)
            
            ax2.set_title('Degradation Rate by Condition', fontsize=14)
            ax2.set_xlabel('Operating Condition', fontsize=12)
            ax2.set_ylabel('Average Degradation Rate', fontsize=12)
            ax2.grid(alpha=0.1)
            
            # Add condition impact factor
            for i, condition in enumerate(condition_rates.index):
                impact = self.config.condition_impact[condition]
                ax2.text(i, condition_rates['mean'].iloc[i] + 0.0001, 
                        f'Impact: {impact}x', ha='center', fontsize=9)
            
            plt.tight_layout()
            plt.subplots_adjust(top=0.88)
            plt.suptitle('Operating Condition Impact Analysis', fontsize=16)
            
            # Save chart
            plt.savefig(os.path.join(output_path, 'condition_impact_analysis.png'), dpi=300, bbox_inches='tight')
            plt.show()
            plt.close()
        else:
            print("No condition data available for analysis")
    
    def plot_cleaning_effectiveness_analysis(self):
        """Plot cleaning effectiveness analysis over time"""
        if not self.cleaning_events:
            print("No cleaning events available for analysis")
            return
        
        # Extract cleaning event data
        cleaning_events_data = self.data[self.data['timestamp'].isin(self.cleaning_events)].copy()
        cleaning_events_data = cleaning_events_data.sort_values('timestamp')
        cleaning_events_data['cleaning_count'] = range(1, len(cleaning_events_data)+1)
        
        # Calculate effectiveness metrics
        cleaning_events_data['recoverable_recovery'] = cleaning_events_data['cleaning_effect_recov'] / cleaning_events_data['recoverable']
        cleaning_events_data['semi_recovery'] = cleaning_events_data['cleaning_effect_semi'] / cleaning_events_data['semi_permanent']
        cleaning_events_data['perm_recovery'] = cleaning_events_data['cleaning_effect_perm'] / cleaning_events_data['permanent']
        
        # Remove invalid values
        cleaning_events_data = cleaning_events_data.replace([np.inf, -np.inf], np.nan).dropna(subset=[
            'recoverable_recovery', 'semi_recovery', 'perm_recovery'])
        
        plt.figure(figsize=(14, 8))
        
        # Chart 1: Cleaning effectiveness over time
        ax1 = plt.subplot(211)
        
        if 'recoverable_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['recoverable_recovery']*100, 
                    'o-', color='#a6d96a', label='Recoverable')
        if 'semi_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['semi_recovery']*100, 
                    's-', color='#fdae61', label='Semi-permanent')
        if 'perm_recovery' in cleaning_events_data.columns:
            ax1.plot(cleaning_events_data['timestamp'], cleaning_events_data['perm_recovery']*100, 
                    'd-', color='#d7191c', label='Permanent')
        
        ax1.set_title('Cleaning Effectiveness Over Time', fontsize=14)
        ax1.set_xlabel('Date', fontsize=12)
        ax1.set_ylabel('Degradation Reduction (%)', fontsize=12)
        ax1.grid(alpha=0.1)
        ax1.legend(loc='upper right', fontsize=10)
        
        # Format date axis
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Chart 2: Health improvement after cleaning
        ax2 = plt.subplot(212)
        health_improvement = []
        for _, row in cleaning_events_data.iterrows():
            pre_data = self.data[self.data['timestamp'] == row['timestamp'] - timedelta(hours=24)]
            if not pre_data.empty:
                improvement = row['health'] - pre_data['health'].values[0]
                health_improvement.append(improvement)
            else:
                health_improvement.append(0)
        cleaning_events_data['health_improvement'] = health_improvement
        
        if 'health_improvement' in cleaning_events_data.columns:
            ax2.plot(cleaning_events_data['timestamp'], cleaning_events_data['health_improvement']*100, 
                    'o-', color='#1f77b4')
            
            # Add linear regression trend
            from scipy.stats import linregress
            x_num = mdates.date2num(cleaning_events_data['timestamp'])
            y_vals = cleaning_events_data['health_improvement']*100
            valid_idx = ~np.isnan(y_vals) & ~np.isinf(y_vals)
            
            if any(valid_idx):
                slope, intercept, r_value, p_value, std_err = linregress(
                    x_num[valid_idx], y_vals[valid_idx])
                ax2.plot(cleaning_events_data['timestamp'], 
                        intercept + slope * x_num, 
                        '--', color='#d62728', 
                        label=f'Trend: y = {slope:.3f}x + {intercept:.3f}\nR² = {r_value**2:.3f}')
            
            ax2.set_title('Health Improvement After Cleaning', fontsize=14)
            ax2.set_xlabel('Date', fontsize=12)
            ax2.set_ylabel('Health Improvement (%)', fontsize=12)
            ax2.grid(alpha=0.1)
            ax2.legend(loc='upper right', fontsize=10)
            
            # Format date axis
            ax2.xaxis.set_major_locator(mdates.YearLocator())
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3)
        plt.suptitle('Cleaning Effectiveness Analysis', fontsize=16)
        
        # Save chart
        plt.savefig(os.path.join(output_path, 'cleaning_effectiveness_analysis.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_time_range_health(self, start_date, end_date):
        """Plot health index for specified time range"""
        time_filtered_data = self.data[(self.data['timestamp'] >= start_date) & (self.data['timestamp'] <= end_date)]
        
        if time_filtered_data.empty:
            print("No data in the specified time range")
            return
        
        plt.figure(figsize=(10, 6))
        plt.plot(time_filtered_data['timestamp'], time_filtered_data['health'], color='#1f77b4', linewidth=2, label='Health Status')
        
        plt.title(f'Health Index from {start_date} to {end_date}', fontsize=14)
        plt.xlabel('Date', fontsize=12)
        plt.ylabel('Health Status', fontsize=12)
        plt.ylim(0.70, 1.02)
        plt.grid(alpha=0.1)
        plt.legend(loc='upper right', fontsize=10)
        
        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        plt.gcf().autofmt_xdate()
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_path, f'health_index_{start_date}_{end_date}.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()
    
    def plot_evaluation_metrics(self):
        """Plot evaluation metrics including interval distribution, health change, degradation rate box plot, health histogram, and health autocorrelation"""
        plt.figure(figsize=(18, 12))
        
        # Interval distribution between cleaning events
        ax1 = plt.subplot(231)
        cleaning_intervals = np.diff(self.data['timestamp'].iloc[self.cleaning_hours])
        days_intervals = [interval / np.timedelta64(1, 'D') for interval in cleaning_intervals]
        sns.histplot(days_intervals, kde=True, ax=ax1, color='#1f77b4')
        ax1.set_title('Interval Distribution Between Cleaning Events', fontsize=14)
        ax1.set_xlabel('Days', fontsize=12)
        ax1.set_ylabel('Frequency', fontsize=12)
        ax1.grid(alpha=0.1)
        
        # Health change before and after cleaning
        ax2 = plt.subplot(232)
        health_changes = []
        for event in self.cleaning_events:
            # Health at cleaning event
            health_at_clean = self.data[self.data['timestamp'] == event]['health'].values[0]
            # Health 24 hours before cleaning
            pre_data = self.data[self.data['timestamp'] == event - timedelta(hours=24)]
            if not pre_data.empty:
                health_pre = pre_data['health'].values[0]
                health_changes.append(health_at_clean - health_pre)
        if health_changes:
            sns.histplot(health_changes, kde=True, ax=ax2, color='#ff7f0e')
            ax2.set_title('24-hour Health Change Before Cleaning', fontsize=14)
            ax2.set_xlabel('Health Change', fontsize=12)
            ax2.set_ylabel('Frequency', fontsize=12)
            ax2.grid(alpha=0.1)
        
        # Degradation rate box plot by condition
        ax3 = plt.subplot(233)
        condition_rates = self.data.copy()
        condition_rates['degradation'] = -condition_rates['health'].diff().fillna(0)
        if 'condition' in condition_rates.columns:
            sns.boxplot(x='condition', y='degradation', data=condition_rates, ax=ax3, palette=['#a6d96a', '#fdae61', '#d7191c'])
            ax3.set_title('Degradation Rate Box Plot by Condition', fontsize=14)
            ax3.set_xlabel('Condition', fontsize=12)
            ax3.set_ylabel('Degradation Rate', fontsize=12)
            ax3.grid(alpha=0.1)
        
        # Health status histogram
        ax4 = plt.subplot(234)
        sns.histplot(self.data['health'], kde=True, ax=ax4, color='#1f77b4')
        ax4.set_title('Health Status Distribution', fontsize=14)
        ax4.set_xlabel('Health', fontsize=12)
        ax4.set_ylabel('Frequency', fontsize=12)
        ax4.grid(alpha=0.1)
        
        # Health status over time (autocorrelation)
        ax5 = plt.subplot(235)
        self.daily_data[['date', 'health']].set_index('date').plot(ax=ax5, color='#1f77b4')
        ax5.set_title('Health Status Over Time', fontsize=14)
        ax5.set_xlabel('Date', fontsize=12)
        ax5.set_ylabel('Health', fontsize=12)
        ax5.grid(alpha=0.1)
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_path, 'evaluation_metrics.png'), dpi=300, bbox_inches='tight')
        plt.show()
        plt.close()

if __name__ == "__main__":
    # Initialize degradation model
    print("Initializing turbine degradation model...")
    config = DegradationModelConfig()
    
    # Run simulation
    print("Starting simulation...")
    simulator = AdvancedDegradationSimulator(config)
    degradation_data, cleaning_hours = simulator.simulate()
    print(f"Simulation completed! Generated {len(degradation_data)} hourly data points")
    print(f"Cleaning events: {len(cleaning_hours)}")
    
    # Analyze results
    analyzer = CompleteVisualization(degradation_data, cleaning_hours, config)
    
    # Generate comprehensive analysis chart
    print("Generating comprehensive analysis...")
    analyzer.plot_complete_analysis()
    
    # Save results
    degradation_data.to_csv(os.path.join(output_path, 'turbine_degradation_data.csv'), index=False)
    print("Results saved to 'turbine_degradation_data.csv'")
    
    # Print final health status
    final_health = degradation_data['health'].iloc[-1]
    print(f"\nFinal health status after 4 years: {final_health:.4f}")
    
    # Plot specified time range health trend
    analyzer.plot_time_range_health(datetime(2018, 5, 22), datetime(2018, 7, 1))
    
    # Plot evaluation metrics
    analyzer.plot_evaluation_metrics()
